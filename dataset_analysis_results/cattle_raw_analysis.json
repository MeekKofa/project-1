{
  "name": "cattle_raw",
  "path": "/data2/enoch/ekd_coding_env/meek/project1/dataset/cattle",
  "timestamp": "2025-10-03 12:07:09",
  "structure": {
    "splits": {
      "train": {
        "images": 7985,
        "labels": 7985,
        "image_dir": "/data2/enoch/ekd_coding_env/meek/project1/dataset/cattle/train/images",
        "label_dir": "/data2/enoch/ekd_coding_env/meek/project1/dataset/cattle/train/labels"
      },
      "val": {
        "images": 2017,
        "labels": 2017,
        "image_dir": "/data2/enoch/ekd_coding_env/meek/project1/dataset/cattle/val/images",
        "label_dir": "/data2/enoch/ekd_coding_env/meek/project1/dataset/cattle/val/labels"
      },
      "test": {
        "images": 1367,
        "labels": 1367,
        "image_dir": "/data2/enoch/ekd_coding_env/meek/project1/dataset/cattle/test/images",
        "label_dir": "/data2/enoch/ekd_coding_env/meek/project1/dataset/cattle/test/labels"
      }
    },
    "format": "unknown",
    "has_data_yaml": false
  },
  "images": {
    "total": 11369,
    "analyzed": 1000,
    "dimensions": {
      "unique_count": 86,
      "most_common": [
        [
          [
            2560,
            1440
          ],
          579
        ],
        [
          [
            2048,
            1363
          ],
          93
        ],
        [
          [
            1500,
            1001
          ],
          51
        ],
        [
          [
            1600,
            1064
          ],
          35
        ],
        [
          [
            2048,
            1362
          ],
          22
        ]
      ],
      "min": [
        886,
        592
      ],
      "max": [
        2048,
        1810
      ]
    },
    "aspect_ratios": {
      "mean": 1.656675245476877,
      "std": 0.15168220767487622,
      "min": 0.75,
      "max": 1.9086672879776327
    },
    "brightness": {
      "mean": 108.95700484078576,
      "std": 27.97817937080066,
      "min": 73.21987006293402,
      "max": 200.1146682905709
    },
    "contrast": {
      "mean": 65.25039592420043,
      "std": 8.097128959159804,
      "min": 35.28267404756676,
      "max": 93.9443088627073
    },
    "sharpness": {
      "mean": 1265.6935304888914,
      "std": 950.9484501854018,
      "min": 86.98596333429133,
      "max": 7857.147908657241
    },
    "file_sizes": {
      "mean_kb": 861.63652734375,
      "median_kb": 1154.60791015625,
      "min_kb": 93.33203125,
      "max_kb": 1485.93359375
    },
    "formats": {
      ".jpg": 1000
    },
    "channels": {
      "unique": [
        3
      ],
      "most_common": [
        3,
        1000
      ]
    }
  },
  "labels": {
    "total_files": 11369,
    "total_objects": 55792,
    "classes": {
      "num_classes": 2,
      "distribution": {
        "1": 4895,
        "0": 50897
      },
      "most_common": [
        [
          0,
          50897
        ],
        [
          1,
          4895
        ]
      ]
    },
    "objects_per_image": {
      "mean": 4.907379716773683,
      "median": 7.0,
      "min": 1,
      "max": 10
    },
    "bbox_size": {
      "width": {
        "mean": 0.12429100423362832,
        "median": 0.108984,
        "min": 0.0036572265625,
        "max": 0.5381640625
      },
      "height": {
        "mean": 0.21091830862558236,
        "median": 0.200694,
        "min": 0.0058002936857562415,
        "max": 0.5209815078236131
      },
      "area": {
        "mean": 0.028655850443734542,
        "median": 0.021629280816,
        "min": 2.1212988137848756e-05,
        "max": 0.26148998474178403
      },
      "aspect_ratio": {
        "mean": 0.5702466645525122,
        "median": 0.5462541783417637
      }
    }
  },
  "quality": {
    "issues": [],
    "warnings": [
      "Class imbalance detected (ratio: 10.40). Consider weighted loss or resampling.",
      "Large aspect ratio variation (0.75 to 1.91). Consider padding or letterboxing."
    ],
    "passed": true
  },
  "recommendations": {
    "preprocessing": [
      "Resize all images to consistent size (e.g., 640x640)"
    ],
    "augmentation": [
      "Add brightness augmentation (\u00b120%)",
      "Add contrast augmentation (\u00b120%)",
      "Horizontal flip (p=0.5)",
      "Random rotation (\u00b110\u00b0)",
      "Random scale (0.8-1.2)",
      "Mosaic augmentation for multi-object scenes"
    ],
    "training": [
      "Use num_classes=2",
      "Use weighted loss or focal loss for class imbalance"
    ],
    "architecture": [
      "Use small anchor sizes for tiny objects",
      "Consider using higher resolution (e.g., 1280x1280)"
    ]
  }
}