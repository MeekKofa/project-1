# Universal Training Configuration
# Dynamic, modular config for cattle detection training
# Auto-detects: num_classes, class_names, image/label counts at runtime

# ============================================================================
# ACTIVE PRESET - Change this to switch training modes quickly
# ============================================================================
active_preset: standard # Options: quick_test, standard, high_performance, custom

# ============================================================================
# DATASET CONFIGURATION
# ============================================================================
dataset:
  name: cattlebody # Options: cattle, cattlebody, cattleface
  split: raw # Options: raw, processed
  root: dataset/${dataset.name} # Auto-constructed path
  format: auto # auto-detect format (yolo, coco, voc)

  # Dataset properties detected at runtime - DO NOT SET MANUALLY
  # num_classes: auto-detected
  # class_names: auto-detected
  # splits: auto-detected

# ============================================================================
# MODEL CONFIGURATION
# ============================================================================
model:
  name: yolov8 # Options: yolov8, faster_rcnn
  pretrained: false
  freeze_backbone: false

# ============================================================================
# TRAINING HYPERPARAMETERS
# ============================================================================
train:
  epochs: 100
  batch_size: 8
  learning_rate: 0.001
  weight_decay: 0.0001
  momentum: 0.9

  # Optimizer
  optimizer: adamw # Options: sgd, adam, adamw, rmsprop
  optimizer_params:
    betas: [0.9, 0.999]
    eps: 1.0e-8

# ============================================================================
# PREPROCESSING (Applied before training)
# ============================================================================
preprocess:
  enabled: true
  target_size: [640, 640] # Resize all images to this size (640 for standard, 1280 for small objects)
  maintain_aspect: true # Use letterboxing to maintain aspect ratio
  normalize: true # Normalize to [0, 1]
  format: yolo # Output format for preprocessed data

  # Image quality filters
  min_image_size: [320, 320] # Filter out images smaller than this (detection minimum)
  max_image_size: null # Filter out images larger than this (null = no limit)

  # Label quality filters
  min_bbox_size: 0.001 # Minimum bbox area (normalized)
  filter_invalid_boxes: true # Remove boxes outside image bounds

# ============================================================================
# DATA AUGMENTATION (Applied during training)
# ============================================================================
augmentation:
  enabled: true

  # Geometric augmentations
  horizontal_flip: 0.5
  vertical_flip: 0.0
  rotation: 10 # degrees
  scale: [0.8, 1.2]
  translate: 0.1 # fraction of image
  shear: 0.0 # degrees

  # Color augmentations
  brightness: 0.2 # +/- 20%
  contrast: 0.2
  saturation: 0.2
  hue: 0.1

  # Advanced augmentations
  mosaic: true # Mosaic augmentation (4 images combined)
  mixup: 0.0 # Mixup alpha (0 = disabled)
  cutout: 0.0 # Cutout probability (0 = disabled)

# ============================================================================
# REGULARIZATION
# ============================================================================
regularization:
  dropout: 0.3
  label_smoothing: 0.0
  gradient_clip: 1.0
  weight_decay: 0.0001

# ============================================================================
# LOSS CONFIGURATION
# ============================================================================
loss:
  type: auto # Options: auto, focal, weighted, standard
  # Focal loss params (for class imbalance)
  focal_alpha: 0.25
  focal_gamma: 2.0
  # Weighted loss (auto-computed from dataset if type=weighted)
  class_weights: auto

# ============================================================================
# TRAINING STRATEGY
# ============================================================================
strategy:
  warmup_epochs: 5
  scheduler: cosine # Options: cosine, step, multistep, plateau
  early_stopping: true
  patience: 20
  mixed_precision: true # Use AMP for faster training

# ============================================================================
# VALIDATION
# ============================================================================
validation:
  interval: 1 # Validate every N epochs
  metric: mAP # Primary metric: mAP, loss, f1
  iou_threshold: 0.5 # IoU threshold for mAP calculation
  conf_threshold: 0.25 # Confidence threshold for predictions

# ============================================================================
# CHECKPOINTING
# ============================================================================
checkpoint:
  save_interval: 5 # Save checkpoint every N epochs
  save_best_only: false # Save only best model (by validation metric)
  save_last: true # Always save last checkpoint
  resume: null # Path to checkpoint to resume from

# ============================================================================
# OUTPUT & LOGGING
# ============================================================================
output:
  base_dir: outputs # Base output directory
  experiment_name: null # Auto-generated: {dataset}_{model}_{timestamp}
  log_interval: 10 # Log every N batches
  save_predictions: true
  save_visualizations: true
  tensorboard: true # Enable tensorboard logging

# ============================================================================
# VISUALIZATION
# ============================================================================
visualization:
  enabled: true
  save_interval: 10 # Save visualizations every N epochs
  num_samples: 8 # Number of samples to visualize
  show_ground_truth: true
  show_predictions: true
  confidence_threshold: 0.5

# ============================================================================
# DEVICE & COMPUTE
# ============================================================================
device:
  type: cuda # Options: cuda, cpu, mps
  gpu_ids: [0] # GPU IDs to use (for multi-GPU)
  workers: 4 # Dataloader workers
  pin_memory: true

# ============================================================================
# DEBUGGING & DEVELOPMENT
# ============================================================================
debug:
  enabled: false
  profile: false # Profile training performance
  fast_dev_run: false # Run 1 batch for debugging
  seed: 42 # Random seed for reproducibility

# ============================================================================
# TRAINING PRESETS (Override settings above based on use case)
# ============================================================================
presets:
  quick_test:
    # Fast experimentation - minimal epochs, smaller size
    train:
      epochs: 20
      batch_size: 16
      learning_rate: 0.001
    preprocess:
      target_size: [416, 416]
    augmentation:
      rotation: 5
      brightness: 0.1
      contrast: 0.1
    strategy:
      early_stopping: false
      warmup_epochs: 2
    checkpoint:
      save_interval: 10
      save_best_only: true
    output:
      save_predictions: false
      save_visualizations: false
    validation:
      interval: 2

  standard:
    # Balanced training - good results with reasonable time
    train:
      epochs: 100
      batch_size: 8
      learning_rate: 0.001
    preprocess:
      target_size: [640, 640]
    augmentation:
      rotation: 10
      brightness: 0.2
      contrast: 0.2
      mosaic: true
    strategy:
      early_stopping: true
      patience: 20
      warmup_epochs: 5
    checkpoint:
      save_interval: 5
      save_best_only: false
    validation:
      interval: 1

  high_performance:
    # Maximum accuracy - long training, aggressive augmentation
    train:
      epochs: 300
      batch_size: 16
      learning_rate: 0.002
    preprocess:
      target_size: [640, 640] # Can increase to 1280 for small objects
    augmentation:
      enabled: true
      horizontal_flip: 0.5
      vertical_flip: 0.2
      rotation: 15
      brightness: 0.3
      contrast: 0.3
      saturation: 0.3
      hue: 0.15
      mosaic: true
      mixup: 0.2
    regularization:
      label_smoothing: 0.1
    strategy:
      early_stopping: true
      patience: 50
      warmup_epochs: 10
    checkpoint:
      save_interval: 10
    validation:
      interval: 1

  custom:
    # Use the base configuration defined above
    # No overrides - fully customizable via config.yaml
# ============================================================================
# DATASET-SPECIFIC PROFILES
# ============================================================================
# Auto-filled from deep analysis, enhanced with preprocessing strategies
# These are automatically loaded from dataset_analysis_results/ at runtime

dataset_profiles:
  # --------------------------------------------------------------------------
  # CATTLEBODY - Single object body detection
  # --------------------------------------------------------------------------
  cattlebody:
    modality: rgb_camera
    task: single_object_detection

    analysis:
      num_classes: 1
      class_names: ["Cattlebody"]
      format: yolo
      has_data_yaml: true

      # Statistics from analysis
      image_stats:
        mean: [0.5380, 0.5380, 0.5380]
        std: [0.0820, 0.0820, 0.0820]
        brightness_mean: 137.20
        contrast_mean: 60.69
        aspect_ratio_range: [0.75, 2.19]

      object_stats:
        objects_per_image: 1.009
        avg_bbox_area: 0.105
        bbox_aspect_ratio: 0.985

      quality_issues:
        - "train: Image/label mismatch (3424 images, 3432 labels)"
        - "Large aspect ratio variation (0.75 to 2.19)"

      recommendations:
        - "Resize to 640x640 with letterboxing"
        - "Use standard loss (no class imbalance)"
        - "Fix train split mismatch via preprocessing"

    # Optimized settings for this dataset
    override:
      preprocess:
        target_size: [640, 640]
        maintain_aspect: true
        fix_mismatches: true
      train:
        batch_size: 16
        learning_rate: 0.001
      loss:
        type: standard

  # --------------------------------------------------------------------------
  # CATTLE - Multi-object detection with class imbalance
  # --------------------------------------------------------------------------
  cattle:
    modality: rgb_camera
    task: multi_object_detection

    analysis:
      num_classes: 2
      class_names: ["class_0", "class_1"]
      format: unknown
      has_data_yaml: false

      # Statistics
      image_stats:
        mean: [0.4272, 0.4272, 0.4272]
        std: [0.1097, 0.1097, 0.1097]
        brightness_mean: 108.96
        contrast_mean: 65.25
        aspect_ratio_range: [0.75, 1.91]

      object_stats:
        objects_per_image: 4.907
        avg_bbox_area: 0.029
        bbox_aspect_ratio: 0.570
        class_imbalance_ratio: 10.40 # SEVERE imbalance!

      quality_issues:
        - "Class imbalance detected (ratio: 10.40)"
        - "Small objects (avg area: 0.029)"

      recommendations:
        - "Use higher resolution (1280x1280) for small objects"
        - "Use focal loss for class imbalance"
        - "Aggressive augmentation (mosaic, mixup)"

    # Optimized settings for this dataset
    override:
      preprocess:
        target_size: [1280, 1280] # Higher for small objects
        min_bbox_size: 0.0005
        normalization:
          method: "dataset_specific"
          mean: [0.4272, 0.4272, 0.4272]
          std: [0.1097, 0.1097, 0.1097]
      augmentation:
        vertical_flip: 0.1
        rotation: 15
        scale: [0.7, 1.3]
        mixup: 0.15
      train:
        epochs: 150
        batch_size: 8 # Smaller due to 1280 resolution
        learning_rate: 0.0005
      loss:
        type: focal
        focal_alpha: 0.25
        focal_gamma: 2.0
      strategy:
        warmup_epochs: 10
        patience: 30

  # --------------------------------------------------------------------------
  # CATTLEFACE - BROKEN (no labels)
  # --------------------------------------------------------------------------
  cattleface:
    modality: rgb_camera
    task: face_detection
    status: broken # Cannot use for training

    analysis:
      num_classes: 0
      class_names: []
      quality_issues:
        - "NO LABELS FOUND - Cannot train!"
        - "All splits missing annotations"

      recommendations:
        - "Find original annotation files or re-annotate"

    # Cannot configure training without labels
    override:
      enabled: false
