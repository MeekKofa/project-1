2025-09-30 11:22:22,237 - INFO - Using device: cuda
2025-09-30 11:22:22,238 - INFO - Loading split dataset (train/val/test)...
2025-09-30 11:22:22,279 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-09-30 11:22:22,280 - INFO - Initializing adaptive fusion model...
2025-09-30 11:29:10,498 - INFO - Using device: cuda
2025-09-30 11:37:26,241 - INFO - Using device: cuda
2025-09-30 11:37:26,242 - INFO - Loading split dataset (train/val/test)...
2025-09-30 11:37:26,264 - INFO - âœ… Split dataset loaded successfully!
2025-09-30 11:37:26,264 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-09-30 11:37:26,265 - INFO - Initializing adaptive fusion model...
2025-09-30 11:39:26,676 - INFO - Using device: cuda
2025-09-30 11:39:26,676 - INFO - Loading split dataset (train/val/test)...
2025-09-30 11:39:26,710 - INFO - Split dataset loaded successfully!
2025-09-30 11:39:26,710 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-09-30 11:39:26,710 - INFO - Initializing adaptive fusion model...
2025-09-30 12:10:35,408 - INFO - Using device: cuda
2025-09-30 12:10:35,409 - INFO - Loading split dataset (train/val/test)...
2025-09-30 12:10:35,444 - INFO - Split dataset loaded successfully!
2025-09-30 12:10:35,444 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-09-30 12:10:35,445 - INFO - Initializing adaptive fusion model...
2025-09-30 12:10:36,053 - INFO -  Starting cattle detection training...
2025-09-30 12:14:48,569 - INFO - Using device: cuda
2025-09-30 12:14:48,569 - INFO - Loading split dataset (train/val/test)...
2025-09-30 12:14:48,586 - INFO - Split dataset loaded successfully!
2025-09-30 12:14:48,586 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-09-30 12:14:48,586 - INFO - Initializing adaptive fusion model...
2025-09-30 12:14:49,113 - INFO -  Starting cattle detection training...
2025-09-30 12:42:12,660 - INFO - Epoch 1 | Training Loss: 1.6522
2025-09-30 12:42:12,661 - INFO - Learning rate updated to: 0.000100
2025-09-30 15:16:27,567 - INFO - Using device: cuda
2025-09-30 15:16:27,567 - INFO - Loading split dataset (train/val/test)...
2025-09-30 15:16:27,642 - INFO - Split dataset loaded successfully!
2025-09-30 15:16:27,643 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-09-30 15:16:27,645 - INFO - Initializing adaptive fusion model...
2025-09-30 15:16:28,450 - INFO -  Starting cattle detection training...
2025-09-30 15:21:48,201 - INFO - Using device: cuda
2025-09-30 15:21:48,202 - INFO - Loading split dataset (train/val/test)...
2025-09-30 15:21:48,235 - INFO - Split dataset loaded successfully!
2025-09-30 15:21:48,235 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-09-30 15:21:48,236 - INFO - Initializing adaptive fusion model...
2025-09-30 15:21:48,873 - INFO -  Starting cattle detection training...
2025-09-30 15:26:54,838 - INFO - Using device: cuda
2025-09-30 15:26:54,838 - INFO - Loading split dataset (train/val/test)...
2025-09-30 15:26:54,862 - INFO - Split dataset loaded successfully!
2025-09-30 15:26:54,863 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-09-30 15:26:54,863 - INFO - Initializing adaptive fusion model...
2025-09-30 15:26:55,638 - INFO -  Starting cattle detection training...
2025-09-30 15:52:43,349 - INFO - Epoch 1 | Training Loss: 1.5993
2025-09-30 15:52:43,350 - INFO - Learning rate updated to: 0.000100
2025-09-30 16:34:53,614 - INFO - Using device: cuda
2025-09-30 16:34:53,614 - INFO - Loading split dataset (train/val/test)...
2025-09-30 16:34:53,633 - INFO - Split dataset loaded successfully!
2025-09-30 16:34:53,633 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-09-30 16:34:53,634 - INFO - Initializing adaptive fusion model...
2025-09-30 16:34:54,364 - INFO -  Starting cattle detection training...
2025-09-30 17:00:45,692 - INFO - Epoch 1 | Training Loss: 1.5624
2025-09-30 17:00:45,693 - INFO - Learning rate updated to: 0.000100
2025-09-30 17:05:24,435 - INFO - ======================================================================
2025-09-30 17:05:24,435 - INFO - VAL Set Metrics:
2025-09-30 17:05:24,436 - INFO - mAP50 (Critical):  0.2154 (Aim for >0.7 for good performance)
2025-09-30 17:05:24,436 - INFO - mAP50-95 (Strict): 0.0653
2025-09-30 17:05:24,436 - INFO - Precision (IoU=0.5): 0.4495 (Fewer false cattle)
2025-09-30 17:05:24,437 - INFO - Recall (IoU=0.5):    0.0409 (Fewer missed cattle)
2025-09-30 17:05:24,437 - INFO - ======================================================================
2025-09-30 17:05:25,288 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model_epoch1_map50_0.2154.pth
2025-09-30 17:32:05,152 - INFO - Epoch 2 | Training Loss: 0.4896
2025-09-30 17:32:05,153 - INFO - Learning rate updated to: 0.000100
2025-09-30 17:36:52,652 - INFO - ======================================================================
2025-09-30 17:36:52,653 - INFO - VAL Set Metrics:
2025-09-30 17:36:52,653 - INFO - mAP50 (Critical):  0.2435 (Aim for >0.7 for good performance)
2025-09-30 17:36:52,653 - INFO - mAP50-95 (Strict): 0.0857
2025-09-30 17:36:52,654 - INFO - Precision (IoU=0.5): 0.4733 (Fewer false cattle)
2025-09-30 17:36:52,654 - INFO - Recall (IoU=0.5):    0.0447 (Fewer missed cattle)
2025-09-30 17:36:52,654 - INFO - ======================================================================
2025-09-30 17:36:53,587 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model_epoch2_map50_0.2435.pth
2025-09-30 18:03:35,070 - INFO - Epoch 3 | Training Loss: 0.5292
2025-09-30 18:03:35,071 - INFO - Learning rate updated to: 0.000100
2025-09-30 18:08:19,404 - INFO - ======================================================================
2025-09-30 18:08:19,404 - INFO - VAL Set Metrics:
2025-09-30 18:08:19,405 - INFO - mAP50 (Critical):  0.1766 (Aim for >0.7 for good performance)
2025-09-30 18:08:19,405 - INFO - mAP50-95 (Strict): 0.0506
2025-09-30 18:08:19,405 - INFO - Precision (IoU=0.5): 0.2524 (Fewer false cattle)
2025-09-30 18:08:19,406 - INFO - Recall (IoU=0.5):    0.0386 (Fewer missed cattle)
2025-09-30 18:08:19,406 - INFO - ======================================================================
2025-09-30 18:08:19,435 - INFO -  No improvement: Current Val mAP50 (0.1766) < Best (0.2435)
2025-09-30 18:34:14,631 - INFO - Epoch 4 | Training Loss: 0.4254
2025-09-30 18:34:14,632 - INFO - Learning rate updated to: 0.000100
2025-09-30 18:38:55,168 - INFO - ======================================================================
2025-09-30 18:38:55,168 - INFO - VAL Set Metrics:
2025-09-30 18:38:55,169 - INFO - mAP50 (Critical):  0.2578 (Aim for >0.7 for good performance)
2025-09-30 18:38:55,169 - INFO - mAP50-95 (Strict): 0.0977
2025-09-30 18:38:55,169 - INFO - Precision (IoU=0.5): 0.5820 (Fewer false cattle)
2025-09-30 18:38:55,170 - INFO - Recall (IoU=0.5):    0.0391 (Fewer missed cattle)
2025-09-30 18:38:55,170 - INFO - ======================================================================
2025-09-30 18:38:56,116 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model_epoch4_map50_0.2578.pth
2025-09-30 19:04:56,619 - INFO - Epoch 5 | Training Loss: 0.4192
2025-09-30 19:04:56,620 - INFO - Learning rate updated to: 0.000100
2025-09-30 19:09:41,228 - INFO - ======================================================================
2025-09-30 19:09:41,229 - INFO - VAL Set Metrics:
2025-09-30 19:09:41,229 - INFO - mAP50 (Critical):  0.3180 (Aim for >0.7 for good performance)
2025-09-30 19:09:41,229 - INFO - mAP50-95 (Strict): 0.1034
2025-09-30 19:09:41,230 - INFO - Precision (IoU=0.5): 0.4333 (Fewer false cattle)
2025-09-30 19:09:41,230 - INFO - Recall (IoU=0.5):    0.0480 (Fewer missed cattle)
2025-09-30 19:09:41,230 - INFO - ======================================================================
2025-09-30 19:09:42,086 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model_epoch5_map50_0.3180.pth
2025-09-30 19:35:54,702 - INFO - Epoch 6 | Training Loss: 0.4159
2025-09-30 19:35:54,716 - INFO - Learning rate updated to: 0.000100
2025-09-30 19:40:36,384 - INFO - ======================================================================
2025-09-30 19:40:36,384 - INFO - VAL Set Metrics:
2025-09-30 19:40:36,385 - INFO - mAP50 (Critical):  0.3446 (Aim for >0.7 for good performance)
2025-09-30 19:40:36,385 - INFO - mAP50-95 (Strict): 0.1313
2025-09-30 19:40:36,385 - INFO - Precision (IoU=0.5): 0.5616 (Fewer false cattle)
2025-09-30 19:40:36,385 - INFO - Recall (IoU=0.5):    0.0481 (Fewer missed cattle)
2025-09-30 19:40:36,385 - INFO - ======================================================================
2025-09-30 19:40:37,232 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model_epoch6_map50_0.3446.pth
2025-09-30 20:06:27,926 - INFO - Epoch 7 | Training Loss: 0.3878
2025-09-30 20:06:27,927 - INFO - Learning rate updated to: 0.000100
2025-09-30 20:11:13,122 - INFO - ======================================================================
2025-09-30 20:11:13,122 - INFO - VAL Set Metrics:
2025-09-30 20:11:13,122 - INFO - mAP50 (Critical):  0.3105 (Aim for >0.7 for good performance)
2025-09-30 20:11:13,123 - INFO - mAP50-95 (Strict): 0.1160
2025-09-30 20:11:13,123 - INFO - Precision (IoU=0.5): 0.4507 (Fewer false cattle)
2025-09-30 20:11:13,123 - INFO - Recall (IoU=0.5):    0.0474 (Fewer missed cattle)
2025-09-30 20:11:13,124 - INFO - ======================================================================
2025-09-30 20:11:13,153 - INFO -  No improvement: Current Val mAP50 (0.3105) < Best (0.3446)
2025-09-30 20:36:51,359 - INFO - Epoch 8 | Training Loss: 0.3900
2025-09-30 20:36:51,361 - INFO - Learning rate updated to: 0.000100
2025-09-30 20:41:39,784 - INFO - ======================================================================
2025-09-30 20:41:39,785 - INFO - VAL Set Metrics:
2025-09-30 20:41:39,785 - INFO - mAP50 (Critical):  0.3230 (Aim for >0.7 for good performance)
2025-09-30 20:41:39,786 - INFO - mAP50-95 (Strict): 0.1082
2025-09-30 20:41:39,786 - INFO - Precision (IoU=0.5): 0.3450 (Fewer false cattle)
2025-09-30 20:41:39,787 - INFO - Recall (IoU=0.5):    0.0506 (Fewer missed cattle)
2025-09-30 20:41:39,787 - INFO - ======================================================================
2025-09-30 20:41:39,812 - INFO -  No improvement: Current Val mAP50 (0.3230) < Best (0.3446)
2025-09-30 21:08:10,218 - INFO - Epoch 9 | Training Loss: 0.4064
2025-09-30 21:08:10,219 - INFO - Learning rate updated to: 0.000100
2025-09-30 21:13:01,187 - INFO - ======================================================================
2025-09-30 21:13:01,187 - INFO - VAL Set Metrics:
2025-09-30 21:13:01,187 - INFO - mAP50 (Critical):  0.3438 (Aim for >0.7 for good performance)
2025-09-30 21:13:01,187 - INFO - mAP50-95 (Strict): 0.1356
2025-09-30 21:13:01,188 - INFO - Precision (IoU=0.5): 0.2560 (Fewer false cattle)
2025-09-30 21:13:01,188 - INFO - Recall (IoU=0.5):    0.0541 (Fewer missed cattle)
2025-09-30 21:13:01,188 - INFO - ======================================================================
2025-09-30 21:13:01,213 - INFO -  No improvement: Current Val mAP50 (0.3438) < Best (0.3446)
2025-09-30 21:39:59,542 - INFO - Epoch 10 | Training Loss: 0.3540
2025-09-30 21:39:59,543 - INFO - Learning rate updated to: 0.000100
2025-09-30 21:45:37,486 - INFO - ======================================================================
2025-09-30 21:45:37,486 - INFO - VAL Set Metrics:
2025-09-30 21:45:37,486 - INFO - mAP50 (Critical):  0.3784 (Aim for >0.7 for good performance)
2025-09-30 21:45:37,487 - INFO - mAP50-95 (Strict): 0.1638
2025-09-30 21:45:37,487 - INFO - Precision (IoU=0.5): 0.5291 (Fewer false cattle)
2025-09-30 21:45:37,487 - INFO - Recall (IoU=0.5):    0.0533 (Fewer missed cattle)
2025-09-30 21:45:37,487 - INFO - ======================================================================
2025-09-30 21:45:38,381 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model_epoch10_map50_0.3784.pth
2025-09-30 21:46:33,536 - INFO - Using device: cuda
2025-09-30 21:46:33,536 - INFO - Loading split dataset (train/val/test)...
2025-09-30 21:46:33,563 - INFO - Split dataset loaded successfully!
2025-09-30 21:46:33,563 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-09-30 21:46:33,563 - INFO - Initializing adaptive fusion model...
2025-09-30 21:46:34,493 - INFO -  Starting cattle detection training...
2025-09-30 22:09:58,861 - INFO - Epoch 1 | Training Loss: 2.5753
2025-09-30 22:09:58,862 - INFO - Learning rate updated to: 0.000100
2025-09-30 22:14:13,691 - INFO - ======================================================================
2025-09-30 22:14:13,691 - INFO - VAL Set Metrics:
2025-09-30 22:14:13,691 - INFO - mAP50 (Critical):  0.2513 (Aim for >0.7 for good performance)
2025-09-30 22:14:13,691 - INFO - mAP50-95 (Strict): 0.0826
2025-09-30 22:14:13,692 - INFO - Precision (IoU=0.5): 0.2216 (Fewer false cattle)
2025-09-30 22:14:13,692 - INFO - Recall (IoU=0.5):    0.0452 (Fewer missed cattle)
2025-09-30 22:14:13,692 - INFO - ======================================================================
2025-09-30 22:14:14,513 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model_epoch1_map50_0.2513.pth
2025-09-30 22:21:27,409 - INFO - Using device: cuda
2025-09-30 22:21:27,409 - INFO - Loading split dataset (train/val/test)...
2025-09-30 22:21:27,433 - INFO - Split dataset loaded successfully!
2025-09-30 22:21:27,433 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-09-30 22:21:27,434 - INFO - Initializing adaptive fusion model...
2025-09-30 22:21:28,018 - INFO -  Starting cattle detection training...
2025-09-30 22:35:55,386 - INFO - Using device: cuda
2025-09-30 22:35:55,386 - INFO - Loading split dataset (train/val/test)...
2025-09-30 22:35:55,417 - INFO - Split dataset loaded successfully!
2025-09-30 22:35:55,417 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-09-30 22:35:55,417 - INFO - Initializing adaptive fusion model...
2025-09-30 22:35:55,963 - INFO -  Starting cattle detection training...
2025-09-30 22:55:56,447 - INFO - Epoch 1 | Training Loss: 2.0462
2025-09-30 22:55:56,448 - INFO - Learning rate updated to: 0.000100
2025-09-30 22:59:55,034 - INFO - ==========================================================================================
2025-09-30 22:59:55,034 - INFO - VAL Set Metrics:
2025-09-30 22:59:55,035 - INFO - mAP50 :  0.0801 
2025-09-30 22:59:55,035 - INFO - mAP50-95 : 0.0263
2025-09-30 22:59:55,035 - INFO - Precision : 0.1288 
2025-09-30 22:59:55,036 - INFO - Recall :    0.0220 
2025-09-30 22:59:55,036 - INFO - ==========================================================================================
2025-09-30 22:59:55,851 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-09-30 23:20:47,466 - INFO - Epoch 2 | Training Loss: 0.3774
2025-09-30 23:20:47,467 - INFO - Learning rate updated to: 0.000100
2025-09-30 23:24:42,300 - INFO - ==========================================================================================
2025-09-30 23:24:42,300 - INFO - VAL Set Metrics:
2025-09-30 23:24:42,301 - INFO - mAP50 :  0.3355 
2025-09-30 23:24:42,301 - INFO - mAP50-95 : 0.1772
2025-09-30 23:24:42,301 - INFO - Precision : 0.3162 
2025-09-30 23:24:42,302 - INFO - Recall :    0.0501 
2025-09-30 23:24:42,302 - INFO - ==========================================================================================
2025-09-30 23:24:43,145 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-09-30 23:45:26,666 - INFO - Epoch 3 | Training Loss: 0.3293
2025-09-30 23:45:26,667 - INFO - Learning rate updated to: 0.000100
2025-09-30 23:49:23,356 - INFO - ==========================================================================================
2025-09-30 23:49:23,357 - INFO - VAL Set Metrics:
2025-09-30 23:49:23,357 - INFO - mAP50 :  0.3541 
2025-09-30 23:49:23,358 - INFO - mAP50-95 : 0.2138
2025-09-30 23:49:23,358 - INFO - Precision : 0.1756 
2025-09-30 23:49:23,358 - INFO - Recall :    0.0515 
2025-09-30 23:49:23,359 - INFO - ==========================================================================================
2025-09-30 23:49:24,239 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 00:10:09,727 - INFO - Epoch 4 | Training Loss: 0.3080
2025-10-01 00:10:09,728 - INFO - Learning rate updated to: 0.000100
2025-10-01 00:14:04,798 - INFO - ==========================================================================================
2025-10-01 00:14:04,798 - INFO - VAL Set Metrics:
2025-10-01 00:14:04,798 - INFO - mAP50 :  0.3946 
2025-10-01 00:14:04,798 - INFO - mAP50-95 : 0.2413
2025-10-01 00:14:04,799 - INFO - Precision : 0.3929 
2025-10-01 00:14:04,799 - INFO - Recall :    0.0559 
2025-10-01 00:14:04,799 - INFO - ==========================================================================================
2025-10-01 00:14:05,628 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 00:34:45,107 - INFO - Epoch 5 | Training Loss: 0.2970
2025-10-01 00:34:45,108 - INFO - Learning rate updated to: 0.000100
2025-10-01 00:38:39,696 - INFO - ==========================================================================================
2025-10-01 00:38:39,696 - INFO - VAL Set Metrics:
2025-10-01 00:38:39,696 - INFO - mAP50 :  0.4152 
2025-10-01 00:38:39,696 - INFO - mAP50-95 : 0.2610
2025-10-01 00:38:39,697 - INFO - Precision : 0.2941 
2025-10-01 00:38:39,697 - INFO - Recall :    0.0589 
2025-10-01 00:38:39,697 - INFO - ==========================================================================================
2025-10-01 00:38:40,524 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 00:59:24,158 - INFO - Epoch 6 | Training Loss: 0.2754
2025-10-01 00:59:24,159 - INFO - Learning rate updated to: 0.000100
2025-10-01 01:03:22,324 - INFO - ==========================================================================================
2025-10-01 01:03:22,324 - INFO - VAL Set Metrics:
2025-10-01 01:03:22,325 - INFO - mAP50 :  0.4432 
2025-10-01 01:03:22,325 - INFO - mAP50-95 : 0.3068
2025-10-01 01:03:22,325 - INFO - Precision : 0.3511 
2025-10-01 01:03:22,326 - INFO - Recall :    0.0610 
2025-10-01 01:03:22,326 - INFO - ==========================================================================================
2025-10-01 01:03:23,171 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 01:24:00,199 - INFO - Epoch 7 | Training Loss: 0.2650
2025-10-01 01:24:00,201 - INFO - Learning rate updated to: 0.000100
2025-10-01 01:27:53,837 - INFO - ==========================================================================================
2025-10-01 01:27:53,837 - INFO - VAL Set Metrics:
2025-10-01 01:27:53,838 - INFO - mAP50 :  0.4549 
2025-10-01 01:27:53,838 - INFO - mAP50-95 : 0.3201
2025-10-01 01:27:53,838 - INFO - Precision : 0.3838 
2025-10-01 01:27:53,838 - INFO - Recall :    0.0623 
2025-10-01 01:27:53,839 - INFO - ==========================================================================================
2025-10-01 01:27:54,691 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 01:48:27,795 - INFO - Epoch 8 | Training Loss: 0.2552
2025-10-01 01:48:27,796 - INFO - Learning rate updated to: 0.000100
2025-10-01 01:52:21,915 - INFO - ==========================================================================================
2025-10-01 01:52:21,916 - INFO - VAL Set Metrics:
2025-10-01 01:52:21,916 - INFO - mAP50 :  0.4574 
2025-10-01 01:52:21,916 - INFO - mAP50-95 : 0.3173
2025-10-01 01:52:21,916 - INFO - Precision : 0.2804 
2025-10-01 01:52:21,917 - INFO - Recall :    0.0632 
2025-10-01 01:52:21,917 - INFO - ==========================================================================================
2025-10-01 01:52:22,755 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 02:14:42,134 - INFO - Epoch 9 | Training Loss: 0.2466
2025-10-01 02:14:42,136 - INFO - Learning rate updated to: 0.000100
2025-10-01 02:19:06,973 - INFO - ==========================================================================================
2025-10-01 02:19:06,973 - INFO - VAL Set Metrics:
2025-10-01 02:19:06,974 - INFO - mAP50 :  0.4585 
2025-10-01 02:19:06,974 - INFO - mAP50-95 : 0.3344
2025-10-01 02:19:06,974 - INFO - Precision : 0.4849 
2025-10-01 02:19:06,974 - INFO - Recall :    0.0619 
2025-10-01 02:19:06,975 - INFO - ==========================================================================================
2025-10-01 02:19:07,809 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 02:40:06,627 - INFO - Epoch 10 | Training Loss: 0.2442
2025-10-01 02:40:06,628 - INFO - Learning rate updated to: 0.000100
2025-10-01 02:44:00,439 - INFO - ==========================================================================================
2025-10-01 02:44:00,440 - INFO - VAL Set Metrics:
2025-10-01 02:44:00,440 - INFO - mAP50 :  0.4701 
2025-10-01 02:44:00,441 - INFO - mAP50-95 : 0.3392
2025-10-01 02:44:00,441 - INFO - Precision : 0.3501 
2025-10-01 02:44:00,441 - INFO - Recall :    0.0640 
2025-10-01 02:44:00,441 - INFO - ==========================================================================================
2025-10-01 02:44:01,273 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 03:04:35,092 - INFO - Epoch 11 | Training Loss: 0.2503
2025-10-01 03:04:35,093 - INFO - Learning rate updated to: 0.000100
2025-10-01 03:08:28,914 - INFO - ==========================================================================================
2025-10-01 03:08:28,915 - INFO - VAL Set Metrics:
2025-10-01 03:08:28,915 - INFO - mAP50 :  0.4699 
2025-10-01 03:08:28,915 - INFO - mAP50-95 : 0.3524
2025-10-01 03:08:28,916 - INFO - Precision : 0.4364 
2025-10-01 03:08:28,916 - INFO - Recall :    0.0636 
2025-10-01 03:08:28,916 - INFO - ==========================================================================================
2025-10-01 03:08:28,953 - INFO -  No improvement: Current Val mAP50 (0.4699) < Best (0.4701)
2025-10-01 03:28:56,996 - INFO - Epoch 12 | Training Loss: 0.2573
2025-10-01 03:28:56,997 - INFO - Learning rate updated to: 0.000100
2025-10-01 03:32:51,535 - INFO - ==========================================================================================
2025-10-01 03:32:51,535 - INFO - VAL Set Metrics:
2025-10-01 03:32:51,536 - INFO - mAP50 :  0.4799 
2025-10-01 03:32:51,536 - INFO - mAP50-95 : 0.3560
2025-10-01 03:32:51,537 - INFO - Precision : 0.3246 
2025-10-01 03:32:51,537 - INFO - Recall :    0.0645 
2025-10-01 03:32:51,537 - INFO - ==========================================================================================
2025-10-01 03:32:52,405 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 03:53:23,460 - INFO - Epoch 13 | Training Loss: 0.2250
2025-10-01 03:53:23,461 - INFO - Learning rate updated to: 0.000100
2025-10-01 03:57:18,027 - INFO - ==========================================================================================
2025-10-01 03:57:18,027 - INFO - VAL Set Metrics:
2025-10-01 03:57:18,027 - INFO - mAP50 :  0.4677 
2025-10-01 03:57:18,028 - INFO - mAP50-95 : 0.3492
2025-10-01 03:57:18,028 - INFO - Precision : 0.3525 
2025-10-01 03:57:18,028 - INFO - Recall :    0.0637 
2025-10-01 03:57:18,028 - INFO - ==========================================================================================
2025-10-01 03:57:18,065 - INFO -  No improvement: Current Val mAP50 (0.4677) < Best (0.4799)
2025-10-01 04:17:47,481 - INFO - Epoch 14 | Training Loss: 0.2470
2025-10-01 04:17:47,496 - INFO - Learning rate updated to: 0.000100
2025-10-01 04:21:42,418 - INFO - ==========================================================================================
2025-10-01 04:21:42,418 - INFO - VAL Set Metrics:
2025-10-01 04:21:42,418 - INFO - mAP50 :  0.4602 
2025-10-01 04:21:42,419 - INFO - mAP50-95 : 0.3541
2025-10-01 04:21:42,419 - INFO - Precision : 0.3286 
2025-10-01 04:21:42,419 - INFO - Recall :    0.0632 
2025-10-01 04:21:42,419 - INFO - ==========================================================================================
2025-10-01 04:21:42,455 - INFO -  No improvement: Current Val mAP50 (0.4602) < Best (0.4799)
2025-10-01 04:42:08,863 - INFO - Epoch 15 | Training Loss: 0.2192
2025-10-01 04:42:08,864 - INFO - Learning rate updated to: 0.000050
2025-10-01 04:46:04,083 - INFO - ==========================================================================================
2025-10-01 04:46:04,083 - INFO - VAL Set Metrics:
2025-10-01 04:46:04,084 - INFO - mAP50 :  0.4721 
2025-10-01 04:46:04,084 - INFO - mAP50-95 : 0.3591
2025-10-01 04:46:04,084 - INFO - Precision : 0.4270 
2025-10-01 04:46:04,085 - INFO - Recall :    0.0639 
2025-10-01 04:46:04,085 - INFO - ==========================================================================================
2025-10-01 04:46:04,115 - INFO -  No improvement: Current Val mAP50 (0.4721) < Best (0.4799)
2025-10-01 05:06:29,869 - INFO - Epoch 16 | Training Loss: 0.2120
2025-10-01 05:06:29,870 - INFO - Learning rate updated to: 0.000050
2025-10-01 05:10:24,299 - INFO - ==========================================================================================
2025-10-01 05:10:24,300 - INFO - VAL Set Metrics:
2025-10-01 05:10:24,300 - INFO - mAP50 :  0.4806 
2025-10-01 05:10:24,300 - INFO - mAP50-95 : 0.3798
2025-10-01 05:10:24,301 - INFO - Precision : 0.3406 
2025-10-01 05:10:24,301 - INFO - Recall :    0.0648 
2025-10-01 05:10:24,301 - INFO - ==========================================================================================
2025-10-01 05:10:25,125 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 05:30:51,931 - INFO - Epoch 17 | Training Loss: 0.2084
2025-10-01 05:30:51,932 - INFO - Learning rate updated to: 0.000050
2025-10-01 05:34:45,768 - INFO - ==========================================================================================
2025-10-01 05:34:45,768 - INFO - VAL Set Metrics:
2025-10-01 05:34:45,768 - INFO - mAP50 :  0.4774 
2025-10-01 05:34:45,769 - INFO - mAP50-95 : 0.3833
2025-10-01 05:34:45,769 - INFO - Precision : 0.4032 
2025-10-01 05:34:45,769 - INFO - Recall :    0.0648 
2025-10-01 05:34:45,769 - INFO - ==========================================================================================
2025-10-01 05:34:45,802 - INFO -  No improvement: Current Val mAP50 (0.4774) < Best (0.4806)
2025-10-01 05:55:05,497 - INFO - Epoch 18 | Training Loss: 0.2057
2025-10-01 05:55:05,498 - INFO - Learning rate updated to: 0.000050
2025-10-01 05:58:59,704 - INFO - ==========================================================================================
2025-10-01 05:58:59,704 - INFO - VAL Set Metrics:
2025-10-01 05:58:59,705 - INFO - mAP50 :  0.4872 
2025-10-01 05:58:59,705 - INFO - mAP50-95 : 0.3861
2025-10-01 05:58:59,706 - INFO - Precision : 0.4689 
2025-10-01 05:58:59,706 - INFO - Recall :    0.0650 
2025-10-01 05:58:59,706 - INFO - ==========================================================================================
2025-10-01 05:59:00,546 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 06:19:30,339 - INFO - Epoch 19 | Training Loss: 0.2074
2025-10-01 06:19:30,340 - INFO - Learning rate updated to: 0.000050
2025-10-01 06:23:24,446 - INFO - ==========================================================================================
2025-10-01 06:23:24,446 - INFO - VAL Set Metrics:
2025-10-01 06:23:24,447 - INFO - mAP50 :  0.4861 
2025-10-01 06:23:24,447 - INFO - mAP50-95 : 0.3848
2025-10-01 06:23:24,447 - INFO - Precision : 0.4084 
2025-10-01 06:23:24,447 - INFO - Recall :    0.0649 
2025-10-01 06:23:24,447 - INFO - ==========================================================================================
2025-10-01 06:23:24,486 - INFO -  No improvement: Current Val mAP50 (0.4861) < Best (0.4872)
2025-10-01 06:43:42,692 - INFO - Epoch 20 | Training Loss: 0.2042
2025-10-01 06:43:42,693 - INFO - Learning rate updated to: 0.000050
2025-10-01 06:47:37,802 - INFO - ==========================================================================================
2025-10-01 06:47:37,803 - INFO - VAL Set Metrics:
2025-10-01 06:47:37,803 - INFO - mAP50 :  0.4833 
2025-10-01 06:47:37,803 - INFO - mAP50-95 : 0.3842
2025-10-01 06:47:37,803 - INFO - Precision : 0.4193 
2025-10-01 06:47:37,803 - INFO - Recall :    0.0649 
2025-10-01 06:47:37,804 - INFO - ==========================================================================================
2025-10-01 06:47:37,839 - INFO -  No improvement: Current Val mAP50 (0.4833) < Best (0.4872)
2025-10-01 07:08:07,301 - INFO - Epoch 21 | Training Loss: 0.2022
2025-10-01 07:08:07,302 - INFO - Learning rate updated to: 0.000050
2025-10-01 07:12:02,948 - INFO - ==========================================================================================
2025-10-01 07:12:02,948 - INFO - VAL Set Metrics:
2025-10-01 07:12:02,948 - INFO - mAP50 :  0.4804 
2025-10-01 07:12:02,948 - INFO - mAP50-95 : 0.3816
2025-10-01 07:12:02,949 - INFO - Precision : 0.4386 
2025-10-01 07:12:02,949 - INFO - Recall :    0.0646 
2025-10-01 07:12:02,949 - INFO - ==========================================================================================
2025-10-01 07:12:02,983 - INFO -  No improvement: Current Val mAP50 (0.4804) < Best (0.4872)
2025-10-01 07:32:25,450 - INFO - Epoch 22 | Training Loss: 0.2011
2025-10-01 07:32:25,451 - INFO - Learning rate updated to: 0.000050
2025-10-01 07:36:20,643 - INFO - ==========================================================================================
2025-10-01 07:36:20,644 - INFO - VAL Set Metrics:
2025-10-01 07:36:20,644 - INFO - mAP50 :  0.4798 
2025-10-01 07:36:20,644 - INFO - mAP50-95 : 0.3848
2025-10-01 07:36:20,645 - INFO - Precision : 0.4746 
2025-10-01 07:36:20,645 - INFO - Recall :    0.0645 
2025-10-01 07:36:20,645 - INFO - ==========================================================================================
2025-10-01 07:36:20,674 - INFO -  No improvement: Current Val mAP50 (0.4798) < Best (0.4872)
2025-10-01 07:56:54,461 - INFO - Epoch 23 | Training Loss: 0.2119
2025-10-01 07:56:54,463 - INFO - Learning rate updated to: 0.000050
2025-10-01 08:00:49,447 - INFO - ==========================================================================================
2025-10-01 08:00:49,447 - INFO - VAL Set Metrics:
2025-10-01 08:00:49,447 - INFO - mAP50 :  0.4821 
2025-10-01 08:00:49,448 - INFO - mAP50-95 : 0.3876
2025-10-01 08:00:49,448 - INFO - Precision : 0.4757 
2025-10-01 08:00:49,448 - INFO - Recall :    0.0648 
2025-10-01 08:00:49,449 - INFO - ==========================================================================================
2025-10-01 08:00:49,489 - INFO -  No improvement: Current Val mAP50 (0.4821) < Best (0.4872)
2025-10-01 08:21:18,567 - INFO - Epoch 24 | Training Loss: 0.2023
2025-10-01 08:21:18,568 - INFO - Learning rate updated to: 0.000050
2025-10-01 08:25:12,918 - INFO - ==========================================================================================
2025-10-01 08:25:12,919 - INFO - VAL Set Metrics:
2025-10-01 08:25:12,919 - INFO - mAP50 :  0.4838 
2025-10-01 08:25:12,919 - INFO - mAP50-95 : 0.3887
2025-10-01 08:25:12,919 - INFO - Precision : 0.4211 
2025-10-01 08:25:12,919 - INFO - Recall :    0.0649 
2025-10-01 08:25:12,920 - INFO - ==========================================================================================
2025-10-01 08:25:12,960 - INFO -  No improvement: Current Val mAP50 (0.4838) < Best (0.4872)
2025-10-01 08:45:42,134 - INFO - Epoch 25 | Training Loss: 0.2116
2025-10-01 08:45:42,148 - INFO - Learning rate updated to: 0.000050
2025-10-01 08:49:37,846 - INFO - ==========================================================================================
2025-10-01 08:49:37,846 - INFO - VAL Set Metrics:
2025-10-01 08:49:37,847 - INFO - mAP50 :  0.4843 
2025-10-01 08:49:37,847 - INFO - mAP50-95 : 0.3891
2025-10-01 08:49:37,847 - INFO - Precision : 0.3580 
2025-10-01 08:49:37,847 - INFO - Recall :    0.0652 
2025-10-01 08:49:37,848 - INFO - ==========================================================================================
2025-10-01 08:49:37,884 - INFO -  No improvement: Current Val mAP50 (0.4843) < Best (0.4872)
2025-10-01 09:09:59,541 - INFO - Epoch 26 | Training Loss: 0.1930
2025-10-01 09:09:59,543 - INFO - Learning rate updated to: 0.000050
2025-10-01 09:13:55,324 - INFO - ==========================================================================================
2025-10-01 09:13:55,325 - INFO - VAL Set Metrics:
2025-10-01 09:13:55,325 - INFO - mAP50 :  0.4784 
2025-10-01 09:13:55,325 - INFO - mAP50-95 : 0.3847
2025-10-01 09:13:55,326 - INFO - Precision : 0.3712 
2025-10-01 09:13:55,326 - INFO - Recall :    0.0645 
2025-10-01 09:13:55,326 - INFO - ==========================================================================================
2025-10-01 09:13:55,351 - INFO -  No improvement: Current Val mAP50 (0.4784) < Best (0.4872)
2025-10-01 09:33:54,702 - INFO - Epoch 27 | Training Loss: 0.2044
2025-10-01 09:33:54,703 - INFO - Learning rate updated to: 0.000050
2025-10-01 09:37:42,002 - INFO - ==========================================================================================
2025-10-01 09:37:42,003 - INFO - VAL Set Metrics:
2025-10-01 09:37:42,003 - INFO - mAP50 :  0.4856 
2025-10-01 09:37:42,003 - INFO - mAP50-95 : 0.3918
2025-10-01 09:37:42,004 - INFO - Precision : 0.4803 
2025-10-01 09:37:42,004 - INFO - Recall :    0.0649 
2025-10-01 09:37:42,004 - INFO - ==========================================================================================
2025-10-01 09:37:42,041 - INFO -  No improvement: Current Val mAP50 (0.4856) < Best (0.4872)
2025-10-01 09:57:20,086 - INFO - Epoch 28 | Training Loss: 0.1913
2025-10-01 09:57:20,087 - INFO - Learning rate updated to: 0.000050
2025-10-01 10:01:04,555 - INFO - ==========================================================================================
2025-10-01 10:01:04,555 - INFO - VAL Set Metrics:
2025-10-01 10:01:04,555 - INFO - mAP50 :  0.4831 
2025-10-01 10:01:04,555 - INFO - mAP50-95 : 0.3896
2025-10-01 10:01:04,556 - INFO - Precision : 0.4275 
2025-10-01 10:01:04,556 - INFO - Recall :    0.0650 
2025-10-01 10:01:04,556 - INFO - ==========================================================================================
2025-10-01 10:01:04,597 - INFO -  No improvement: Current Val mAP50 (0.4831) < Best (0.4872)
2025-10-01 10:20:30,590 - INFO - Epoch 29 | Training Loss: 0.1891
2025-10-01 10:20:30,591 - INFO - Learning rate updated to: 0.000050
2025-10-01 10:24:15,042 - INFO - ==========================================================================================
2025-10-01 10:24:15,043 - INFO - VAL Set Metrics:
2025-10-01 10:24:15,043 - INFO - mAP50 :  0.4876 
2025-10-01 10:24:15,044 - INFO - mAP50-95 : 0.3934
2025-10-01 10:24:15,044 - INFO - Precision : 0.4610 
2025-10-01 10:24:15,044 - INFO - Recall :    0.0652 
2025-10-01 10:24:15,045 - INFO - ==========================================================================================
2025-10-01 10:24:15,884 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 10:43:46,612 - INFO - Epoch 30 | Training Loss: 0.1889
2025-10-01 10:43:46,613 - INFO - Learning rate updated to: 0.000025
2025-10-01 10:48:07,865 - INFO - ==========================================================================================
2025-10-01 10:48:07,865 - INFO - VAL Set Metrics:
2025-10-01 10:48:07,865 - INFO - mAP50 :  0.4803 
2025-10-01 10:48:07,866 - INFO - mAP50-95 : 0.3926
2025-10-01 10:48:07,866 - INFO - Precision : 0.3510 
2025-10-01 10:48:07,867 - INFO - Recall :    0.0649 
2025-10-01 10:48:07,867 - INFO - ==========================================================================================
2025-10-01 10:48:07,901 - INFO -  No improvement: Current Val mAP50 (0.4803) < Best (0.4876)
2025-10-01 11:07:32,526 - INFO - Epoch 31 | Training Loss: 0.1898
2025-10-01 11:07:32,527 - INFO - Learning rate updated to: 0.000025
2025-10-01 11:11:11,617 - INFO - ==========================================================================================
2025-10-01 11:11:11,618 - INFO - VAL Set Metrics:
2025-10-01 11:11:11,618 - INFO - mAP50 :  0.4876 
2025-10-01 11:11:11,618 - INFO - mAP50-95 : 0.4024
2025-10-01 11:11:11,618 - INFO - Precision : 0.4631 
2025-10-01 11:11:11,618 - INFO - Recall :    0.0652 
2025-10-01 11:11:11,619 - INFO - ==========================================================================================
2025-10-01 11:11:12,404 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 11:31:06,533 - INFO - Epoch 32 | Training Loss: 0.1859
2025-10-01 11:31:06,534 - INFO - Learning rate updated to: 0.000025
2025-10-01 11:34:48,012 - INFO - ==========================================================================================
2025-10-01 11:34:48,013 - INFO - VAL Set Metrics:
2025-10-01 11:34:48,013 - INFO - mAP50 :  0.4877 
2025-10-01 11:34:48,013 - INFO - mAP50-95 : 0.3979
2025-10-01 11:34:48,013 - INFO - Precision : 0.4560 
2025-10-01 11:34:48,014 - INFO - Recall :    0.0652 
2025-10-01 11:34:48,014 - INFO - ==========================================================================================
2025-10-01 11:34:48,823 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 11:54:06,207 - INFO - Epoch 33 | Training Loss: 0.1853
2025-10-01 11:54:06,208 - INFO - Learning rate updated to: 0.000025
2025-10-01 11:57:52,935 - INFO - ==========================================================================================
2025-10-01 11:57:52,935 - INFO - VAL Set Metrics:
2025-10-01 11:57:52,936 - INFO - mAP50 :  0.4879 
2025-10-01 11:57:52,936 - INFO - mAP50-95 : 0.4008
2025-10-01 11:57:52,936 - INFO - Precision : 0.4368 
2025-10-01 11:57:52,936 - INFO - Recall :    0.0654 
2025-10-01 11:57:52,936 - INFO - ==========================================================================================
2025-10-01 11:57:53,747 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 12:17:50,797 - INFO - Epoch 34 | Training Loss: 0.1815
2025-10-01 12:17:50,798 - INFO - Learning rate updated to: 0.000025
2025-10-01 12:21:41,593 - INFO - ==========================================================================================
2025-10-01 12:21:41,593 - INFO - VAL Set Metrics:
2025-10-01 12:21:41,593 - INFO - mAP50 :  0.4875 
2025-10-01 12:21:41,593 - INFO - mAP50-95 : 0.4007
2025-10-01 12:21:41,594 - INFO - Precision : 0.4732 
2025-10-01 12:21:41,594 - INFO - Recall :    0.0649 
2025-10-01 12:21:41,594 - INFO - ==========================================================================================
2025-10-01 12:21:41,623 - INFO -  No improvement: Current Val mAP50 (0.4875) < Best (0.4879)
2025-10-01 12:41:31,212 - INFO - Epoch 35 | Training Loss: 0.1831
2025-10-01 12:41:31,213 - INFO - Learning rate updated to: 0.000025
2025-10-01 12:45:19,164 - INFO - ==========================================================================================
2025-10-01 12:45:19,164 - INFO - VAL Set Metrics:
2025-10-01 12:45:19,165 - INFO - mAP50 :  0.4869 
2025-10-01 12:45:19,165 - INFO - mAP50-95 : 0.4001
2025-10-01 12:45:19,165 - INFO - Precision : 0.4787 
2025-10-01 12:45:19,166 - INFO - Recall :    0.0650 
2025-10-01 12:45:19,166 - INFO - ==========================================================================================
2025-10-01 12:45:19,191 - INFO -  No improvement: Current Val mAP50 (0.4869) < Best (0.4879)
2025-10-01 13:04:29,788 - INFO - Epoch 36 | Training Loss: 0.1793
2025-10-01 13:04:29,788 - INFO - Learning rate updated to: 0.000025
2025-10-01 13:08:14,385 - INFO - ==========================================================================================
2025-10-01 13:08:14,385 - INFO - VAL Set Metrics:
2025-10-01 13:08:14,385 - INFO - mAP50 :  0.4873 
2025-10-01 13:08:14,385 - INFO - mAP50-95 : 0.3994
2025-10-01 13:08:14,386 - INFO - Precision : 0.4860 
2025-10-01 13:08:14,386 - INFO - Recall :    0.0652 
2025-10-01 13:08:14,386 - INFO - ==========================================================================================
2025-10-01 13:08:14,419 - INFO -  No improvement: Current Val mAP50 (0.4873) < Best (0.4879)
2025-10-01 13:27:18,631 - INFO - Epoch 37 | Training Loss: 0.1778
2025-10-01 13:27:18,632 - INFO - Learning rate updated to: 0.000025
2025-10-01 13:31:00,025 - INFO - ==========================================================================================
2025-10-01 13:31:00,025 - INFO - VAL Set Metrics:
2025-10-01 13:31:00,026 - INFO - mAP50 :  0.4855 
2025-10-01 13:31:00,026 - INFO - mAP50-95 : 0.4024
2025-10-01 13:31:00,026 - INFO - Precision : 0.4502 
2025-10-01 13:31:00,027 - INFO - Recall :    0.0652 
2025-10-01 13:31:00,027 - INFO - ==========================================================================================
2025-10-01 13:31:00,082 - INFO -  No improvement: Current Val mAP50 (0.4855) < Best (0.4879)
2025-10-01 13:50:03,538 - INFO - Epoch 38 | Training Loss: 0.1781
2025-10-01 13:50:03,539 - INFO - Learning rate updated to: 0.000025
2025-10-01 13:53:48,782 - INFO - ==========================================================================================
2025-10-01 13:53:48,782 - INFO - VAL Set Metrics:
2025-10-01 13:53:48,782 - INFO - mAP50 :  0.4867 
2025-10-01 13:53:48,782 - INFO - mAP50-95 : 0.4050
2025-10-01 13:53:48,783 - INFO - Precision : 0.4115 
2025-10-01 13:53:48,783 - INFO - Recall :    0.0653 
2025-10-01 13:53:48,783 - INFO - ==========================================================================================
2025-10-01 13:53:48,826 - INFO -  No improvement: Current Val mAP50 (0.4867) < Best (0.4879)
2025-10-01 14:14:47,869 - INFO - Epoch 39 | Training Loss: 0.1759
2025-10-01 14:14:47,870 - INFO - Learning rate updated to: 0.000025
2025-10-01 14:19:01,541 - INFO - ==========================================================================================
2025-10-01 14:19:01,541 - INFO - VAL Set Metrics:
2025-10-01 14:19:01,541 - INFO - mAP50 :  0.4915 
2025-10-01 14:19:01,542 - INFO - mAP50-95 : 0.4087
2025-10-01 14:19:01,542 - INFO - Precision : 0.5152 
2025-10-01 14:19:01,542 - INFO - Recall :    0.0654 
2025-10-01 14:19:01,542 - INFO - ==========================================================================================
2025-10-01 14:19:02,345 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 14:38:52,795 - INFO - Epoch 40 | Training Loss: 0.1769
2025-10-01 14:38:52,796 - INFO - Learning rate updated to: 0.000025
2025-10-01 14:42:38,124 - INFO - ==========================================================================================
2025-10-01 14:42:38,125 - INFO - VAL Set Metrics:
2025-10-01 14:42:38,125 - INFO - mAP50 :  0.4869 
2025-10-01 14:42:38,125 - INFO - mAP50-95 : 0.4046
2025-10-01 14:42:38,125 - INFO - Precision : 0.4065 
2025-10-01 14:42:38,125 - INFO - Recall :    0.0651 
2025-10-01 14:42:38,126 - INFO - ==========================================================================================
2025-10-01 14:42:38,157 - INFO -  No improvement: Current Val mAP50 (0.4869) < Best (0.4915)
2025-10-01 15:01:56,009 - INFO - Epoch 41 | Training Loss: 0.1746
2025-10-01 15:01:56,009 - INFO - Learning rate updated to: 0.000025
2025-10-01 15:05:41,736 - INFO - ==========================================================================================
2025-10-01 15:05:41,736 - INFO - VAL Set Metrics:
2025-10-01 15:05:41,737 - INFO - mAP50 :  0.4852 
2025-10-01 15:05:41,737 - INFO - mAP50-95 : 0.4002
2025-10-01 15:05:41,737 - INFO - Precision : 0.4381 
2025-10-01 15:05:41,737 - INFO - Recall :    0.0653 
2025-10-01 15:05:41,737 - INFO - ==========================================================================================
2025-10-01 15:05:41,771 - INFO -  No improvement: Current Val mAP50 (0.4852) < Best (0.4915)
2025-10-01 15:25:05,330 - INFO - Epoch 42 | Training Loss: 0.1711
2025-10-01 15:25:05,331 - INFO - Learning rate updated to: 0.000025
2025-10-01 15:28:58,384 - INFO - ==========================================================================================
2025-10-01 15:28:58,384 - INFO - VAL Set Metrics:
2025-10-01 15:28:58,384 - INFO - mAP50 :  0.4880 
2025-10-01 15:28:58,384 - INFO - mAP50-95 : 0.4043
2025-10-01 15:28:58,385 - INFO - Precision : 0.5338 
2025-10-01 15:28:58,385 - INFO - Recall :    0.0652 
2025-10-01 15:28:58,385 - INFO - ==========================================================================================
2025-10-01 15:28:58,418 - INFO -  No improvement: Current Val mAP50 (0.4880) < Best (0.4915)
2025-10-01 15:48:42,626 - INFO - Epoch 43 | Training Loss: 0.1817
2025-10-01 15:48:42,627 - INFO - Learning rate updated to: 0.000025
2025-10-01 15:52:33,469 - INFO - ==========================================================================================
2025-10-01 15:52:33,470 - INFO - VAL Set Metrics:
2025-10-01 15:52:33,470 - INFO - mAP50 :  0.4879 
2025-10-01 15:52:33,470 - INFO - mAP50-95 : 0.4028
2025-10-01 15:52:33,471 - INFO - Precision : 0.4866 
2025-10-01 15:52:33,471 - INFO - Recall :    0.0652 
2025-10-01 15:52:33,471 - INFO - ==========================================================================================
2025-10-01 15:52:33,506 - INFO -  No improvement: Current Val mAP50 (0.4879) < Best (0.4915)
2025-10-01 16:12:23,745 - INFO - Epoch 44 | Training Loss: 0.1712
2025-10-01 16:12:23,746 - INFO - Learning rate updated to: 0.000025
2025-10-01 16:16:21,974 - INFO - ==========================================================================================
2025-10-01 16:16:21,974 - INFO - VAL Set Metrics:
2025-10-01 16:16:21,975 - INFO - mAP50 :  0.4883 
2025-10-01 16:16:21,975 - INFO - mAP50-95 : 0.4049
2025-10-01 16:16:21,975 - INFO - Precision : 0.4817 
2025-10-01 16:16:21,975 - INFO - Recall :    0.0651 
2025-10-01 16:16:21,976 - INFO - ==========================================================================================
2025-10-01 16:16:22,013 - INFO -  No improvement: Current Val mAP50 (0.4883) < Best (0.4915)
2025-10-01 16:36:47,009 - INFO - Epoch 45 | Training Loss: 0.1717
2025-10-01 16:36:47,010 - INFO - Learning rate updated to: 0.000013
2025-10-01 16:40:55,412 - INFO - ==========================================================================================
2025-10-01 16:40:55,412 - INFO - VAL Set Metrics:
2025-10-01 16:40:55,413 - INFO - mAP50 :  0.4891 
2025-10-01 16:40:55,413 - INFO - mAP50-95 : 0.4086
2025-10-01 16:40:55,413 - INFO - Precision : 0.4067 
2025-10-01 16:40:55,413 - INFO - Recall :    0.0655 
2025-10-01 16:40:55,414 - INFO - ==========================================================================================
2025-10-01 16:40:55,447 - INFO -  No improvement: Current Val mAP50 (0.4891) < Best (0.4915)
2025-10-01 17:01:31,465 - INFO - Epoch 46 | Training Loss: 0.1703
2025-10-01 17:01:31,467 - INFO - Learning rate updated to: 0.000013
2025-10-01 17:05:32,860 - INFO - ==========================================================================================
2025-10-01 17:05:32,861 - INFO - VAL Set Metrics:
2025-10-01 17:05:32,861 - INFO - mAP50 :  0.4883 
2025-10-01 17:05:32,861 - INFO - mAP50-95 : 0.4065
2025-10-01 17:05:32,862 - INFO - Precision : 0.4293 
2025-10-01 17:05:32,862 - INFO - Recall :    0.0652 
2025-10-01 17:05:32,862 - INFO - ==========================================================================================
2025-10-01 17:05:32,895 - INFO -  No improvement: Current Val mAP50 (0.4883) < Best (0.4915)
2025-10-01 17:27:23,503 - INFO - Epoch 47 | Training Loss: 0.1673
2025-10-01 17:27:23,504 - INFO - Learning rate updated to: 0.000013
2025-10-01 17:31:29,031 - INFO - ==========================================================================================
2025-10-01 17:31:29,032 - INFO - VAL Set Metrics:
2025-10-01 17:31:29,032 - INFO - mAP50 :  0.4891 
2025-10-01 17:31:29,032 - INFO - mAP50-95 : 0.4083
2025-10-01 17:31:29,032 - INFO - Precision : 0.4587 
2025-10-01 17:31:29,032 - INFO - Recall :    0.0653 
2025-10-01 17:31:29,032 - INFO - ==========================================================================================
2025-10-01 17:31:29,065 - INFO -  No improvement: Current Val mAP50 (0.4891) < Best (0.4915)
2025-10-01 17:51:14,368 - INFO - Epoch 48 | Training Loss: 0.1698
2025-10-01 17:51:14,369 - INFO - Learning rate updated to: 0.000013
2025-10-01 17:55:01,059 - INFO - ==========================================================================================
2025-10-01 17:55:01,060 - INFO - VAL Set Metrics:
2025-10-01 17:55:01,060 - INFO - mAP50 :  0.4892 
2025-10-01 17:55:01,060 - INFO - mAP50-95 : 0.4097
2025-10-01 17:55:01,061 - INFO - Precision : 0.5035 
2025-10-01 17:55:01,061 - INFO - Recall :    0.0653 
2025-10-01 17:55:01,061 - INFO - ==========================================================================================
2025-10-01 17:55:01,088 - INFO -  No improvement: Current Val mAP50 (0.4892) < Best (0.4915)
2025-10-01 18:14:52,052 - INFO - Epoch 49 | Training Loss: 0.1656
2025-10-01 18:14:52,053 - INFO - Learning rate updated to: 0.000013
2025-10-01 18:18:37,110 - INFO - ==========================================================================================
2025-10-01 18:18:37,111 - INFO - VAL Set Metrics:
2025-10-01 18:18:37,111 - INFO - mAP50 :  0.4877 
2025-10-01 18:18:37,112 - INFO - mAP50-95 : 0.4070
2025-10-01 18:18:37,112 - INFO - Precision : 0.4402 
2025-10-01 18:18:37,112 - INFO - Recall :    0.0652 
2025-10-01 18:18:37,112 - INFO - ==========================================================================================
2025-10-01 18:18:37,149 - INFO -  No improvement: Current Val mAP50 (0.4877) < Best (0.4915)
2025-10-01 18:38:02,472 - INFO - Epoch 50 | Training Loss: 0.1659
2025-10-01 18:38:02,473 - INFO - Learning rate updated to: 0.000013
2025-10-01 18:41:46,834 - INFO - ==========================================================================================
2025-10-01 18:41:46,835 - INFO - VAL Set Metrics:
2025-10-01 18:41:46,835 - INFO - mAP50 :  0.4910 
2025-10-01 18:41:46,835 - INFO - mAP50-95 : 0.4105
2025-10-01 18:41:46,836 - INFO - Precision : 0.4976 
2025-10-01 18:41:46,836 - INFO - Recall :    0.0654 
2025-10-01 18:41:46,836 - INFO - ==========================================================================================
2025-10-01 18:41:46,866 - INFO -  No improvement: Current Val mAP50 (0.4910) < Best (0.4915)
2025-10-01 19:00:59,600 - INFO - Epoch 51 | Training Loss: 0.1678
2025-10-01 19:00:59,601 - INFO - Learning rate updated to: 0.000013
2025-10-01 19:04:46,099 - INFO - ==========================================================================================
2025-10-01 19:04:46,100 - INFO - VAL Set Metrics:
2025-10-01 19:04:46,100 - INFO - mAP50 :  0.4902 
2025-10-01 19:04:46,100 - INFO - mAP50-95 : 0.4090
2025-10-01 19:04:46,101 - INFO - Precision : 0.4639 
2025-10-01 19:04:46,101 - INFO - Recall :    0.0655 
2025-10-01 19:04:46,101 - INFO - ==========================================================================================
2025-10-01 19:04:46,133 - INFO -  No improvement: Current Val mAP50 (0.4902) < Best (0.4915)
2025-10-01 19:24:00,490 - INFO - Epoch 52 | Training Loss: 0.1641
2025-10-01 19:24:00,491 - INFO - Learning rate updated to: 0.000013
2025-10-01 19:27:44,776 - INFO - ==========================================================================================
2025-10-01 19:27:44,777 - INFO - VAL Set Metrics:
2025-10-01 19:27:44,777 - INFO - mAP50 :  0.4886 
2025-10-01 19:27:44,777 - INFO - mAP50-95 : 0.4056
2025-10-01 19:27:44,777 - INFO - Precision : 0.4309 
2025-10-01 19:27:44,777 - INFO - Recall :    0.0653 
2025-10-01 19:27:44,778 - INFO - ==========================================================================================
2025-10-01 19:27:44,807 - INFO -  No improvement: Current Val mAP50 (0.4886) < Best (0.4915)
2025-10-01 19:46:53,866 - INFO - Epoch 53 | Training Loss: 0.1631
2025-10-01 19:46:53,867 - INFO - Learning rate updated to: 0.000013
2025-10-01 19:50:39,281 - INFO - ==========================================================================================
2025-10-01 19:50:39,281 - INFO - VAL Set Metrics:
2025-10-01 19:50:39,282 - INFO - mAP50 :  0.4882 
2025-10-01 19:50:39,282 - INFO - mAP50-95 : 0.4093
2025-10-01 19:50:39,282 - INFO - Precision : 0.4364 
2025-10-01 19:50:39,282 - INFO - Recall :    0.0655 
2025-10-01 19:50:39,283 - INFO - ==========================================================================================
2025-10-01 19:50:39,318 - INFO -  No improvement: Current Val mAP50 (0.4882) < Best (0.4915)
2025-10-01 20:09:51,026 - INFO - Epoch 54 | Training Loss: 0.1621
2025-10-01 20:09:51,027 - INFO - Learning rate updated to: 0.000013
2025-10-01 20:13:35,239 - INFO - ==========================================================================================
2025-10-01 20:13:35,239 - INFO - VAL Set Metrics:
2025-10-01 20:13:35,239 - INFO - mAP50 :  0.4882 
2025-10-01 20:13:35,240 - INFO - mAP50-95 : 0.4076
2025-10-01 20:13:35,240 - INFO - Precision : 0.5209 
2025-10-01 20:13:35,240 - INFO - Recall :    0.0653 
2025-10-01 20:13:35,241 - INFO - ==========================================================================================
2025-10-01 20:13:35,280 - INFO -  No improvement: Current Val mAP50 (0.4882) < Best (0.4915)
2025-10-01 20:32:48,974 - INFO - Epoch 55 | Training Loss: 0.1612
2025-10-01 20:32:48,975 - INFO - Learning rate updated to: 0.000013
2025-10-01 20:36:34,017 - INFO - ==========================================================================================
2025-10-01 20:36:34,018 - INFO - VAL Set Metrics:
2025-10-01 20:36:34,018 - INFO - mAP50 :  0.4874 
2025-10-01 20:36:34,018 - INFO - mAP50-95 : 0.4078
2025-10-01 20:36:34,018 - INFO - Precision : 0.4355 
2025-10-01 20:36:34,019 - INFO - Recall :    0.0654 
2025-10-01 20:36:34,019 - INFO - ==========================================================================================
2025-10-01 20:36:34,058 - INFO -  No improvement: Current Val mAP50 (0.4874) < Best (0.4915)
2025-10-01 20:55:40,803 - INFO - Epoch 56 | Training Loss: 0.1623
2025-10-01 20:55:40,804 - INFO - Learning rate updated to: 0.000013
2025-10-01 20:59:26,756 - INFO - ==========================================================================================
2025-10-01 20:59:26,756 - INFO - VAL Set Metrics:
2025-10-01 20:59:26,756 - INFO - mAP50 :  0.4881 
2025-10-01 20:59:26,757 - INFO - mAP50-95 : 0.4083
2025-10-01 20:59:26,757 - INFO - Precision : 0.5004 
2025-10-01 20:59:26,757 - INFO - Recall :    0.0653 
2025-10-01 20:59:26,758 - INFO - ==========================================================================================
2025-10-01 20:59:26,791 - INFO -  No improvement: Current Val mAP50 (0.4881) < Best (0.4915)
2025-10-01 21:19:58,204 - INFO - Epoch 57 | Training Loss: 0.1615
2025-10-01 21:19:58,205 - INFO - Learning rate updated to: 0.000013
2025-10-01 21:24:06,111 - INFO - ==========================================================================================
2025-10-01 21:24:06,111 - INFO - VAL Set Metrics:
2025-10-01 21:24:06,111 - INFO - mAP50 :  0.4866 
2025-10-01 21:24:06,112 - INFO - mAP50-95 : 0.4087
2025-10-01 21:24:06,112 - INFO - Precision : 0.4425 
2025-10-01 21:24:06,113 - INFO - Recall :    0.0654 
2025-10-01 21:24:06,113 - INFO - ==========================================================================================
2025-10-01 21:24:06,143 - INFO -  No improvement: Current Val mAP50 (0.4866) < Best (0.4915)
2025-10-01 21:25:32,513 - INFO - Using device: cuda
2025-10-01 21:25:32,513 - INFO - Loading split dataset (train/val/test)...
2025-10-01 21:25:32,563 - INFO - Split dataset loaded successfully!
2025-10-01 21:25:32,563 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-01 21:25:32,563 - INFO - Initializing adaptive fusion model...
2025-10-01 21:25:33,191 - INFO -  Starting cattle detection training...
2025-10-01 21:46:23,020 - INFO - Epoch 1 | Training Loss: 1.6732
2025-10-01 21:50:25,630 - INFO - ==========================================================================================
2025-10-01 21:50:25,631 - INFO - VAL Set Metrics:
2025-10-01 21:50:25,631 - INFO - mAP50 :  0.2723 
2025-10-01 21:50:25,631 - INFO - mAP50-95 : 0.1109
2025-10-01 21:50:25,631 - INFO - Precision : 0.1830 
2025-10-01 21:50:25,631 - INFO - Recall :    0.0482 
2025-10-01 21:50:25,632 - INFO - ==========================================================================================
2025-10-01 21:50:26,463 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 22:11:08,090 - INFO - Epoch 2 | Training Loss: 0.3414
2025-10-01 22:15:13,316 - INFO - ==========================================================================================
2025-10-01 22:15:13,317 - INFO - VAL Set Metrics:
2025-10-01 22:15:13,317 - INFO - mAP50 :  0.3718 
2025-10-01 22:15:13,317 - INFO - mAP50-95 : 0.2049
2025-10-01 22:15:13,317 - INFO - Precision : 0.2383 
2025-10-01 22:15:13,317 - INFO - Recall :    0.0551 
2025-10-01 22:15:13,317 - INFO - ==========================================================================================
2025-10-01 22:15:14,116 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 22:35:53,887 - INFO - Epoch 3 | Training Loss: 0.2593
2025-10-01 22:39:56,969 - INFO - ==========================================================================================
2025-10-01 22:39:56,969 - INFO - VAL Set Metrics:
2025-10-01 22:39:56,970 - INFO - mAP50 :  0.4218 
2025-10-01 22:39:56,970 - INFO - mAP50-95 : 0.2753
2025-10-01 22:39:56,970 - INFO - Precision : 0.3021 
2025-10-01 22:39:56,971 - INFO - Recall :    0.0595 
2025-10-01 22:39:56,971 - INFO - ==========================================================================================
2025-10-01 22:39:57,763 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 23:00:44,243 - INFO - Epoch 4 | Training Loss: 0.2285
2025-10-01 23:04:50,129 - INFO - ==========================================================================================
2025-10-01 23:04:50,130 - INFO - VAL Set Metrics:
2025-10-01 23:04:50,130 - INFO - mAP50 :  0.4461 
2025-10-01 23:04:50,130 - INFO - mAP50-95 : 0.2959
2025-10-01 23:04:50,130 - INFO - Precision : 0.4381 
2025-10-01 23:04:50,131 - INFO - Recall :    0.0614 
2025-10-01 23:04:50,131 - INFO - ==========================================================================================
2025-10-01 23:04:50,944 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 23:25:49,014 - INFO - Epoch 5 | Training Loss: 0.2118
2025-10-01 23:29:55,091 - INFO - ==========================================================================================
2025-10-01 23:29:55,091 - INFO - VAL Set Metrics:
2025-10-01 23:29:55,092 - INFO - mAP50 :  0.4531 
2025-10-01 23:29:55,092 - INFO - mAP50-95 : 0.3125
2025-10-01 23:29:55,092 - INFO - Precision : 0.3721 
2025-10-01 23:29:55,092 - INFO - Recall :    0.0632 
2025-10-01 23:29:55,093 - INFO - ==========================================================================================
2025-10-01 23:29:55,881 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-01 23:52:12,011 - INFO - Epoch 6 | Training Loss: 0.2127
2025-10-01 23:56:47,560 - INFO - ==========================================================================================
2025-10-01 23:56:47,560 - INFO - VAL Set Metrics:
2025-10-01 23:56:47,560 - INFO - mAP50 :  0.4625 
2025-10-01 23:56:47,561 - INFO - mAP50-95 : 0.3250
2025-10-01 23:56:47,561 - INFO - Precision : 0.5201 
2025-10-01 23:56:47,561 - INFO - Recall :    0.0631 
2025-10-01 23:56:47,561 - INFO - ==========================================================================================
2025-10-01 23:56:48,466 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 00:18:53,187 - INFO - Epoch 7 | Training Loss: 0.1963
2025-10-02 00:22:59,863 - INFO - ==========================================================================================
2025-10-02 00:22:59,864 - INFO - VAL Set Metrics:
2025-10-02 00:22:59,864 - INFO - mAP50 :  0.4662 
2025-10-02 00:22:59,864 - INFO - mAP50-95 : 0.3400
2025-10-02 00:22:59,865 - INFO - Precision : 0.4142 
2025-10-02 00:22:59,865 - INFO - Recall :    0.0641 
2025-10-02 00:22:59,865 - INFO - ==========================================================================================
2025-10-02 00:23:00,686 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 00:43:59,546 - INFO - Epoch 8 | Training Loss: 0.2035
2025-10-02 00:48:05,162 - INFO - ==========================================================================================
2025-10-02 00:48:05,163 - INFO - VAL Set Metrics:
2025-10-02 00:48:05,163 - INFO - mAP50 :  0.4610 
2025-10-02 00:48:05,164 - INFO - mAP50-95 : 0.3315
2025-10-02 00:48:05,164 - INFO - Precision : 0.4723 
2025-10-02 00:48:05,164 - INFO - Recall :    0.0627 
2025-10-02 00:48:05,164 - INFO - ==========================================================================================
2025-10-02 00:48:05,197 - INFO -  No improvement: Current Val mAP50 (0.4610) < Best (0.4662)
2025-10-02 01:09:01,530 - INFO - Epoch 9 | Training Loss: 0.1855
2025-10-02 01:13:08,031 - INFO - ==========================================================================================
2025-10-02 01:13:08,031 - INFO - VAL Set Metrics:
2025-10-02 01:13:08,032 - INFO - mAP50 :  0.4785 
2025-10-02 01:13:08,032 - INFO - mAP50-95 : 0.3537
2025-10-02 01:13:08,032 - INFO - Precision : 0.3810 
2025-10-02 01:13:08,033 - INFO - Recall :    0.0648 
2025-10-02 01:13:08,033 - INFO - ==========================================================================================
2025-10-02 01:13:08,879 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 01:34:07,823 - INFO - Epoch 10 | Training Loss: 0.1815
2025-10-02 01:38:14,146 - INFO - ==========================================================================================
2025-10-02 01:38:14,146 - INFO - VAL Set Metrics:
2025-10-02 01:38:14,147 - INFO - mAP50 :  0.4764 
2025-10-02 01:38:14,147 - INFO - mAP50-95 : 0.3526
2025-10-02 01:38:14,147 - INFO - Precision : 0.4518 
2025-10-02 01:38:14,147 - INFO - Recall :    0.0642 
2025-10-02 01:38:14,148 - INFO - ==========================================================================================
2025-10-02 01:38:14,191 - INFO -  No improvement: Current Val mAP50 (0.4764) < Best (0.4785)
2025-10-02 01:59:06,434 - INFO - Epoch 11 | Training Loss: 0.1765
2025-10-02 02:03:33,359 - INFO - ==========================================================================================
2025-10-02 02:03:33,359 - INFO - VAL Set Metrics:
2025-10-02 02:03:33,359 - INFO - mAP50 :  0.4789 
2025-10-02 02:03:33,360 - INFO - mAP50-95 : 0.3560
2025-10-02 02:03:33,360 - INFO - Precision : 0.3780 
2025-10-02 02:03:33,360 - INFO - Recall :    0.0650 
2025-10-02 02:03:33,361 - INFO - ==========================================================================================
2025-10-02 02:03:34,091 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 02:27:01,289 - INFO - Epoch 12 | Training Loss: 0.1760
2025-10-02 02:31:32,536 - INFO - ==========================================================================================
2025-10-02 02:31:32,536 - INFO - VAL Set Metrics:
2025-10-02 02:31:32,536 - INFO - mAP50 :  0.4784 
2025-10-02 02:31:32,536 - INFO - mAP50-95 : 0.3620
2025-10-02 02:31:32,536 - INFO - Precision : 0.5471 
2025-10-02 02:31:32,537 - INFO - Recall :    0.0645 
2025-10-02 02:31:32,537 - INFO - ==========================================================================================
2025-10-02 02:31:32,577 - INFO -  No improvement: Current Val mAP50 (0.4784) < Best (0.4789)
2025-10-02 02:52:29,850 - INFO - Epoch 13 | Training Loss: 0.1749
2025-10-02 02:56:36,630 - INFO - ==========================================================================================
2025-10-02 02:56:36,631 - INFO - VAL Set Metrics:
2025-10-02 02:56:36,631 - INFO - mAP50 :  0.4823 
2025-10-02 02:56:36,631 - INFO - mAP50-95 : 0.3698
2025-10-02 02:56:36,632 - INFO - Precision : 0.3916 
2025-10-02 02:56:36,632 - INFO - Recall :    0.0648 
2025-10-02 02:56:36,632 - INFO - ==========================================================================================
2025-10-02 02:56:37,461 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 03:17:44,191 - INFO - Epoch 14 | Training Loss: 0.1726
2025-10-02 03:21:50,508 - INFO - ==========================================================================================
2025-10-02 03:21:50,508 - INFO - VAL Set Metrics:
2025-10-02 03:21:50,508 - INFO - mAP50 :  0.4829 
2025-10-02 03:21:50,509 - INFO - mAP50-95 : 0.3731
2025-10-02 03:21:50,509 - INFO - Precision : 0.3387 
2025-10-02 03:21:50,509 - INFO - Recall :    0.0653 
2025-10-02 03:21:50,509 - INFO - ==========================================================================================
2025-10-02 03:21:51,373 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 03:42:58,708 - INFO - Epoch 15 | Training Loss: 0.1708
2025-10-02 03:47:04,347 - INFO - ==========================================================================================
2025-10-02 03:47:04,348 - INFO - VAL Set Metrics:
2025-10-02 03:47:04,348 - INFO - mAP50 :  0.4750 
2025-10-02 03:47:04,348 - INFO - mAP50-95 : 0.3689
2025-10-02 03:47:04,349 - INFO - Precision : 0.4160 
2025-10-02 03:47:04,349 - INFO - Recall :    0.0644 
2025-10-02 03:47:04,349 - INFO - ==========================================================================================
2025-10-02 03:47:04,388 - INFO -  No improvement: Current Val mAP50 (0.4750) < Best (0.4829)
2025-10-02 04:08:04,075 - INFO - Epoch 16 | Training Loss: 0.1696
2025-10-02 04:12:10,779 - INFO - ==========================================================================================
2025-10-02 04:12:10,780 - INFO - VAL Set Metrics:
2025-10-02 04:12:10,780 - INFO - mAP50 :  0.4850 
2025-10-02 04:12:10,780 - INFO - mAP50-95 : 0.3804
2025-10-02 04:12:10,781 - INFO - Precision : 0.5032 
2025-10-02 04:12:10,781 - INFO - Recall :    0.0653 
2025-10-02 04:12:10,781 - INFO - ==========================================================================================
2025-10-02 04:12:11,609 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 04:33:22,407 - INFO - Epoch 17 | Training Loss: 0.1660
2025-10-02 04:37:30,846 - INFO - ==========================================================================================
2025-10-02 04:37:30,846 - INFO - VAL Set Metrics:
2025-10-02 04:37:30,847 - INFO - mAP50 :  0.4853 
2025-10-02 04:37:30,847 - INFO - mAP50-95 : 0.3846
2025-10-02 04:37:30,847 - INFO - Precision : 0.6055 
2025-10-02 04:37:30,847 - INFO - Recall :    0.0651 
2025-10-02 04:37:30,848 - INFO - ==========================================================================================
2025-10-02 04:37:31,687 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 04:58:42,203 - INFO - Epoch 18 | Training Loss: 0.1647
2025-10-02 05:02:49,811 - INFO - ==========================================================================================
2025-10-02 05:02:49,812 - INFO - VAL Set Metrics:
2025-10-02 05:02:49,812 - INFO - mAP50 :  0.4798 
2025-10-02 05:02:49,812 - INFO - mAP50-95 : 0.3825
2025-10-02 05:02:49,812 - INFO - Precision : 0.5354 
2025-10-02 05:02:49,813 - INFO - Recall :    0.0646 
2025-10-02 05:02:49,813 - INFO - ==========================================================================================
2025-10-02 05:02:49,837 - INFO -  No improvement: Current Val mAP50 (0.4798) < Best (0.4853)
2025-10-02 05:23:58,637 - INFO - Epoch 19 | Training Loss: 0.1649
2025-10-02 05:28:05,804 - INFO - ==========================================================================================
2025-10-02 05:28:05,805 - INFO - VAL Set Metrics:
2025-10-02 05:28:05,805 - INFO - mAP50 :  0.4818 
2025-10-02 05:28:05,805 - INFO - mAP50-95 : 0.3802
2025-10-02 05:28:05,806 - INFO - Precision : 0.4633 
2025-10-02 05:28:05,806 - INFO - Recall :    0.0648 
2025-10-02 05:28:05,806 - INFO - ==========================================================================================
2025-10-02 05:28:05,843 - INFO -  No improvement: Current Val mAP50 (0.4818) < Best (0.4853)
2025-10-02 05:49:13,455 - INFO - Epoch 20 | Training Loss: 0.1624
2025-10-02 05:53:22,454 - INFO - ==========================================================================================
2025-10-02 05:53:22,454 - INFO - VAL Set Metrics:
2025-10-02 05:53:22,455 - INFO - mAP50 :  0.4856 
2025-10-02 05:53:22,455 - INFO - mAP50-95 : 0.3921
2025-10-02 05:53:22,456 - INFO - Precision : 0.3832 
2025-10-02 05:53:22,456 - INFO - Recall :    0.0654 
2025-10-02 05:53:22,456 - INFO - ==========================================================================================
2025-10-02 05:53:23,180 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 06:14:40,636 - INFO - Epoch 21 | Training Loss: 0.1628
2025-10-02 06:18:47,551 - INFO - ==========================================================================================
2025-10-02 06:18:47,552 - INFO - VAL Set Metrics:
2025-10-02 06:18:47,552 - INFO - mAP50 :  0.4888 
2025-10-02 06:18:47,553 - INFO - mAP50-95 : 0.3942
2025-10-02 06:18:47,553 - INFO - Precision : 0.5586 
2025-10-02 06:18:47,553 - INFO - Recall :    0.0652 
2025-10-02 06:18:47,554 - INFO - ==========================================================================================
2025-10-02 06:18:48,431 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 06:39:59,121 - INFO - Epoch 22 | Training Loss: 0.1610
2025-10-02 06:44:05,932 - INFO - ==========================================================================================
2025-10-02 06:44:05,932 - INFO - VAL Set Metrics:
2025-10-02 06:44:05,933 - INFO - mAP50 :  0.4867 
2025-10-02 06:44:05,933 - INFO - mAP50-95 : 0.3842
2025-10-02 06:44:05,933 - INFO - Precision : 0.4591 
2025-10-02 06:44:05,934 - INFO - Recall :    0.0654 
2025-10-02 06:44:05,934 - INFO - ==========================================================================================
2025-10-02 06:44:05,972 - INFO -  No improvement: Current Val mAP50 (0.4867) < Best (0.4888)
2025-10-02 07:05:16,473 - INFO - Epoch 23 | Training Loss: 0.1588
2025-10-02 07:09:24,615 - INFO - ==========================================================================================
2025-10-02 07:09:24,616 - INFO - VAL Set Metrics:
2025-10-02 07:09:24,616 - INFO - mAP50 :  0.4907 
2025-10-02 07:09:24,616 - INFO - mAP50-95 : 0.3862
2025-10-02 07:09:24,616 - INFO - Precision : 0.4611 
2025-10-02 07:09:24,616 - INFO - Recall :    0.0654 
2025-10-02 07:09:24,617 - INFO - ==========================================================================================
2025-10-02 07:09:25,453 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 07:30:40,353 - INFO - Epoch 24 | Training Loss: 0.1579
2025-10-02 07:34:46,347 - INFO - ==========================================================================================
2025-10-02 07:34:46,348 - INFO - VAL Set Metrics:
2025-10-02 07:34:46,348 - INFO - mAP50 :  0.4883 
2025-10-02 07:34:46,349 - INFO - mAP50-95 : 0.3880
2025-10-02 07:34:46,349 - INFO - Precision : 0.3962 
2025-10-02 07:34:46,349 - INFO - Recall :    0.0652 
2025-10-02 07:34:46,349 - INFO - ==========================================================================================
2025-10-02 07:34:46,374 - INFO -  No improvement: Current Val mAP50 (0.4883) < Best (0.4907)
2025-10-02 07:56:01,046 - INFO - Epoch 25 | Training Loss: 0.1557
2025-10-02 08:00:07,982 - INFO - ==========================================================================================
2025-10-02 08:00:07,982 - INFO - VAL Set Metrics:
2025-10-02 08:00:07,983 - INFO - mAP50 :  0.4899 
2025-10-02 08:00:07,983 - INFO - mAP50-95 : 0.3969
2025-10-02 08:00:07,983 - INFO - Precision : 0.4602 
2025-10-02 08:00:07,984 - INFO - Recall :    0.0654 
2025-10-02 08:00:07,984 - INFO - ==========================================================================================
2025-10-02 08:00:08,012 - INFO -  No improvement: Current Val mAP50 (0.4899) < Best (0.4907)
2025-10-02 08:21:24,217 - INFO - Epoch 26 | Training Loss: 0.1578
2025-10-02 08:25:32,307 - INFO - ==========================================================================================
2025-10-02 08:25:32,308 - INFO - VAL Set Metrics:
2025-10-02 08:25:32,308 - INFO - mAP50 :  0.4859 
2025-10-02 08:25:32,309 - INFO - mAP50-95 : 0.3965
2025-10-02 08:25:32,309 - INFO - Precision : 0.4972 
2025-10-02 08:25:32,309 - INFO - Recall :    0.0651 
2025-10-02 08:25:32,310 - INFO - ==========================================================================================
2025-10-02 08:25:32,343 - INFO -  No improvement: Current Val mAP50 (0.4859) < Best (0.4907)
2025-10-02 08:49:18,520 - INFO - Epoch 27 | Training Loss: 0.1566
2025-10-02 08:53:59,435 - INFO - ==========================================================================================
2025-10-02 08:53:59,435 - INFO - VAL Set Metrics:
2025-10-02 08:53:59,436 - INFO - mAP50 :  0.4812 
2025-10-02 08:53:59,436 - INFO - mAP50-95 : 0.3905
2025-10-02 08:53:59,436 - INFO - Precision : 0.4909 
2025-10-02 08:53:59,436 - INFO - Recall :    0.0646 
2025-10-02 08:53:59,437 - INFO - ==========================================================================================
2025-10-02 08:53:59,476 - INFO -  No improvement: Current Val mAP50 (0.4812) < Best (0.4907)
2025-10-02 09:15:32,379 - INFO - Epoch 28 | Training Loss: 0.1541
2025-10-02 09:19:41,890 - INFO - ==========================================================================================
2025-10-02 09:19:41,890 - INFO - VAL Set Metrics:
2025-10-02 09:19:41,890 - INFO - mAP50 :  0.4894 
2025-10-02 09:19:41,891 - INFO - mAP50-95 : 0.3981
2025-10-02 09:19:41,891 - INFO - Precision : 0.5634 
2025-10-02 09:19:41,891 - INFO - Recall :    0.0653 
2025-10-02 09:19:41,892 - INFO - ==========================================================================================
2025-10-02 09:19:41,940 - INFO -  No improvement: Current Val mAP50 (0.4894) < Best (0.4907)
2025-10-02 09:40:33,039 - INFO - Epoch 29 | Training Loss: 0.1531
2025-10-02 09:44:33,996 - INFO - ==========================================================================================
2025-10-02 09:44:33,996 - INFO - VAL Set Metrics:
2025-10-02 09:44:33,997 - INFO - mAP50 :  0.4783 
2025-10-02 09:44:33,997 - INFO - mAP50-95 : 0.3915
2025-10-02 09:44:33,997 - INFO - Precision : 0.4151 
2025-10-02 09:44:33,997 - INFO - Recall :    0.0646 
2025-10-02 09:44:33,998 - INFO - ==========================================================================================
2025-10-02 09:44:34,043 - INFO -  No improvement: Current Val mAP50 (0.4783) < Best (0.4907)
2025-10-02 10:04:51,024 - INFO - Epoch 30 | Training Loss: 0.1525
2025-10-02 10:08:49,858 - INFO - ==========================================================================================
2025-10-02 10:08:49,858 - INFO - VAL Set Metrics:
2025-10-02 10:08:49,858 - INFO - mAP50 :  0.4840 
2025-10-02 10:08:49,859 - INFO - mAP50-95 : 0.3949
2025-10-02 10:08:49,859 - INFO - Precision : 0.4637 
2025-10-02 10:08:49,859 - INFO - Recall :    0.0651 
2025-10-02 10:08:49,860 - INFO - ==========================================================================================
2025-10-02 10:08:49,905 - INFO -  No improvement: Current Val mAP50 (0.4840) < Best (0.4907)
2025-10-02 10:28:54,384 - INFO - Epoch 31 | Training Loss: 0.1518
2025-10-02 10:32:50,056 - INFO - ==========================================================================================
2025-10-02 10:32:50,056 - INFO - VAL Set Metrics:
2025-10-02 10:32:50,057 - INFO - mAP50 :  0.4900 
2025-10-02 10:32:50,057 - INFO - mAP50-95 : 0.3984
2025-10-02 10:32:50,057 - INFO - Precision : 0.3959 
2025-10-02 10:32:50,058 - INFO - Recall :    0.0653 
2025-10-02 10:32:50,058 - INFO - ==========================================================================================
2025-10-02 10:32:50,083 - INFO -  No improvement: Current Val mAP50 (0.4900) < Best (0.4907)
2025-10-02 10:52:45,523 - INFO - Epoch 32 | Training Loss: 0.1521
2025-10-02 10:56:41,786 - INFO - ==========================================================================================
2025-10-02 10:56:41,786 - INFO - VAL Set Metrics:
2025-10-02 10:56:41,787 - INFO - mAP50 :  0.4880 
2025-10-02 10:56:41,787 - INFO - mAP50-95 : 0.4006
2025-10-02 10:56:41,787 - INFO - Precision : 0.5248 
2025-10-02 10:56:41,788 - INFO - Recall :    0.0652 
2025-10-02 10:56:41,788 - INFO - ==========================================================================================
2025-10-02 10:56:41,826 - INFO -  No improvement: Current Val mAP50 (0.4880) < Best (0.4907)
2025-10-02 11:16:35,338 - INFO - Epoch 33 | Training Loss: 0.1527
2025-10-02 11:20:30,627 - INFO - ==========================================================================================
2025-10-02 11:20:30,627 - INFO - VAL Set Metrics:
2025-10-02 11:20:30,627 - INFO - mAP50 :  0.4889 
2025-10-02 11:20:30,628 - INFO - mAP50-95 : 0.4005
2025-10-02 11:20:30,628 - INFO - Precision : 0.4725 
2025-10-02 11:20:30,629 - INFO - Recall :    0.0655 
2025-10-02 11:20:30,629 - INFO - ==========================================================================================
2025-10-02 11:20:30,671 - INFO -  No improvement: Current Val mAP50 (0.4889) < Best (0.4907)
2025-10-02 11:40:20,543 - INFO - Epoch 34 | Training Loss: 0.1505
2025-10-02 11:44:15,671 - INFO - ==========================================================================================
2025-10-02 11:44:15,671 - INFO - VAL Set Metrics:
2025-10-02 11:44:15,672 - INFO - mAP50 :  0.4907 
2025-10-02 11:44:15,672 - INFO - mAP50-95 : 0.4035
2025-10-02 11:44:15,672 - INFO - Precision : 0.5379 
2025-10-02 11:44:15,672 - INFO - Recall :    0.0652 
2025-10-02 11:44:15,673 - INFO - ==========================================================================================
2025-10-02 11:44:16,526 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 12:04:13,947 - INFO - Epoch 35 | Training Loss: 0.1503
2025-10-02 12:08:16,558 - INFO - ==========================================================================================
2025-10-02 12:08:16,558 - INFO - VAL Set Metrics:
2025-10-02 12:08:16,558 - INFO - mAP50 :  0.4847 
2025-10-02 12:08:16,559 - INFO - mAP50-95 : 0.4029
2025-10-02 12:08:16,559 - INFO - Precision : 0.5621 
2025-10-02 12:08:16,559 - INFO - Recall :    0.0648 
2025-10-02 12:08:16,559 - INFO - ==========================================================================================
2025-10-02 12:08:16,591 - INFO -  No improvement: Current Val mAP50 (0.4847) < Best (0.4907)
2025-10-02 12:28:19,804 - INFO - Epoch 36 | Training Loss: 0.1497
2025-10-02 12:32:18,013 - INFO - ==========================================================================================
2025-10-02 12:32:18,013 - INFO - VAL Set Metrics:
2025-10-02 12:32:18,013 - INFO - mAP50 :  0.4902 
2025-10-02 12:32:18,014 - INFO - mAP50-95 : 0.4032
2025-10-02 12:32:18,014 - INFO - Precision : 0.4917 
2025-10-02 12:32:18,014 - INFO - Recall :    0.0655 
2025-10-02 12:32:18,014 - INFO - ==========================================================================================
2025-10-02 12:32:18,042 - INFO -  No improvement: Current Val mAP50 (0.4902) < Best (0.4907)
2025-10-02 12:52:17,979 - INFO - Epoch 37 | Training Loss: 0.1487
2025-10-02 12:56:15,515 - INFO - ==========================================================================================
2025-10-02 12:56:15,515 - INFO - VAL Set Metrics:
2025-10-02 12:56:15,515 - INFO - mAP50 :  0.4877 
2025-10-02 12:56:15,515 - INFO - mAP50-95 : 0.4053
2025-10-02 12:56:15,515 - INFO - Precision : 0.4224 
2025-10-02 12:56:15,516 - INFO - Recall :    0.0650 
2025-10-02 12:56:15,516 - INFO - ==========================================================================================
2025-10-02 12:56:15,559 - INFO -  No improvement: Current Val mAP50 (0.4877) < Best (0.4907)
2025-10-02 13:16:15,235 - INFO - Epoch 38 | Training Loss: 0.1489
2025-10-02 13:20:12,052 - INFO - ==========================================================================================
2025-10-02 13:20:12,052 - INFO - VAL Set Metrics:
2025-10-02 13:20:12,052 - INFO - mAP50 :  0.4898 
2025-10-02 13:20:12,053 - INFO - mAP50-95 : 0.4066
2025-10-02 13:20:12,053 - INFO - Precision : 0.5402 
2025-10-02 13:20:12,053 - INFO - Recall :    0.0654 
2025-10-02 13:20:12,054 - INFO - ==========================================================================================
2025-10-02 13:20:12,090 - INFO -  No improvement: Current Val mAP50 (0.4898) < Best (0.4907)
2025-10-02 13:40:04,157 - INFO - Epoch 39 | Training Loss: 0.1491
2025-10-02 13:43:59,207 - INFO - ==========================================================================================
2025-10-02 13:43:59,208 - INFO - VAL Set Metrics:
2025-10-02 13:43:59,208 - INFO - mAP50 :  0.4904 
2025-10-02 13:43:59,209 - INFO - mAP50-95 : 0.4072
2025-10-02 13:43:59,209 - INFO - Precision : 0.5436 
2025-10-02 13:43:59,209 - INFO - Recall :    0.0652 
2025-10-02 13:43:59,209 - INFO - ==========================================================================================
2025-10-02 13:43:59,251 - INFO -  No improvement: Current Val mAP50 (0.4904) < Best (0.4907)
2025-10-02 14:03:53,615 - INFO - Epoch 40 | Training Loss: 0.1487
2025-10-02 14:08:28,700 - INFO - ==========================================================================================
2025-10-02 14:08:28,700 - INFO - VAL Set Metrics:
2025-10-02 14:08:28,701 - INFO - mAP50 :  0.4868 
2025-10-02 14:08:28,701 - INFO - mAP50-95 : 0.4034
2025-10-02 14:08:28,701 - INFO - Precision : 0.4564 
2025-10-02 14:08:28,702 - INFO - Recall :    0.0653 
2025-10-02 14:08:28,702 - INFO - ==========================================================================================
2025-10-02 14:08:28,743 - INFO -  No improvement: Current Val mAP50 (0.4868) < Best (0.4907)
2025-10-02 14:30:47,050 - INFO - Epoch 41 | Training Loss: 0.1459
2025-10-02 14:35:01,988 - INFO - ==========================================================================================
2025-10-02 14:35:01,988 - INFO - VAL Set Metrics:
2025-10-02 14:35:01,988 - INFO - mAP50 :  0.4895 
2025-10-02 14:35:01,989 - INFO - mAP50-95 : 0.4047
2025-10-02 14:35:01,989 - INFO - Precision : 0.3791 
2025-10-02 14:35:01,989 - INFO - Recall :    0.0654 
2025-10-02 14:35:01,989 - INFO - ==========================================================================================
2025-10-02 14:35:02,020 - INFO -  No improvement: Current Val mAP50 (0.4895) < Best (0.4907)
2025-10-02 14:35:37,834 - INFO - Using device: cuda
2025-10-02 14:35:37,834 - INFO - Loading split dataset (train/val/test)...
2025-10-02 14:35:37,876 - INFO - Split dataset loaded successfully!
2025-10-02 14:35:37,876 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-02 14:35:37,877 - INFO - Initializing adaptive fusion model...
2025-10-02 14:35:38,451 - INFO -  Starting cattle detection training...
2025-10-02 15:01:17,784 - INFO - Epoch 1 | Training Loss: nan
2025-10-02 15:06:01,322 - INFO - ==========================================================================================
2025-10-02 15:06:01,322 - INFO - VAL Set Metrics:
2025-10-02 15:06:01,322 - INFO - mAP50 :  0.0000 
2025-10-02 15:06:01,322 - INFO - mAP50-95 : 0.0000
2025-10-02 15:06:01,323 - INFO - Precision : 0.0000 
2025-10-02 15:06:01,323 - INFO - Recall :    0.0000 
2025-10-02 15:06:01,323 - INFO - ==========================================================================================
2025-10-02 15:06:01,342 - INFO -  No improvement: Current Val mAP50 (0.0000) < Best (0.0000)
2025-10-02 15:06:28,393 - INFO - Using device: cuda
2025-10-02 15:06:28,394 - INFO - Loading split dataset (train/val/test)...
2025-10-02 15:06:28,425 - INFO - Split dataset loaded successfully!
2025-10-02 15:06:28,425 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-02 15:06:28,426 - INFO - Initializing adaptive fusion model...
2025-10-02 15:06:29,004 - INFO -  Starting cattle detection training...
2025-10-02 15:34:58,314 - INFO - Epoch 1 | Training Loss: 2.4681
2025-10-02 15:39:57,643 - INFO - ==========================================================================================
2025-10-02 15:39:57,644 - INFO - VAL Set Metrics:
2025-10-02 15:39:57,644 - INFO - mAP50 :  0.0253 
2025-10-02 15:39:57,644 - INFO - mAP50-95 : 0.0057
2025-10-02 15:39:57,645 - INFO - Precision : 0.1529 
2025-10-02 15:39:57,645 - INFO - Recall :    0.0094 
2025-10-02 15:39:57,645 - INFO - ==========================================================================================
2025-10-02 15:39:58,387 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 16:08:20,950 - INFO - Epoch 2 | Training Loss: 0.4336
2025-10-02 16:13:23,773 - INFO - ==========================================================================================
2025-10-02 16:13:23,773 - INFO - VAL Set Metrics:
2025-10-02 16:13:23,773 - INFO - mAP50 :  0.0526 
2025-10-02 16:13:23,774 - INFO - mAP50-95 : 0.0120
2025-10-02 16:13:23,774 - INFO - Precision : 0.1162 
2025-10-02 16:13:23,774 - INFO - Recall :    0.0167 
2025-10-02 16:13:23,774 - INFO - ==========================================================================================
2025-10-02 16:13:24,578 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 16:41:46,005 - INFO - Epoch 3 | Training Loss: 0.3897
2025-10-02 16:46:44,564 - INFO - ==========================================================================================
2025-10-02 16:46:44,564 - INFO - VAL Set Metrics:
2025-10-02 16:46:44,564 - INFO - mAP50 :  0.0980 
2025-10-02 16:46:44,564 - INFO - mAP50-95 : 0.0158
2025-10-02 16:46:44,565 - INFO - Precision : 0.1853 
2025-10-02 16:46:44,565 - INFO - Recall :    0.0315 
2025-10-02 16:46:44,565 - INFO - ==========================================================================================
2025-10-02 16:46:45,285 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 17:15:04,633 - INFO - Epoch 4 | Training Loss: 0.3937
2025-10-02 17:20:01,327 - INFO - ==========================================================================================
2025-10-02 17:20:01,328 - INFO - VAL Set Metrics:
2025-10-02 17:20:01,328 - INFO - mAP50 :  0.0199 
2025-10-02 17:20:01,328 - INFO - mAP50-95 : 0.0061
2025-10-02 17:20:01,329 - INFO - Precision : 0.1888 
2025-10-02 17:20:01,329 - INFO - Recall :    0.0081 
2025-10-02 17:20:01,329 - INFO - ==========================================================================================
2025-10-02 17:20:01,371 - INFO -  No improvement: Current Val mAP50 (0.0199) < Best (0.0980)
2025-10-02 17:48:46,609 - INFO - Epoch 5 | Training Loss: 0.4144
2025-10-02 17:53:43,723 - INFO - ==========================================================================================
2025-10-02 17:53:43,723 - INFO - VAL Set Metrics:
2025-10-02 17:53:43,724 - INFO - mAP50 :  0.1402 
2025-10-02 17:53:43,724 - INFO - mAP50-95 : 0.0313
2025-10-02 17:53:43,724 - INFO - Precision : 0.2172 
2025-10-02 17:53:43,725 - INFO - Recall :    0.0325 
2025-10-02 17:53:43,725 - INFO - ==========================================================================================
2025-10-02 17:53:44,483 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 18:23:24,870 - INFO - Epoch 6 | Training Loss: 0.3320
2025-10-02 18:28:20,440 - INFO - ==========================================================================================
2025-10-02 18:28:20,440 - INFO - VAL Set Metrics:
2025-10-02 18:28:20,441 - INFO - mAP50 :  0.1473 
2025-10-02 18:28:20,441 - INFO - mAP50-95 : 0.0356
2025-10-02 18:28:20,441 - INFO - Precision : 0.1873 
2025-10-02 18:28:20,442 - INFO - Recall :    0.0313 
2025-10-02 18:28:20,442 - INFO - ==========================================================================================
2025-10-02 18:28:21,218 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 18:57:30,313 - INFO - Epoch 7 | Training Loss: 0.3230
2025-10-02 19:02:33,060 - INFO - ==========================================================================================
2025-10-02 19:02:33,061 - INFO - VAL Set Metrics:
2025-10-02 19:02:33,061 - INFO - mAP50 :  0.1836 
2025-10-02 19:02:33,061 - INFO - mAP50-95 : 0.0552
2025-10-02 19:02:33,062 - INFO - Precision : 0.3550 
2025-10-02 19:02:33,062 - INFO - Recall :    0.0346 
2025-10-02 19:02:33,062 - INFO - ==========================================================================================
2025-10-02 19:02:33,831 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 19:32:05,684 - INFO - Epoch 8 | Training Loss: 0.3008
2025-10-02 19:37:07,296 - INFO - ==========================================================================================
2025-10-02 19:37:07,297 - INFO - VAL Set Metrics:
2025-10-02 19:37:07,297 - INFO - mAP50 :  0.2843 
2025-10-02 19:37:07,298 - INFO - mAP50-95 : 0.0976
2025-10-02 19:37:07,298 - INFO - Precision : 0.4500 
2025-10-02 19:37:07,298 - INFO - Recall :    0.0471 
2025-10-02 19:37:07,299 - INFO - ==========================================================================================
2025-10-02 19:37:08,189 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 20:06:43,761 - INFO - Epoch 9 | Training Loss: 0.2957
2025-10-02 20:11:46,346 - INFO - ==========================================================================================
2025-10-02 20:11:46,346 - INFO - VAL Set Metrics:
2025-10-02 20:11:46,346 - INFO - mAP50 :  0.2311 
2025-10-02 20:11:46,347 - INFO - mAP50-95 : 0.0671
2025-10-02 20:11:46,347 - INFO - Precision : 0.2205 
2025-10-02 20:11:46,347 - INFO - Recall :    0.0476 
2025-10-02 20:11:46,347 - INFO - ==========================================================================================
2025-10-02 20:11:46,387 - INFO -  No improvement: Current Val mAP50 (0.2311) < Best (0.2843)
2025-10-02 20:41:17,853 - INFO - Epoch 10 | Training Loss: 0.3005
2025-10-02 20:46:18,882 - INFO - ==========================================================================================
2025-10-02 20:46:18,882 - INFO - VAL Set Metrics:
2025-10-02 20:46:18,883 - INFO - mAP50 :  0.3565 
2025-10-02 20:46:18,883 - INFO - mAP50-95 : 0.1490
2025-10-02 20:46:18,884 - INFO - Precision : 0.2390 
2025-10-02 20:46:18,884 - INFO - Recall :    0.0551 
2025-10-02 20:46:18,884 - INFO - ==========================================================================================
2025-10-02 20:46:20,257 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 21:15:38,481 - INFO - Epoch 11 | Training Loss: 0.2744
2025-10-02 21:20:42,700 - INFO - ==========================================================================================
2025-10-02 21:20:42,701 - INFO - VAL Set Metrics:
2025-10-02 21:20:42,701 - INFO - mAP50 :  0.2931 
2025-10-02 21:20:42,701 - INFO - mAP50-95 : 0.0945
2025-10-02 21:20:42,701 - INFO - Precision : 0.2915 
2025-10-02 21:20:42,702 - INFO - Recall :    0.0508 
2025-10-02 21:20:42,702 - INFO - ==========================================================================================
2025-10-02 21:20:42,735 - INFO -  No improvement: Current Val mAP50 (0.2931) < Best (0.3565)
2025-10-02 21:49:04,321 - INFO - Epoch 12 | Training Loss: 0.2655
2025-10-02 21:53:58,064 - INFO - ==========================================================================================
2025-10-02 21:53:58,065 - INFO - VAL Set Metrics:
2025-10-02 21:53:58,065 - INFO - mAP50 :  0.3751 
2025-10-02 21:53:58,066 - INFO - mAP50-95 : 0.1268
2025-10-02 21:53:58,066 - INFO - Precision : 0.4138 
2025-10-02 21:53:58,066 - INFO - Recall :    0.0573 
2025-10-02 21:53:58,067 - INFO - ==========================================================================================
2025-10-02 21:53:58,849 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 22:21:44,074 - INFO - Epoch 13 | Training Loss: 0.2580
2025-10-02 22:26:39,079 - INFO - ==========================================================================================
2025-10-02 22:26:39,079 - INFO - VAL Set Metrics:
2025-10-02 22:26:39,079 - INFO - mAP50 :  0.4064 
2025-10-02 22:26:39,080 - INFO - mAP50-95 : 0.2151
2025-10-02 22:26:39,080 - INFO - Precision : 0.5235 
2025-10-02 22:26:39,080 - INFO - Recall :    0.0602 
2025-10-02 22:26:39,081 - INFO - ==========================================================================================
2025-10-02 22:26:39,864 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-02 22:54:13,367 - INFO - Epoch 14 | Training Loss: 0.2844
2025-10-02 22:59:06,819 - INFO - ==========================================================================================
2025-10-02 22:59:06,819 - INFO - VAL Set Metrics:
2025-10-02 22:59:06,819 - INFO - mAP50 :  0.2069 
2025-10-02 22:59:06,820 - INFO - mAP50-95 : 0.0596
2025-10-02 22:59:06,820 - INFO - Precision : 0.1882 
2025-10-02 22:59:06,820 - INFO - Recall :    0.0466 
2025-10-02 22:59:06,820 - INFO - ==========================================================================================
2025-10-02 22:59:06,860 - INFO -  No improvement: Current Val mAP50 (0.2069) < Best (0.4064)
2025-10-02 23:26:44,740 - INFO - Epoch 15 | Training Loss: 0.2494
2025-10-02 23:31:36,942 - INFO - ==========================================================================================
2025-10-02 23:31:36,943 - INFO - VAL Set Metrics:
2025-10-02 23:31:36,943 - INFO - mAP50 :  0.3515 
2025-10-02 23:31:36,943 - INFO - mAP50-95 : 0.1569
2025-10-02 23:31:36,944 - INFO - Precision : 0.3659 
2025-10-02 23:31:36,944 - INFO - Recall :    0.0544 
2025-10-02 23:31:36,945 - INFO - ==========================================================================================
2025-10-02 23:31:36,993 - INFO -  No improvement: Current Val mAP50 (0.3515) < Best (0.4064)
2025-10-02 23:59:13,484 - INFO - Epoch 16 | Training Loss: 0.2413
2025-10-03 00:04:06,415 - INFO - ==========================================================================================
2025-10-03 00:04:06,416 - INFO - VAL Set Metrics:
2025-10-03 00:04:06,416 - INFO - mAP50 :  0.4360 
2025-10-03 00:04:06,417 - INFO - mAP50-95 : 0.2589
2025-10-03 00:04:06,417 - INFO - Precision : 0.5011 
2025-10-03 00:04:06,417 - INFO - Recall :    0.0612 
2025-10-03 00:04:06,417 - INFO - ==========================================================================================
2025-10-03 00:04:07,189 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-03 00:31:47,085 - INFO - Epoch 17 | Training Loss: 0.2290
2025-10-03 00:36:37,647 - INFO - ==========================================================================================
2025-10-03 00:36:37,647 - INFO - VAL Set Metrics:
2025-10-03 00:36:37,647 - INFO - mAP50 :  0.4444 
2025-10-03 00:36:37,648 - INFO - mAP50-95 : 0.2498
2025-10-03 00:36:37,648 - INFO - Precision : 0.4211 
2025-10-03 00:36:37,648 - INFO - Recall :    0.0627 
2025-10-03 00:36:37,649 - INFO - ==========================================================================================
2025-10-03 00:36:38,422 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-03 01:04:31,217 - INFO - Epoch 18 | Training Loss: 0.2237
2025-10-03 01:09:24,489 - INFO - ==========================================================================================
2025-10-03 01:09:24,489 - INFO - VAL Set Metrics:
2025-10-03 01:09:24,489 - INFO - mAP50 :  0.4001 
2025-10-03 01:09:24,490 - INFO - mAP50-95 : 0.2265
2025-10-03 01:09:24,490 - INFO - Precision : 0.2950 
2025-10-03 01:09:24,490 - INFO - Recall :    0.0601 
2025-10-03 01:09:24,491 - INFO - ==========================================================================================
2025-10-03 01:09:24,531 - INFO -  No improvement: Current Val mAP50 (0.4001) < Best (0.4444)
2025-10-03 01:36:38,889 - INFO - Epoch 19 | Training Loss: 0.2254
2025-10-03 01:41:56,037 - INFO - ==========================================================================================
2025-10-03 01:41:56,038 - INFO - VAL Set Metrics:
2025-10-03 01:41:56,038 - INFO - mAP50 :  0.4485 
2025-10-03 01:41:56,039 - INFO - mAP50-95 : 0.2905
2025-10-03 01:41:56,039 - INFO - Precision : 0.5149 
2025-10-03 01:41:56,039 - INFO - Recall :    0.0621 
2025-10-03 01:41:56,040 - INFO - ==========================================================================================
2025-10-03 01:41:56,786 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-03 02:12:57,282 - INFO - Epoch 20 | Training Loss: 0.2266
2025-10-03 02:18:03,850 - INFO - ==========================================================================================
2025-10-03 02:18:03,851 - INFO - VAL Set Metrics:
2025-10-03 02:18:03,851 - INFO - mAP50 :  0.4528 
2025-10-03 02:18:03,851 - INFO - mAP50-95 : 0.2893
2025-10-03 02:18:03,852 - INFO - Precision : 0.4076 
2025-10-03 02:18:03,852 - INFO - Recall :    0.0628 
2025-10-03 02:18:03,852 - INFO - ==========================================================================================
2025-10-03 02:18:04,632 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-03 02:48:47,260 - INFO - Epoch 21 | Training Loss: 0.2043
2025-10-03 02:54:18,807 - INFO - ==========================================================================================
2025-10-03 02:54:18,807 - INFO - VAL Set Metrics:
2025-10-03 02:54:18,808 - INFO - mAP50 :  0.4487 
2025-10-03 02:54:18,808 - INFO - mAP50-95 : 0.2925
2025-10-03 02:54:18,808 - INFO - Precision : 0.6335 
2025-10-03 02:54:18,808 - INFO - Recall :    0.0614 
2025-10-03 02:54:18,808 - INFO - ==========================================================================================
2025-10-03 02:54:18,851 - INFO -  No improvement: Current Val mAP50 (0.4487) < Best (0.4528)
2025-10-03 03:22:35,037 - INFO - Epoch 22 | Training Loss: 0.2129
2025-10-03 03:27:26,713 - INFO - ==========================================================================================
2025-10-03 03:27:26,714 - INFO - VAL Set Metrics:
2025-10-03 03:27:26,714 - INFO - mAP50 :  0.4589 
2025-10-03 03:27:26,714 - INFO - mAP50-95 : 0.3080
2025-10-03 03:27:26,715 - INFO - Precision : 0.3482 
2025-10-03 03:27:26,715 - INFO - Recall :    0.0636 
2025-10-03 03:27:26,715 - INFO - ==========================================================================================
2025-10-03 03:27:27,484 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-03 03:55:50,211 - INFO - Epoch 23 | Training Loss: 0.2015
2025-10-03 04:00:41,671 - INFO - ==========================================================================================
2025-10-03 04:00:41,671 - INFO - VAL Set Metrics:
2025-10-03 04:00:41,672 - INFO - mAP50 :  0.4492 
2025-10-03 04:00:41,672 - INFO - mAP50-95 : 0.3169
2025-10-03 04:00:41,672 - INFO - Precision : 0.5605 
2025-10-03 04:00:41,672 - INFO - Recall :    0.0617 
2025-10-03 04:00:41,673 - INFO - ==========================================================================================
2025-10-03 04:00:41,711 - INFO -  No improvement: Current Val mAP50 (0.4492) < Best (0.4589)
2025-10-03 04:29:13,504 - INFO - Epoch 24 | Training Loss: 0.1968
2025-10-03 04:34:05,664 - INFO - ==========================================================================================
2025-10-03 04:34:05,664 - INFO - VAL Set Metrics:
2025-10-03 04:34:05,664 - INFO - mAP50 :  0.4628 
2025-10-03 04:34:05,664 - INFO - mAP50-95 : 0.3168
2025-10-03 04:34:05,665 - INFO - Precision : 0.4052 
2025-10-03 04:34:05,665 - INFO - Recall :    0.0640 
2025-10-03 04:34:05,665 - INFO - ==========================================================================================
2025-10-03 04:34:06,418 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-03 05:01:42,904 - INFO - Epoch 25 | Training Loss: 0.1947
2025-10-03 05:06:33,779 - INFO - ==========================================================================================
2025-10-03 05:06:33,779 - INFO - VAL Set Metrics:
2025-10-03 05:06:33,780 - INFO - mAP50 :  0.4712 
2025-10-03 05:06:33,780 - INFO - mAP50-95 : 0.3399
2025-10-03 05:06:33,780 - INFO - Precision : 0.4954 
2025-10-03 05:06:33,780 - INFO - Recall :    0.0639 
2025-10-03 05:06:33,780 - INFO - ==========================================================================================
2025-10-03 05:06:34,577 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-03 05:34:36,974 - INFO - Epoch 26 | Training Loss: 0.1922
2025-10-03 05:39:27,434 - INFO - ==========================================================================================
2025-10-03 05:39:27,434 - INFO - VAL Set Metrics:
2025-10-03 05:39:27,435 - INFO - mAP50 :  0.4680 
2025-10-03 05:39:27,435 - INFO - mAP50-95 : 0.3095
2025-10-03 05:39:27,435 - INFO - Precision : 0.4562 
2025-10-03 05:39:27,435 - INFO - Recall :    0.0636 
2025-10-03 05:39:27,436 - INFO - ==========================================================================================
2025-10-03 05:39:27,467 - INFO -  No improvement: Current Val mAP50 (0.4680) < Best (0.4712)
2025-10-03 06:07:31,679 - INFO - Epoch 27 | Training Loss: 0.1869
2025-10-03 06:12:22,191 - INFO - ==========================================================================================
2025-10-03 06:12:22,191 - INFO - VAL Set Metrics:
2025-10-03 06:12:22,192 - INFO - mAP50 :  0.4753 
2025-10-03 06:12:22,192 - INFO - mAP50-95 : 0.3439
2025-10-03 06:12:22,192 - INFO - Precision : 0.5065 
2025-10-03 06:12:22,193 - INFO - Recall :    0.0648 
2025-10-03 06:12:22,193 - INFO - ==========================================================================================
2025-10-03 06:12:22,930 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-03 06:41:21,975 - INFO - Epoch 28 | Training Loss: 0.1868
2025-10-03 06:46:22,896 - INFO - ==========================================================================================
2025-10-03 06:46:22,896 - INFO - VAL Set Metrics:
2025-10-03 06:46:22,897 - INFO - mAP50 :  0.4566 
2025-10-03 06:46:22,897 - INFO - mAP50-95 : 0.3144
2025-10-03 06:46:22,897 - INFO - Precision : 0.4953 
2025-10-03 06:46:22,898 - INFO - Recall :    0.0629 
2025-10-03 06:46:22,898 - INFO - ==========================================================================================
2025-10-03 06:46:22,939 - INFO -  No improvement: Current Val mAP50 (0.4566) < Best (0.4753)
2025-10-03 07:13:51,093 - INFO - Epoch 29 | Training Loss: 0.1896
2025-10-03 07:18:43,907 - INFO - ==========================================================================================
2025-10-03 07:18:43,907 - INFO - VAL Set Metrics:
2025-10-03 07:18:43,908 - INFO - mAP50 :  0.4840 
2025-10-03 07:18:43,908 - INFO - mAP50-95 : 0.3465
2025-10-03 07:18:43,908 - INFO - Precision : 0.5054 
2025-10-03 07:18:43,909 - INFO - Recall :    0.0650 
2025-10-03 07:18:43,909 - INFO - ==========================================================================================
2025-10-03 07:18:44,769 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-03 07:47:09,860 - INFO - Epoch 30 | Training Loss: 0.1793
2025-10-03 07:52:00,346 - INFO - ==========================================================================================
2025-10-03 07:52:00,347 - INFO - VAL Set Metrics:
2025-10-03 07:52:00,347 - INFO - mAP50 :  0.4704 
2025-10-03 07:52:00,347 - INFO - mAP50-95 : 0.3376
2025-10-03 07:52:00,347 - INFO - Precision : 0.3843 
2025-10-03 07:52:00,348 - INFO - Recall :    0.0642 
2025-10-03 07:52:00,348 - INFO - ==========================================================================================
2025-10-03 07:52:00,385 - INFO -  No improvement: Current Val mAP50 (0.4704) < Best (0.4840)
2025-10-03 08:20:17,021 - INFO - Epoch 31 | Training Loss: 0.1787
2025-10-03 08:25:08,214 - INFO - ==========================================================================================
2025-10-03 08:25:08,214 - INFO - VAL Set Metrics:
2025-10-03 08:25:08,215 - INFO - mAP50 :  0.4689 
2025-10-03 08:25:08,215 - INFO - mAP50-95 : 0.3236
2025-10-03 08:25:08,215 - INFO - Precision : 0.6898 
2025-10-03 08:25:08,215 - INFO - Recall :    0.0631 
2025-10-03 08:25:08,216 - INFO - ==========================================================================================
2025-10-03 08:25:08,245 - INFO -  No improvement: Current Val mAP50 (0.4689) < Best (0.4840)
2025-10-03 08:55:55,897 - INFO - Epoch 32 | Training Loss: 0.1774
2025-10-03 09:01:26,482 - INFO - ==========================================================================================
2025-10-03 09:01:26,482 - INFO - VAL Set Metrics:
2025-10-03 09:01:26,482 - INFO - mAP50 :  0.4841 
2025-10-03 09:01:26,482 - INFO - mAP50-95 : 0.3496
2025-10-03 09:01:26,483 - INFO - Precision : 0.5536 
2025-10-03 09:01:26,483 - INFO - Recall :    0.0649 
2025-10-03 09:01:26,483 - INFO - ==========================================================================================
2025-10-03 09:01:27,323 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-03 09:29:42,207 - INFO - Epoch 33 | Training Loss: 0.1728
2025-10-03 09:34:33,478 - INFO - ==========================================================================================
2025-10-03 09:34:33,479 - INFO - VAL Set Metrics:
2025-10-03 09:34:33,479 - INFO - mAP50 :  0.4739 
2025-10-03 09:34:33,479 - INFO - mAP50-95 : 0.3411
2025-10-03 09:34:33,480 - INFO - Precision : 0.4639 
2025-10-03 09:34:33,480 - INFO - Recall :    0.0648 
2025-10-03 09:34:33,480 - INFO - ==========================================================================================
2025-10-03 09:34:33,510 - INFO -  No improvement: Current Val mAP50 (0.4739) < Best (0.4841)
2025-10-03 10:03:03,423 - INFO - Epoch 34 | Training Loss: 0.1717
2025-10-03 10:07:57,617 - INFO - ==========================================================================================
2025-10-03 10:07:57,617 - INFO - VAL Set Metrics:
2025-10-03 10:07:57,617 - INFO - mAP50 :  0.4832 
2025-10-03 10:07:57,617 - INFO - mAP50-95 : 0.3578
2025-10-03 10:07:57,618 - INFO - Precision : 0.4338 
2025-10-03 10:07:57,618 - INFO - Recall :    0.0650 
2025-10-03 10:07:57,618 - INFO - ==========================================================================================
2025-10-03 10:07:57,656 - INFO -  No improvement: Current Val mAP50 (0.4832) < Best (0.4841)
2025-10-03 10:35:23,937 - INFO - Epoch 35 | Training Loss: 0.1716
2025-10-03 10:40:11,523 - INFO - ==========================================================================================
2025-10-03 10:40:11,524 - INFO - VAL Set Metrics:
2025-10-03 10:40:11,524 - INFO - mAP50 :  0.4839 
2025-10-03 10:40:11,524 - INFO - mAP50-95 : 0.3515
2025-10-03 10:40:11,525 - INFO - Precision : 0.4070 
2025-10-03 10:40:11,525 - INFO - Recall :    0.0651 
2025-10-03 10:40:11,525 - INFO - ==========================================================================================
2025-10-03 10:40:11,555 - INFO -  No improvement: Current Val mAP50 (0.4839) < Best (0.4841)
2025-10-03 14:31:41,523 - INFO - Using device: cuda
2025-10-03 14:31:41,524 - INFO - Loading split dataset (train/val/test)...
2025-10-03 14:31:42,100 - INFO - Split dataset loaded successfully!
2025-10-03 14:31:42,101 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-03 14:31:42,101 - INFO - Initializing adaptive fusion model...
2025-10-03 14:31:42,761 - INFO -  Starting cattle detection training...
2025-10-03 15:10:10,098 - INFO - Epoch 1 | Training Loss: 2.2282
2025-10-03 15:16:40,492 - INFO - ==========================================================================================
2025-10-03 15:16:40,492 - INFO - VAL Set Metrics:
2025-10-03 15:16:40,492 - INFO - mAP50 :  0.2555 
2025-10-03 15:16:40,493 - INFO - mAP50-95 : 0.0881
2025-10-03 15:16:40,493 - INFO - Precision : 0.1359 
2025-10-03 15:16:40,493 - INFO - Recall :    0.0461 
2025-10-03 15:16:40,493 - INFO - ==========================================================================================
2025-10-03 15:16:41,355 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-03 15:50:55,762 - INFO - Epoch 2 | Training Loss: 0.4194
2025-10-03 15:57:05,198 - INFO - ==========================================================================================
2025-10-03 15:57:05,198 - INFO - VAL Set Metrics:
2025-10-03 15:57:05,199 - INFO - mAP50 :  0.3475 
2025-10-03 15:57:05,199 - INFO - mAP50-95 : 0.1901
2025-10-03 15:57:05,200 - INFO - Precision : 0.2364 
2025-10-03 15:57:05,200 - INFO - Recall :    0.0540 
2025-10-03 15:57:05,201 - INFO - ==========================================================================================
2025-10-03 15:57:06,505 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-03 16:30:06,967 - INFO - Using device: cuda
2025-10-03 16:30:06,967 - INFO - Loading split dataset (train/val/test)...
2025-10-03 16:30:07,102 - INFO - Split dataset loaded successfully!
2025-10-03 16:30:07,102 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-03 16:30:07,103 - INFO - Initializing adaptive fusion model...
2025-10-03 16:30:07,928 - INFO -  Starting cattle detection training...
2025-10-03 16:39:45,650 - INFO - Using device: cuda
2025-10-03 16:39:45,651 - INFO - Loading split dataset (train/val/test)...
2025-10-03 16:39:45,845 - INFO - Split dataset loaded successfully!
2025-10-03 16:39:45,845 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-03 16:39:45,845 - INFO - Initializing adaptive fusion model...
2025-10-03 16:39:46,790 - INFO -  Starting cattle detection training...
2025-10-03 17:29:46,239 - INFO - Epoch 1 | Training Loss: 2.3674
2025-10-03 17:29:46,244 - INFO - Learning rate remains fixed at: 0.000100
2025-10-03 17:37:42,405 - INFO - ==========================================================================================
2025-10-03 17:37:42,406 - INFO - VAL Set Metrics:
2025-10-03 17:37:42,406 - INFO - mAP50 :  0.0745 
2025-10-03 17:37:42,406 - INFO - mAP50-95 : 0.0176
2025-10-03 17:37:42,406 - INFO - Precision : 0.0376 
2025-10-03 17:37:42,406 - INFO - Recall :    0.0396 
2025-10-03 17:37:42,406 - INFO - ==========================================================================================
2025-10-03 17:37:43,488 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-03 18:26:31,036 - INFO - Epoch 2 | Training Loss: 0.2859
2025-10-03 18:26:31,038 - INFO - Learning rate remains fixed at: 0.000100
2025-10-03 18:33:55,595 - INFO - ==========================================================================================
2025-10-03 18:33:55,596 - INFO - VAL Set Metrics:
2025-10-03 18:33:55,596 - INFO - mAP50 :  0.2276 
2025-10-03 18:33:55,596 - INFO - mAP50-95 : 0.0744
2025-10-03 18:33:55,596 - INFO - Precision : 0.0254 
2025-10-03 18:33:55,596 - INFO - Recall :    0.0532 
2025-10-03 18:33:55,597 - INFO - ==========================================================================================
2025-10-03 18:33:56,760 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-03 18:57:49,764 - INFO - Using device: cuda
2025-10-03 18:57:49,764 - INFO - Loading split dataset (train/val/test)...
2025-10-03 18:57:49,813 - INFO - Split dataset loaded successfully!
2025-10-03 18:57:49,813 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-03 18:57:49,813 - INFO - Initializing adaptive fusion model...
2025-10-03 18:57:50,830 - INFO -  Starting cattle detection training...
2025-10-03 19:30:28,637 - INFO - Epoch 1 | Training Loss: 3.5575
2025-10-03 19:30:28,637 - INFO - Learning rate remains fixed at: 0.000100
2025-10-03 19:34:30,849 - INFO - ==========================================================================================
2025-10-03 19:34:30,849 - INFO - VAL Set Metrics:
2025-10-03 19:34:30,849 - INFO - mAP50 :  0.1715 
2025-10-03 19:34:30,849 - INFO - mAP50-95 : 0.0468
2025-10-03 19:34:30,850 - INFO - Precision : 0.0500 
2025-10-03 19:34:30,850 - INFO - Recall :    0.5123 
2025-10-03 19:34:30,850 - INFO - ==========================================================================================
2025-10-03 19:34:31,789 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-03 20:00:57,441 - INFO - Epoch 2 | Training Loss: 0.8237
2025-10-03 20:00:57,441 - INFO - Learning rate remains fixed at: 0.000100
2025-10-03 20:04:56,355 - INFO - ==========================================================================================
2025-10-03 20:04:56,355 - INFO - VAL Set Metrics:
2025-10-03 20:04:56,355 - INFO - mAP50 :  0.3069 
2025-10-03 20:04:56,355 - INFO - mAP50-95 : 0.1258
2025-10-03 20:04:56,356 - INFO - Precision : 0.0636 
2025-10-03 20:04:56,356 - INFO - Recall :    0.5918 
2025-10-03 20:04:56,356 - INFO - ==========================================================================================
2025-10-03 20:04:57,246 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-03 20:31:29,650 - INFO - Epoch 3 | Training Loss: 0.6715
2025-10-03 20:31:29,650 - INFO - Learning rate remains fixed at: 0.000100
2025-10-03 20:35:28,836 - INFO - ==========================================================================================
2025-10-03 20:35:28,837 - INFO - VAL Set Metrics:
2025-10-03 20:35:28,837 - INFO - mAP50 :  0.3460 
2025-10-03 20:35:28,837 - INFO - mAP50-95 : 0.1407
2025-10-03 20:35:28,837 - INFO - Precision : 0.0735 
2025-10-03 20:35:28,837 - INFO - Recall :    0.5932 
2025-10-03 20:35:28,837 - INFO - ==========================================================================================
2025-10-03 20:35:29,751 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-03 21:02:04,588 - INFO - Epoch 4 | Training Loss: 0.6733
2025-10-03 21:02:04,589 - INFO - Learning rate remains fixed at: 0.000100
2025-10-03 21:06:04,553 - INFO - ==========================================================================================
2025-10-03 21:06:04,553 - INFO - VAL Set Metrics:
2025-10-03 21:06:04,553 - INFO - mAP50 :  0.3456 
2025-10-03 21:06:04,554 - INFO - mAP50-95 : 0.1375
2025-10-03 21:06:04,554 - INFO - Precision : 0.0697 
2025-10-03 21:06:04,554 - INFO - Recall :    0.6090 
2025-10-03 21:06:04,554 - INFO - ==========================================================================================
2025-10-03 21:06:04,581 - INFO -  No improvement: Current Val mAP50 (0.3456) < Best (0.3460)
2025-10-03 21:32:38,788 - INFO - Epoch 5 | Training Loss: 0.7255
2025-10-03 21:32:38,789 - INFO - Learning rate remains fixed at: 0.000100
2025-10-03 21:36:39,615 - INFO - ==========================================================================================
2025-10-03 21:36:39,615 - INFO - VAL Set Metrics:
2025-10-03 21:36:39,615 - INFO - mAP50 :  0.3274 
2025-10-03 21:36:39,616 - INFO - mAP50-95 : 0.1164
2025-10-03 21:36:39,616 - INFO - Precision : 0.0678 
2025-10-03 21:36:39,616 - INFO - Recall :    0.6126 
2025-10-03 21:36:39,616 - INFO - ==========================================================================================
2025-10-03 21:36:39,646 - INFO -  No improvement: Current Val mAP50 (0.3274) < Best (0.3460)
2025-10-03 22:03:14,503 - INFO - Epoch 6 | Training Loss: 0.5893
2025-10-03 22:03:14,503 - INFO - Learning rate remains fixed at: 0.000100
2025-10-03 22:07:13,930 - INFO - ==========================================================================================
2025-10-03 22:07:13,930 - INFO - VAL Set Metrics:
2025-10-03 22:07:13,930 - INFO - mAP50 :  0.3505 
2025-10-03 22:07:13,931 - INFO - mAP50-95 : 0.1575
2025-10-03 22:07:13,931 - INFO - Precision : 0.0930 
2025-10-03 22:07:13,931 - INFO - Recall :    0.6148 
2025-10-03 22:07:13,931 - INFO - ==========================================================================================
2025-10-03 22:07:14,660 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-03 22:33:46,997 - INFO - Epoch 7 | Training Loss: 0.5754
2025-10-03 22:33:46,998 - INFO - Learning rate remains fixed at: 0.000100
2025-10-03 22:37:44,080 - INFO - ==========================================================================================
2025-10-03 22:37:44,081 - INFO - VAL Set Metrics:
2025-10-03 22:37:44,081 - INFO - mAP50 :  0.3969 
2025-10-03 22:37:44,081 - INFO - mAP50-95 : 0.2059
2025-10-03 22:37:44,082 - INFO - Precision : 0.1143 
2025-10-03 22:37:44,082 - INFO - Recall :    0.6483 
2025-10-03 22:37:44,082 - INFO - ==========================================================================================
2025-10-03 22:37:44,852 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-03 23:04:19,061 - INFO - Epoch 8 | Training Loss: 0.5684
2025-10-03 23:04:19,061 - INFO - Learning rate remains fixed at: 0.000100
2025-10-03 23:08:18,581 - INFO - ==========================================================================================
2025-10-03 23:08:18,581 - INFO - VAL Set Metrics:
2025-10-03 23:08:18,582 - INFO - mAP50 :  0.4341 
2025-10-03 23:08:18,582 - INFO - mAP50-95 : 0.2403
2025-10-03 23:08:18,582 - INFO - Precision : 0.0852 
2025-10-03 23:08:18,582 - INFO - Recall :    0.6662 
2025-10-03 23:08:18,583 - INFO - ==========================================================================================
2025-10-03 23:08:19,399 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-03 23:34:50,259 - INFO - Epoch 9 | Training Loss: 0.5297
2025-10-03 23:34:50,259 - INFO - Learning rate remains fixed at: 0.000100
2025-10-03 23:38:49,457 - INFO - ==========================================================================================
2025-10-03 23:38:49,458 - INFO - VAL Set Metrics:
2025-10-03 23:38:49,458 - INFO - mAP50 :  0.4207 
2025-10-03 23:38:49,458 - INFO - mAP50-95 : 0.2260
2025-10-03 23:38:49,458 - INFO - Precision : 0.0895 
2025-10-03 23:38:49,458 - INFO - Recall :    0.6350 
2025-10-03 23:38:49,459 - INFO - ==========================================================================================
2025-10-03 23:38:49,489 - INFO -  No improvement: Current Val mAP50 (0.4207) < Best (0.4341)
2025-10-04 00:05:21,779 - INFO - Epoch 10 | Training Loss: 0.6436
2025-10-04 00:05:21,780 - INFO - Learning rate remains fixed at: 0.000100
2025-10-04 00:09:21,382 - INFO - ==========================================================================================
2025-10-04 00:09:21,382 - INFO - VAL Set Metrics:
2025-10-04 00:09:21,383 - INFO - mAP50 :  0.4359 
2025-10-04 00:09:21,383 - INFO - mAP50-95 : 0.2376
2025-10-04 00:09:21,383 - INFO - Precision : 0.0922 
2025-10-04 00:09:21,383 - INFO - Recall :    0.5975 
2025-10-04 00:09:21,384 - INFO - ==========================================================================================
2025-10-04 00:09:22,136 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-04 00:35:53,608 - INFO - Epoch 11 | Training Loss: 0.7259
2025-10-04 00:35:53,609 - INFO - Learning rate remains fixed at: 0.000100
2025-10-04 00:39:51,518 - INFO - ==========================================================================================
2025-10-04 00:39:51,518 - INFO - VAL Set Metrics:
2025-10-04 00:39:51,518 - INFO - mAP50 :  0.4250 
2025-10-04 00:39:51,518 - INFO - mAP50-95 : 0.2378
2025-10-04 00:39:51,519 - INFO - Precision : 0.1075 
2025-10-04 00:39:51,519 - INFO - Recall :    0.6543 
2025-10-04 00:39:51,519 - INFO - ==========================================================================================
2025-10-04 00:39:51,549 - INFO -  No improvement: Current Val mAP50 (0.4250) < Best (0.4359)
2025-10-04 01:06:26,654 - INFO - Epoch 12 | Training Loss: 0.5098
2025-10-04 01:06:26,655 - INFO - Learning rate remains fixed at: 0.000100
2025-10-04 01:10:26,112 - INFO - ==========================================================================================
2025-10-04 01:10:26,113 - INFO - VAL Set Metrics:
2025-10-04 01:10:26,113 - INFO - mAP50 :  0.4340 
2025-10-04 01:10:26,113 - INFO - mAP50-95 : 0.2493
2025-10-04 01:10:26,113 - INFO - Precision : 0.1188 
2025-10-04 01:10:26,113 - INFO - Recall :    0.6669 
2025-10-04 01:10:26,114 - INFO - ==========================================================================================
2025-10-04 01:10:26,142 - INFO -  No improvement: Current Val mAP50 (0.4340) < Best (0.4359)
2025-10-04 01:22:22,193 - INFO - Using device: cuda
2025-10-04 01:22:22,193 - INFO - Loading split dataset (train/val/test)...
2025-10-04 01:22:22,216 - INFO - Split dataset loaded successfully!
2025-10-04 01:22:22,216 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-04 01:22:22,217 - INFO - Initializing adaptive fusion model...
2025-10-04 01:22:22,793 - INFO -  Starting cattle detection training...
2025-10-04 01:48:41,288 - INFO - Epoch 1 | Training Loss: 4.6025
2025-10-04 01:48:41,289 - INFO - Learning rate remains fixed at: 0.000100
2025-10-04 01:52:44,967 - INFO - ==========================================================================================
2025-10-04 01:52:44,967 - INFO - VAL Set Metrics:
2025-10-04 01:52:44,968 - INFO - mAP50 :  0.1608 
2025-10-04 01:52:44,968 - INFO - mAP50-95 : 0.0425
2025-10-04 01:52:44,968 - INFO - Precision : 0.0331 
2025-10-04 01:52:44,968 - INFO - Recall :    0.5758 
2025-10-04 01:52:44,969 - INFO - ==========================================================================================
2025-10-04 01:52:45,798 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-04 02:19:24,439 - INFO - Epoch 2 | Training Loss: 0.8531
2025-10-04 02:19:24,439 - INFO - Learning rate remains fixed at: 0.000100
2025-10-04 02:23:27,363 - INFO - ==========================================================================================
2025-10-04 02:23:27,364 - INFO - VAL Set Metrics:
2025-10-04 02:23:27,364 - INFO - mAP50 :  0.1843 
2025-10-04 02:23:27,364 - INFO - mAP50-95 : 0.0611
2025-10-04 02:23:27,364 - INFO - Precision : 0.0427 
2025-10-04 02:23:27,364 - INFO - Recall :    0.5460 
2025-10-04 02:23:27,365 - INFO - ==========================================================================================
2025-10-04 02:23:28,223 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-04 04:08:04,734 - INFO - Using device: cuda
2025-10-04 04:08:04,735 - INFO - Loading split dataset (train/val/test)...
2025-10-04 04:08:05,258 - INFO - Split dataset loaded successfully!
2025-10-04 04:08:05,259 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-04 04:08:05,259 - INFO - Initializing adaptive fusion model...
2025-10-04 04:08:06,118 - INFO -  Starting cattle detection training...
2025-10-04 04:48:55,340 - INFO - Epoch 1 | Training Loss: 2.6236
2025-10-04 04:48:55,341 - INFO - Learning rate remains fixed at: 0.000100
2025-10-04 04:54:39,774 - INFO - ==========================================================================================
2025-10-04 04:54:39,774 - INFO - VAL Set Metrics:
2025-10-04 04:54:39,774 - INFO - mAP50 :  0.0822 
2025-10-04 04:54:39,775 - INFO - mAP50-95 : 0.0211
2025-10-04 04:54:39,775 - INFO - Precision : 0.0426 
2025-10-04 04:54:39,775 - INFO - Recall :    0.4043 
2025-10-04 04:54:39,776 - INFO - ==========================================================================================
2025-10-04 04:54:40,761 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-04 04:58:37,482 - INFO - Using device: cuda
2025-10-04 04:58:37,483 - INFO - Loading split dataset (train/val/test)...
2025-10-04 04:58:37,505 - INFO - Split dataset loaded successfully!
2025-10-04 04:58:37,505 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-04 04:58:37,506 - INFO - Initializing adaptive fusion model...
2025-10-04 04:58:38,272 - INFO -  Starting cattle detection training...
2025-10-04 05:00:09,329 - INFO - Using device: cuda
2025-10-04 05:00:09,330 - INFO - Loading split dataset (train/val/test)...
2025-10-04 05:00:09,351 - INFO - Split dataset loaded successfully!
2025-10-04 05:00:09,351 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-04 05:00:09,352 - INFO - Initializing adaptive fusion model...
2025-10-04 05:00:10,100 - INFO -  Starting cattle detection training...
2025-10-04 05:14:25,586 - INFO - Using device: cuda
2025-10-04 05:14:25,587 - INFO - Loading split dataset (train/val/test)...
2025-10-04 05:14:25,609 - INFO - Split dataset loaded successfully!
2025-10-04 05:14:25,609 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-04 05:14:25,610 - INFO - Initializing adaptive fusion model...
2025-10-04 05:14:26,348 - INFO -  Starting cattle detection training...
2025-10-04 05:48:50,873 - INFO - Epoch 1 | Training Loss: 2.6348
2025-10-04 05:48:50,874 - INFO - Learning rate remains fixed at: 0.000100
2025-10-04 05:54:10,251 - INFO - ==========================================================================================
2025-10-04 05:54:10,252 - INFO - VAL Set Metrics:
2025-10-04 05:54:10,252 - INFO - mAP50 :  0.1819 
2025-10-04 05:54:10,252 - INFO - mAP50-95 : 0.0550
2025-10-04 05:54:10,253 - INFO - Precision : 0.0754 
2025-10-04 05:54:10,253 - INFO - Recall :    0.5050 
2025-10-04 05:54:10,253 - INFO - ==========================================================================================
2025-10-04 05:54:11,280 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-04 06:28:17,534 - INFO - Epoch 2 | Training Loss: 0.5544
2025-10-04 06:28:17,535 - INFO - Learning rate remains fixed at: 0.000100
2025-10-04 06:33:33,730 - INFO - ==========================================================================================
2025-10-04 06:33:33,730 - INFO - VAL Set Metrics:
2025-10-04 06:33:33,731 - INFO - mAP50 :  0.2499 
2025-10-04 06:33:33,731 - INFO - mAP50-95 : 0.0904
2025-10-04 06:33:33,731 - INFO - Precision : 0.1564 
2025-10-04 06:33:33,732 - INFO - Recall :    0.5164 
2025-10-04 06:33:33,732 - INFO - ==========================================================================================
2025-10-04 06:33:34,699 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-04 07:07:21,651 - INFO - Epoch 3 | Training Loss: 0.3633
2025-10-04 07:07:21,652 - INFO - Learning rate remains fixed at: 0.000100
2025-10-04 07:12:31,028 - INFO - ==========================================================================================
2025-10-04 07:12:31,029 - INFO - VAL Set Metrics:
2025-10-04 07:12:31,029 - INFO - mAP50 :  0.3287 
2025-10-04 07:12:31,029 - INFO - mAP50-95 : 0.1158
2025-10-04 07:12:31,029 - INFO - Precision : 0.1576 
2025-10-04 07:12:31,030 - INFO - Recall :    0.5699 
2025-10-04 07:12:31,030 - INFO - ==========================================================================================
2025-10-04 07:12:32,059 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-04 07:46:16,507 - INFO - Epoch 4 | Training Loss: 0.3293
2025-10-04 07:46:16,508 - INFO - Learning rate remains fixed at: 0.000100
2025-10-04 07:51:27,501 - INFO - ==========================================================================================
2025-10-04 07:51:27,501 - INFO - VAL Set Metrics:
2025-10-04 07:51:27,502 - INFO - mAP50 :  0.2596 
2025-10-04 07:51:27,502 - INFO - mAP50-95 : 0.0812
2025-10-04 07:51:27,502 - INFO - Precision : 0.0719 
2025-10-04 07:51:27,502 - INFO - Recall :    0.5599 
2025-10-04 07:51:27,502 - INFO - ==========================================================================================
2025-10-04 07:51:27,544 - INFO -  No improvement: Current Val mAP50 (0.2596) < Best (0.3287)
2025-10-04 08:25:17,379 - INFO - Epoch 5 | Training Loss: 0.3385
2025-10-04 08:25:17,380 - INFO - Learning rate remains fixed at: 0.000100
2025-10-04 08:30:30,405 - INFO - ==========================================================================================
2025-10-04 08:30:30,405 - INFO - VAL Set Metrics:
2025-10-04 08:30:30,405 - INFO - mAP50 :  0.1913 
2025-10-04 08:30:30,405 - INFO - mAP50-95 : 0.0517
2025-10-04 08:30:30,406 - INFO - Precision : 0.0711 
2025-10-04 08:30:30,406 - INFO - Recall :    0.5222 
2025-10-04 08:30:30,406 - INFO - ==========================================================================================
2025-10-04 08:30:30,446 - INFO -  No improvement: Current Val mAP50 (0.1913) < Best (0.3287)
2025-10-04 09:04:18,839 - INFO - Epoch 6 | Training Loss: 0.3176
2025-10-04 09:04:18,840 - INFO - Learning rate remains fixed at: 0.000100
2025-10-04 09:09:39,510 - INFO - ==========================================================================================
2025-10-04 09:09:39,510 - INFO - VAL Set Metrics:
2025-10-04 09:09:39,510 - INFO - mAP50 :  0.2463 
2025-10-04 09:09:39,510 - INFO - mAP50-95 : 0.0710
2025-10-04 09:09:39,511 - INFO - Precision : 0.0457 
2025-10-04 09:09:39,511 - INFO - Recall :    0.5919 
2025-10-04 09:09:39,511 - INFO - ==========================================================================================
2025-10-04 09:09:39,551 - INFO -  No improvement: Current Val mAP50 (0.2463) < Best (0.3287)
2025-10-04 09:43:25,529 - INFO - Epoch 7 | Training Loss: 0.3228
2025-10-04 09:43:25,531 - INFO - Learning rate remains fixed at: 0.000100
2025-10-04 09:48:33,100 - INFO - ==========================================================================================
2025-10-04 09:48:33,100 - INFO - VAL Set Metrics:
2025-10-04 09:48:33,100 - INFO - mAP50 :  0.2961 
2025-10-04 09:48:33,100 - INFO - mAP50-95 : 0.0944
2025-10-04 09:48:33,101 - INFO - Precision : 0.1171 
2025-10-04 09:48:33,101 - INFO - Recall :    0.5865 
2025-10-04 09:48:33,101 - INFO - ==========================================================================================
2025-10-04 09:48:33,142 - INFO -  No improvement: Current Val mAP50 (0.2961) < Best (0.3287)
2025-10-04 10:22:31,446 - INFO - Epoch 8 | Training Loss: 0.2749
2025-10-04 10:22:31,447 - INFO - Learning rate remains fixed at: 0.000100
2025-10-04 10:27:38,284 - INFO - ==========================================================================================
2025-10-04 10:27:38,284 - INFO - VAL Set Metrics:
2025-10-04 10:27:38,284 - INFO - mAP50 :  0.3517 
2025-10-04 10:27:38,284 - INFO - mAP50-95 : 0.1333
2025-10-04 10:27:38,285 - INFO - Precision : 0.1213 
2025-10-04 10:27:38,285 - INFO - Recall :    0.6464 
2025-10-04 10:27:38,285 - INFO - ==========================================================================================
2025-10-04 10:27:39,529 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-04 11:01:20,673 - INFO - Epoch 9 | Training Loss: 0.3099
2025-10-04 11:01:20,674 - INFO - Learning rate remains fixed at: 0.000100
2025-10-04 11:06:30,986 - INFO - ==========================================================================================
2025-10-04 11:06:30,986 - INFO - VAL Set Metrics:
2025-10-04 11:06:30,986 - INFO - mAP50 :  0.3683 
2025-10-04 11:06:30,986 - INFO - mAP50-95 : 0.1725
2025-10-04 11:06:30,987 - INFO - Precision : 0.0881 
2025-10-04 11:06:30,987 - INFO - Recall :    0.6017 
2025-10-04 11:06:30,987 - INFO - ==========================================================================================
2025-10-04 11:06:31,992 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-04 11:40:07,559 - INFO - Epoch 10 | Training Loss: 0.2891
2025-10-04 11:40:07,560 - INFO - Learning rate remains fixed at: 0.000100
2025-10-04 11:45:17,229 - INFO - ==========================================================================================
2025-10-04 11:45:17,230 - INFO - VAL Set Metrics:
2025-10-04 11:45:17,230 - INFO - mAP50 :  0.3758 
2025-10-04 11:45:17,230 - INFO - mAP50-95 : 0.1796
2025-10-04 11:45:17,230 - INFO - Precision : 0.1052 
2025-10-04 11:45:17,230 - INFO - Recall :    0.5986 
2025-10-04 11:45:17,231 - INFO - ==========================================================================================
2025-10-04 11:45:18,238 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-04 12:19:02,407 - INFO - Epoch 11 | Training Loss: 0.2921
2025-10-04 12:19:02,408 - INFO - Learning rate remains fixed at: 0.000100
2025-10-04 12:24:18,017 - INFO - ==========================================================================================
2025-10-04 12:24:18,017 - INFO - VAL Set Metrics:
2025-10-04 12:24:18,018 - INFO - mAP50 :  0.3956 
2025-10-04 12:24:18,018 - INFO - mAP50-95 : 0.1960
2025-10-04 12:24:18,018 - INFO - Precision : 0.1324 
2025-10-04 12:24:18,018 - INFO - Recall :    0.6392 
2025-10-04 12:24:18,018 - INFO - ==========================================================================================
2025-10-04 12:24:19,001 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-04 12:59:29,596 - INFO - Epoch 12 | Training Loss: 0.2764
2025-10-04 12:59:29,598 - INFO - Learning rate remains fixed at: 0.000100
2025-10-04 13:05:06,737 - INFO - ==========================================================================================
2025-10-04 13:05:06,738 - INFO - VAL Set Metrics:
2025-10-04 13:05:06,738 - INFO - mAP50 :  0.4176 
2025-10-04 13:05:06,738 - INFO - mAP50-95 : 0.2201
2025-10-04 13:05:06,739 - INFO - Precision : 0.0993 
2025-10-04 13:05:06,739 - INFO - Recall :    0.6339 
2025-10-04 13:05:06,739 - INFO - ==========================================================================================
2025-10-04 13:05:07,911 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-04 13:16:11,049 - INFO - Using device: cuda
2025-10-04 13:16:11,050 - INFO - Loading split dataset (train/val/test)...
2025-10-04 13:16:11,076 - INFO - Split dataset loaded successfully!
2025-10-04 13:16:11,076 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-04 13:16:11,076 - INFO - Initializing adaptive fusion model...
2025-10-04 13:16:11,964 - INFO -  Starting cattle detection training...
2025-10-04 13:52:14,003 - INFO - Epoch 1 | Training Loss: 2.8231
2025-10-04 13:52:14,004 - INFO - Current learning rate: 0.000100
2025-10-04 13:57:50,027 - INFO - ==========================================================================================
2025-10-04 13:57:50,028 - INFO - VAL Set Metrics:
2025-10-04 13:57:50,028 - INFO - mAP50 :  0.2087 
2025-10-04 13:57:50,029 - INFO - mAP50-95 : 0.0570
2025-10-04 13:57:50,029 - INFO - Precision : 0.0555 
2025-10-04 13:57:50,029 - INFO - Recall :    0.5750 
2025-10-04 13:57:50,030 - INFO - ==========================================================================================
2025-10-04 13:57:51,109 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-04 14:31:02,283 - INFO - Epoch 2 | Training Loss: 0.4249
2025-10-04 14:31:02,285 - INFO - Current learning rate: 0.000100
2025-10-04 14:36:21,141 - INFO - ==========================================================================================
2025-10-04 14:36:21,141 - INFO - VAL Set Metrics:
2025-10-04 14:36:21,142 - INFO - mAP50 :  0.2039 
2025-10-04 14:36:21,142 - INFO - mAP50-95 : 0.0626
2025-10-04 14:36:21,142 - INFO - Precision : 0.0493 
2025-10-04 14:36:21,143 - INFO - Recall :    0.5457 
2025-10-04 14:36:21,143 - INFO - ==========================================================================================
2025-10-04 14:36:21,184 - INFO -  No improvement: Current Val mAP50 (0.2039) < Best (0.2087)
2025-10-04 15:05:20,098 - INFO - Using device: cuda
2025-10-04 15:05:20,099 - INFO - Loading split dataset (train/val/test)...
2025-10-04 15:05:20,239 - INFO - Split dataset loaded successfully!
2025-10-04 15:05:20,239 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-04 15:05:20,239 - INFO - Initializing adaptive fusion model...
2025-10-04 15:05:21,240 - INFO -  Starting cattle detection training...
2025-10-04 15:08:11,149 - INFO - Using device: cuda
2025-10-04 15:08:11,149 - INFO - Loading split dataset (train/val/test)...
2025-10-04 15:08:11,173 - INFO - Split dataset loaded successfully!
2025-10-04 15:08:11,173 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-04 15:08:11,174 - INFO - Initializing adaptive fusion model...
2025-10-04 15:08:11,943 - INFO -  Starting cattle detection training...
2025-10-04 15:11:25,516 - INFO - Using device: cuda
2025-10-04 15:11:25,517 - INFO - Loading split dataset (train/val/test)...
2025-10-04 15:11:25,551 - INFO - Split dataset loaded successfully!
2025-10-04 15:11:25,551 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-04 15:11:25,551 - INFO - Initializing adaptive fusion model...
2025-10-04 15:11:26,278 - INFO -  Starting cattle detection training...
2025-10-04 15:15:27,943 - INFO - Using device: cuda
2025-10-04 15:15:27,944 - INFO - Loading split dataset (train/val/test)...
2025-10-04 15:15:27,967 - INFO - Split dataset loaded successfully!
2025-10-04 15:15:27,967 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-04 15:15:27,967 - INFO - Initializing adaptive fusion model...
2025-10-04 15:15:28,688 - INFO -  Starting cattle detection training...
2025-10-04 15:19:32,185 - INFO - Using device: cuda
2025-10-04 15:19:32,186 - INFO - Loading split dataset (train/val/test)...
2025-10-04 15:19:32,209 - INFO - Split dataset loaded successfully!
2025-10-04 15:19:32,209 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-04 15:19:32,209 - INFO - Initializing adaptive fusion model...
2025-10-04 15:19:32,970 - INFO -  Starting cattle detection training...
2025-10-04 15:21:55,480 - INFO - Using device: cuda
2025-10-04 15:21:55,480 - INFO - Loading split dataset (train/val/test)...
2025-10-04 15:21:55,504 - INFO - Split dataset loaded successfully!
2025-10-04 15:21:55,505 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-04 15:21:55,505 - INFO - Initializing adaptive fusion model...
2025-10-04 15:21:56,199 - INFO -  Starting cattle detection training...
2025-10-04 16:03:16,096 - INFO - Epoch 1 | Training Loss: 2.6692
2025-10-04 16:03:16,097 - INFO - Current learning rate: 0.000100
2025-10-04 16:08:47,493 - INFO - ==========================================================================================
2025-10-04 16:08:47,493 - INFO - VAL Set Metrics:
2025-10-04 16:08:47,494 - INFO - mAP50 :  0.2402 
2025-10-04 16:08:47,494 - INFO - mAP50-95 : 0.0701
2025-10-04 16:08:47,494 - INFO - Precision : 0.0369 
2025-10-04 16:08:47,495 - INFO - Recall :    0.5468 
2025-10-04 16:08:47,495 - INFO - ==========================================================================================
2025-10-04 16:08:48,608 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-04 16:51:29,130 - INFO - Epoch 2 | Training Loss: 0.5387
2025-10-04 16:51:29,131 - INFO - Current learning rate: 0.000100
2025-10-04 16:57:13,617 - INFO - ==========================================================================================
2025-10-04 16:57:13,617 - INFO - VAL Set Metrics:
2025-10-04 16:57:13,617 - INFO - mAP50 :  0.2791 
2025-10-04 16:57:13,617 - INFO - mAP50-95 : 0.0750
2025-10-04 16:57:13,618 - INFO - Precision : 0.0572 
2025-10-04 16:57:13,618 - INFO - Recall :    0.6123 
2025-10-04 16:57:13,618 - INFO - ==========================================================================================
2025-10-04 16:57:14,747 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-04 17:40:27,725 - INFO - Epoch 3 | Training Loss: 0.4589
2025-10-04 17:40:27,726 - INFO - Current learning rate: 0.000100
2025-10-04 17:45:42,465 - INFO - ==========================================================================================
2025-10-04 17:45:42,465 - INFO - VAL Set Metrics:
2025-10-04 17:45:42,466 - INFO - mAP50 :  0.2889 
2025-10-04 17:45:42,466 - INFO - mAP50-95 : 0.0943
2025-10-04 17:45:42,466 - INFO - Precision : 0.0950 
2025-10-04 17:45:42,467 - INFO - Recall :    0.5868 
2025-10-04 17:45:42,467 - INFO - ==========================================================================================
2025-10-04 17:45:43,467 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-04 18:27:14,740 - INFO - Epoch 4 | Training Loss: 0.4339
2025-10-04 18:27:14,741 - INFO - Current learning rate: 0.000100
2025-10-04 18:32:41,529 - INFO - ==========================================================================================
2025-10-04 18:32:41,529 - INFO - VAL Set Metrics:
2025-10-04 18:32:41,530 - INFO - mAP50 :  0.2082 
2025-10-04 18:32:41,530 - INFO - mAP50-95 : 0.0624
2025-10-04 18:32:41,530 - INFO - Precision : 0.0302 
2025-10-04 18:32:41,530 - INFO - Recall :    0.5626 
2025-10-04 18:32:41,530 - INFO - ==========================================================================================
2025-10-04 18:32:41,572 - INFO -  No improvement: Current Val mAP50 (0.2082) < Best (0.2889)
2025-10-04 18:32:41,572 - INFO - Stagnant epochs: 1/10
2025-10-04 19:13:49,332 - INFO - Epoch 5 | Training Loss: 0.4271
2025-10-04 19:13:49,333 - INFO - Current learning rate: 0.000099
2025-10-04 19:19:43,373 - INFO - ==========================================================================================
2025-10-04 19:19:43,374 - INFO - VAL Set Metrics:
2025-10-04 19:19:43,374 - INFO - mAP50 :  0.0466 
2025-10-04 19:19:43,374 - INFO - mAP50-95 : 0.0131
2025-10-04 19:19:43,374 - INFO - Precision : 0.0140 
2025-10-04 19:19:43,374 - INFO - Recall :    0.6116 
2025-10-04 19:19:43,375 - INFO - ==========================================================================================
2025-10-04 19:19:43,428 - INFO -  No improvement: Current Val mAP50 (0.0466) < Best (0.2889)
2025-10-04 19:19:43,429 - INFO - Stagnant epochs: 2/10
2025-10-04 20:00:36,822 - INFO - Epoch 6 | Training Loss: 0.4732
2025-10-04 20:00:36,822 - INFO - Current learning rate: 0.000099
2025-10-04 20:05:53,010 - INFO - ==========================================================================================
2025-10-04 20:05:53,010 - INFO - VAL Set Metrics:
2025-10-04 20:05:53,010 - INFO - mAP50 :  0.3352 
2025-10-04 20:05:53,011 - INFO - mAP50-95 : 0.1236
2025-10-04 20:05:53,011 - INFO - Precision : 0.0874 
2025-10-04 20:05:53,011 - INFO - Recall :    0.5989 
2025-10-04 20:05:53,012 - INFO - ==========================================================================================
2025-10-04 20:05:54,027 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-04 20:47:14,263 - INFO - Epoch 7 | Training Loss: 0.3560
2025-10-04 20:47:14,264 - INFO - Current learning rate: 0.000099
2025-10-04 20:52:27,795 - INFO - ==========================================================================================
2025-10-04 20:52:27,795 - INFO - VAL Set Metrics:
2025-10-04 20:52:27,796 - INFO - mAP50 :  0.3355 
2025-10-04 20:52:27,796 - INFO - mAP50-95 : 0.0993
2025-10-04 20:52:27,796 - INFO - Precision : 0.0839 
2025-10-04 20:52:27,796 - INFO - Recall :    0.6287 
2025-10-04 20:52:27,797 - INFO - ==========================================================================================
2025-10-04 20:52:28,961 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-04 21:33:35,607 - INFO - Epoch 8 | Training Loss: 0.3274
2025-10-04 21:33:35,608 - INFO - Current learning rate: 0.000099
2025-10-04 21:38:49,272 - INFO - ==========================================================================================
2025-10-04 21:38:49,272 - INFO - VAL Set Metrics:
2025-10-04 21:38:49,272 - INFO - mAP50 :  0.3817 
2025-10-04 21:38:49,273 - INFO - mAP50-95 : 0.1560
2025-10-04 21:38:49,273 - INFO - Precision : 0.0944 
2025-10-04 21:38:49,273 - INFO - Recall :    0.6240 
2025-10-04 21:38:49,273 - INFO - ==========================================================================================
2025-10-04 21:38:50,491 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-04 22:19:26,798 - INFO - Epoch 9 | Training Loss: 0.3286
2025-10-04 22:19:26,799 - INFO - Current learning rate: 0.000098
2025-10-04 22:24:52,534 - INFO - ==========================================================================================
2025-10-04 22:24:52,535 - INFO - VAL Set Metrics:
2025-10-04 22:24:52,535 - INFO - mAP50 :  0.3946 
2025-10-04 22:24:52,536 - INFO - mAP50-95 : 0.1694
2025-10-04 22:24:52,536 - INFO - Precision : 0.0929 
2025-10-04 22:24:52,536 - INFO - Recall :    0.6386 
2025-10-04 22:24:52,536 - INFO - ==========================================================================================
2025-10-04 22:24:53,583 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-04 23:06:31,810 - INFO - Epoch 10 | Training Loss: 0.3149
2025-10-04 23:06:31,811 - INFO - Current learning rate: 0.000098
2025-10-04 23:12:08,037 - INFO - ==========================================================================================
2025-10-04 23:12:08,038 - INFO - VAL Set Metrics:
2025-10-04 23:12:08,038 - INFO - mAP50 :  0.3893 
2025-10-04 23:12:08,038 - INFO - mAP50-95 : 0.1483
2025-10-04 23:12:08,039 - INFO - Precision : 0.0676 
2025-10-04 23:12:08,039 - INFO - Recall :    0.6185 
2025-10-04 23:12:08,039 - INFO - ==========================================================================================
2025-10-04 23:12:08,097 - INFO -  No improvement: Current Val mAP50 (0.3893) < Best (0.3946)
2025-10-04 23:12:08,098 - INFO - Stagnant epochs: 1/10
2025-10-04 23:54:28,907 - INFO - Epoch 11 | Training Loss: 0.3050
2025-10-04 23:54:28,908 - INFO - Current learning rate: 0.000097
2025-10-04 23:59:51,844 - INFO - ==========================================================================================
2025-10-04 23:59:51,844 - INFO - VAL Set Metrics:
2025-10-04 23:59:51,845 - INFO - mAP50 :  0.3992 
2025-10-04 23:59:51,845 - INFO - mAP50-95 : 0.1571
2025-10-04 23:59:51,845 - INFO - Precision : 0.0669 
2025-10-04 23:59:51,845 - INFO - Recall :    0.6285 
2025-10-04 23:59:51,846 - INFO - ==========================================================================================
2025-10-04 23:59:52,954 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 00:41:56,300 - INFO - Epoch 12 | Training Loss: 0.3049
2025-10-05 00:41:56,301 - INFO - Current learning rate: 0.000097
2025-10-05 00:47:40,928 - INFO - ==========================================================================================
2025-10-05 00:47:40,928 - INFO - VAL Set Metrics:
2025-10-05 00:47:40,929 - INFO - mAP50 :  0.3956 
2025-10-05 00:47:40,929 - INFO - mAP50-95 : 0.1594
2025-10-05 00:47:40,929 - INFO - Precision : 0.0935 
2025-10-05 00:47:40,929 - INFO - Recall :    0.6055 
2025-10-05 00:47:40,930 - INFO - ==========================================================================================
2025-10-05 00:47:40,962 - INFO -  No improvement: Current Val mAP50 (0.3956) < Best (0.3992)
2025-10-05 00:47:40,963 - INFO - Stagnant epochs: 1/10
2025-10-05 01:28:27,673 - INFO - Epoch 13 | Training Loss: 0.2891
2025-10-05 01:28:27,674 - INFO - Current learning rate: 0.000096
2025-10-05 01:32:27,485 - INFO - ==========================================================================================
2025-10-05 01:32:27,485 - INFO - VAL Set Metrics:
2025-10-05 01:32:27,486 - INFO - mAP50 :  0.4127 
2025-10-05 01:32:27,486 - INFO - mAP50-95 : 0.1739
2025-10-05 01:32:27,486 - INFO - Precision : 0.1130 
2025-10-05 01:32:27,486 - INFO - Recall :    0.6727 
2025-10-05 01:32:27,486 - INFO - ==========================================================================================
2025-10-05 01:32:28,291 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 02:04:10,766 - INFO - Epoch 14 | Training Loss: 0.2806
2025-10-05 02:04:10,766 - INFO - Current learning rate: 0.000096
2025-10-05 02:08:13,350 - INFO - ==========================================================================================
2025-10-05 02:08:13,351 - INFO - VAL Set Metrics:
2025-10-05 02:08:13,351 - INFO - mAP50 :  0.4161 
2025-10-05 02:08:13,351 - INFO - mAP50-95 : 0.1918
2025-10-05 02:08:13,351 - INFO - Precision : 0.1677 
2025-10-05 02:08:13,352 - INFO - Recall :    0.6110 
2025-10-05 02:08:13,352 - INFO - ==========================================================================================
2025-10-05 02:08:14,055 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 02:39:29,440 - INFO - Epoch 15 | Training Loss: 0.2756
2025-10-05 02:39:29,440 - INFO - Current learning rate: 0.000095
2025-10-05 02:43:24,991 - INFO - ==========================================================================================
2025-10-05 02:43:24,991 - INFO - VAL Set Metrics:
2025-10-05 02:43:24,991 - INFO - mAP50 :  0.4176 
2025-10-05 02:43:24,991 - INFO - mAP50-95 : 0.1695
2025-10-05 02:43:24,992 - INFO - Precision : 0.1681 
2025-10-05 02:43:24,992 - INFO - Recall :    0.6277 
2025-10-05 02:43:24,992 - INFO - ==========================================================================================
2025-10-05 02:43:25,637 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 03:11:40,480 - INFO - Epoch 16 | Training Loss: nan
2025-10-05 03:11:40,481 - INFO - Current learning rate: 0.000094
2025-10-05 03:14:57,378 - INFO - ==========================================================================================
2025-10-05 03:14:57,378 - INFO - VAL Set Metrics:
2025-10-05 03:14:57,378 - INFO - mAP50 :  0.0000 
2025-10-05 03:14:57,379 - INFO - mAP50-95 : 0.0000
2025-10-05 03:14:57,379 - INFO - Precision : 0.0000 
2025-10-05 03:14:57,379 - INFO - Recall :    0.0000 
2025-10-05 03:14:57,379 - INFO - ==========================================================================================
2025-10-05 03:14:57,401 - INFO -  No improvement: Current Val mAP50 (0.0000) < Best (0.4176)
2025-10-05 03:14:57,401 - INFO - Stagnant epochs: 1/10
2025-10-05 03:31:19,943 - INFO - Using device: cuda
2025-10-05 03:31:19,943 - INFO - Loading split dataset (train/val/test)...
2025-10-05 03:31:20,003 - INFO - Split dataset loaded successfully!
2025-10-05 03:31:20,003 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 03:31:20,003 - INFO - Initializing adaptive fusion model...
2025-10-05 03:31:20,985 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 03:31:21,494 - INFO - Start epoch: 15 | Best Val mAP50 so far: 0.4176
2025-10-05 03:31:21,495 - INFO -  Starting cattle detection training...
2025-10-05 04:02:20,894 - INFO - Using device: cuda
2025-10-05 04:02:20,894 - INFO - Loading split dataset (train/val/test)...
2025-10-05 04:02:20,913 - INFO - Split dataset loaded successfully!
2025-10-05 04:02:20,913 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 04:02:20,914 - INFO - Initializing adaptive fusion model...
2025-10-05 04:02:21,843 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 04:02:21,843 - INFO - Start epoch: 15 | Best Val mAP50 so far: 0.4176
2025-10-05 04:02:21,843 - INFO -  Starting cattle detection training...
2025-10-05 04:07:30,343 - INFO - Using device: cuda
2025-10-05 04:07:30,344 - INFO - Loading split dataset (train/val/test)...
2025-10-05 04:07:30,362 - INFO - Split dataset loaded successfully!
2025-10-05 04:07:30,363 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 04:07:30,363 - INFO - Initializing adaptive fusion model...
2025-10-05 04:07:31,270 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 04:07:31,270 - INFO - Start epoch: 15 | Best Val mAP50 so far: 0.4176
2025-10-05 04:07:31,270 - INFO -  Starting cattle detection training...
2025-10-05 13:45:18,039 - INFO - Using device: cuda
2025-10-05 13:45:18,039 - INFO - Loading split dataset (train/val/test)...
2025-10-05 13:45:18,548 - INFO - Split dataset loaded successfully!
2025-10-05 13:45:18,548 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 13:45:18,548 - INFO - Initializing adaptive fusion model...
2025-10-05 13:45:19,797 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 13:45:19,797 - INFO - Start epoch: 15 | Best Val mAP50 so far: 0.4176
2025-10-05 13:45:19,797 - INFO -  Starting cattle detection training...
2025-10-05 14:45:40,275 - INFO - Using device: cuda
2025-10-05 14:45:40,276 - INFO - Loading split dataset (train/val/test)...
2025-10-05 14:45:40,293 - INFO - Split dataset loaded successfully!
2025-10-05 14:45:40,293 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 14:45:40,293 - INFO - Initializing adaptive fusion model...
2025-10-05 14:45:41,258 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 14:45:41,259 - INFO - Start epoch: 15 | Best Val mAP50 so far: 0.4176
2025-10-05 14:45:41,259 - INFO -  Starting cattle detection training...
2025-10-05 14:45:41,263 - ERROR - Training failed with error: 
Traceback (most recent call last):
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 421, in <module>
    train_one_epoch(model, train_loader, optimizer, scaler, device, epoch, args, logger)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 197, in train_one_epoch
    for batch_idx, (images, targets) in enumerate(progress_bar):
                                        ~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\tqdm\std.py", line 1181, in __iter__
    for obj in iterable:
               ^^^^^^^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\dataloader.py", line 491, in __iter__
    return self._get_iterator()
           ~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\dataloader.py", line 419, in _get_iterator
    return _SingleProcessDataLoaderIter(self)
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\dataloader.py", line 743, in __init__
    assert self._timeout == 0
           ^^^^^^^^^^^^^^^^^^
AssertionError
2025-10-05 14:46:34,292 - INFO - Using device: cuda
2025-10-05 14:46:34,293 - INFO - Loading split dataset (train/val/test)...
2025-10-05 14:46:34,310 - INFO - Split dataset loaded successfully!
2025-10-05 14:46:34,310 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 14:46:34,310 - INFO - Initializing adaptive fusion model...
2025-10-05 14:46:35,224 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 14:46:35,224 - INFO - Start epoch: 15 | Best Val mAP50 so far: 0.4176
2025-10-05 14:46:35,224 - INFO -  Starting cattle detection training...
2025-10-05 14:46:35,229 - ERROR - Training failed with error: 
Traceback (most recent call last):
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 421, in <module>
    train_one_epoch(model, train_loader, optimizer, scaler, device, epoch, args, logger)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 197, in train_one_epoch
    for batch_idx, (images, targets) in enumerate(progress_bar):
                                        ~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\tqdm\std.py", line 1181, in __iter__
    for obj in iterable:
               ^^^^^^^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\dataloader.py", line 491, in __iter__
    return self._get_iterator()
           ~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\dataloader.py", line 419, in _get_iterator
    return _SingleProcessDataLoaderIter(self)
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\dataloader.py", line 743, in __init__
    assert self._timeout == 0
           ^^^^^^^^^^^^^^^^^^
AssertionError
2025-10-05 14:50:08,562 - INFO - Using device: cuda
2025-10-05 14:50:08,563 - INFO - Loading split dataset (train/val/test)...
2025-10-05 14:50:08,580 - ERROR - Training failed with error: DataLoader.__init__() missing 1 required positional argument: 'dataset'
Traceback (most recent call last):
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 381, in <module>
    train_loader, val_loader, test_loader = load_split_dataloaders(args, train_transform, val_test_transform, logger)
                                            ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 150, in load_split_dataloaders
    dataloaders[split] = DataLoader(**dataloader_kwargs)
                         ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^
TypeError: DataLoader.__init__() missing 1 required positional argument: 'dataset'
2025-10-05 14:52:57,988 - INFO - Using device: cuda
2025-10-05 14:52:57,988 - INFO - Loading split dataset (train/val/test)...
2025-10-05 14:52:58,005 - INFO - Split dataset loaded successfully!
2025-10-05 14:52:58,005 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 14:52:58,005 - INFO - Initializing adaptive fusion model...
2025-10-05 14:52:58,902 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 14:52:58,902 - INFO - Start epoch: 15 | Best Val mAP50 so far: 0.4176
2025-10-05 14:52:58,902 - INFO -  Starting cattle detection training...
2025-10-05 15:06:08,550 - WARNING - NaN loss detected in batch 825, skipping...
2025-10-05 15:06:22,421 - WARNING - NaN loss detected in batch 833, skipping...
2025-10-05 15:06:25,276 - WARNING - NaN loss detected in batch 834, skipping...
2025-10-05 15:06:31,612 - WARNING - NaN loss detected in batch 839, skipping...
2025-10-05 15:06:39,717 - WARNING - NaN loss detected in batch 844, skipping...
2025-10-05 15:06:44,297 - WARNING - NaN loss detected in batch 846, skipping...
2025-10-05 15:06:54,615 - WARNING - NaN loss detected in batch 853, skipping...
2025-10-05 15:07:03,899 - WARNING - NaN loss detected in batch 859, skipping...
2025-10-05 15:07:08,471 - WARNING - NaN loss detected in batch 861, skipping...
2025-10-05 15:07:17,744 - WARNING - NaN loss detected in batch 867, skipping...
2025-10-05 15:07:23,442 - WARNING - NaN loss detected in batch 870, skipping...
2025-10-05 15:07:29,214 - WARNING - NaN loss detected in batch 873, skipping...
2025-10-05 15:07:32,137 - WARNING - NaN loss detected in batch 874, skipping...
2025-10-05 15:07:35,136 - WARNING - NaN loss detected in batch 876, skipping...
2025-10-05 15:07:43,208 - WARNING - NaN loss detected in batch 881, skipping...
2025-10-05 15:07:46,162 - WARNING - NaN loss detected in batch 882, skipping...
2025-10-05 15:07:49,119 - WARNING - NaN loss detected in batch 884, skipping...
2025-10-05 15:07:52,051 - WARNING - NaN loss detected in batch 885, skipping...
2025-10-05 15:07:53,683 - WARNING - NaN loss detected in batch 886, skipping...
2025-10-05 15:07:55,749 - WARNING - NaN loss detected in batch 887, skipping...
2025-10-05 15:07:57,964 - WARNING - NaN loss detected in batch 888, skipping...
2025-10-05 15:07:59,679 - WARNING - NaN loss detected in batch 889, skipping...
2025-10-05 15:08:03,679 - WARNING - NaN loss detected in batch 891, skipping...
2025-10-05 15:08:06,527 - WARNING - NaN loss detected in batch 892, skipping...
2025-10-05 15:08:08,123 - WARNING - NaN loss detected in batch 893, skipping...
2025-10-05 15:08:11,619 - WARNING - NaN loss detected in batch 895, skipping...
2025-10-05 15:08:20,638 - WARNING - NaN loss detected in batch 901, skipping...
2025-10-05 15:08:25,107 - WARNING - NaN loss detected in batch 903, skipping...
2025-10-05 15:08:27,984 - WARNING - NaN loss detected in batch 904, skipping...
2025-10-05 15:08:29,624 - WARNING - NaN loss detected in batch 905, skipping...
2025-10-05 15:08:33,137 - WARNING - NaN loss detected in batch 907, skipping...
2025-10-05 15:08:35,978 - WARNING - NaN loss detected in batch 908, skipping...
2025-10-05 15:08:37,665 - WARNING - NaN loss detected in batch 909, skipping...
2025-10-05 15:08:39,703 - WARNING - NaN loss detected in batch 910, skipping...
2025-10-05 15:08:41,820 - WARNING - NaN loss detected in batch 911, skipping...
2025-10-05 15:08:43,517 - WARNING - NaN loss detected in batch 912, skipping...
2025-10-05 15:08:45,632 - WARNING - NaN loss detected in batch 913, skipping...
2025-10-05 15:08:49,904 - WARNING - NaN loss detected in batch 915, skipping...
2025-10-05 15:08:52,843 - WARNING - NaN loss detected in batch 916, skipping...
2025-10-05 15:08:54,570 - WARNING - NaN loss detected in batch 917, skipping...
2025-10-05 15:08:56,620 - WARNING - NaN loss detected in batch 918, skipping...
2025-10-05 15:08:58,821 - WARNING - NaN loss detected in batch 919, skipping...
2025-10-05 15:09:00,567 - WARNING - NaN loss detected in batch 920, skipping...
2025-10-05 15:09:04,660 - WARNING - NaN loss detected in batch 922, skipping...
2025-10-05 15:09:07,588 - WARNING - NaN loss detected in batch 923, skipping...
2025-10-05 15:09:10,485 - WARNING - NaN loss detected in batch 925, skipping...
2025-10-05 15:09:13,445 - WARNING - NaN loss detected in batch 926, skipping...
2025-10-05 15:09:16,332 - WARNING - NaN loss detected in batch 928, skipping...
2025-10-05 15:09:19,268 - WARNING - NaN loss detected in batch 929, skipping...
2025-10-05 15:09:20,912 - WARNING - NaN loss detected in batch 930, skipping...
2025-10-05 15:09:23,036 - WARNING - NaN loss detected in batch 931, skipping...
2025-10-05 15:09:26,833 - WARNING - NaN loss detected in batch 933, skipping...
2025-10-05 15:09:29,678 - WARNING - NaN loss detected in batch 934, skipping...
2025-10-05 15:09:31,353 - WARNING - NaN loss detected in batch 935, skipping...
2025-10-05 15:09:33,432 - WARNING - NaN loss detected in batch 936, skipping...
2025-10-05 15:09:35,552 - WARNING - NaN loss detected in batch 937, skipping...
2025-10-05 15:09:38,465 - WARNING - NaN loss detected in batch 939, skipping...
2025-10-05 15:09:41,357 - WARNING - NaN loss detected in batch 940, skipping...
2025-10-05 15:09:43,087 - WARNING - NaN loss detected in batch 941, skipping...
2025-10-05 15:09:45,168 - WARNING - NaN loss detected in batch 942, skipping...
2025-10-05 15:09:47,315 - WARNING - NaN loss detected in batch 943, skipping...
2025-10-05 15:09:48,999 - WARNING - NaN loss detected in batch 944, skipping...
2025-10-05 15:09:51,128 - WARNING - NaN loss detected in batch 945, skipping...
2025-10-05 15:09:53,876 - WARNING - NaN loss detected in batch 946, skipping...
2025-10-05 15:09:58,954 - WARNING - NaN loss detected in batch 949, skipping...
2025-10-05 15:10:04,716 - WARNING - NaN loss detected in batch 952, skipping...
2025-10-05 15:16:18,247 - INFO - Using device: cuda
2025-10-05 15:16:18,247 - INFO - Loading split dataset (train/val/test)...
2025-10-05 15:16:18,268 - INFO - Split dataset loaded successfully!
2025-10-05 15:16:18,268 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 15:16:18,269 - INFO - Initializing adaptive fusion model...
2025-10-05 15:16:19,160 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 15:16:19,160 - INFO - Start epoch: 15 | Best Val mAP50 so far: 0.4176
2025-10-05 15:16:19,160 - INFO -  Starting cattle detection training...
2025-10-05 15:47:57,231 - INFO - Epoch 16 | Training Loss: 0.2657
2025-10-05 15:47:57,232 - INFO - Current learning rate: 0.000095
2025-10-05 15:47:57,235 - ERROR - Training failed with error: Unexpected keyword arguments: `warn_on_many_detections`
Traceback (most recent call last):
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 447, in <module>
    current_val_mAP50, _, _, _ = evaluate_model(
                                 ~~~~~~~~~~~~~~^
        model, val_loader, device, "val", logger,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        threshold=args.inference_threshold
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 311, in evaluate_model
    metric = MeanAveragePrecision(
        box_format="xyxy",
        iou_type="bbox",
        warn_on_many_detections=False  # Disable warning about too many detections
    )
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torchmetrics\detection\mean_ap.py", line 357, in __init__
    super().__init__(**kwargs)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torchmetrics\metric.py", line 154, in __init__
    raise ValueError(f"Unexpected keyword arguments: {', '.join(kwargs_)}")
ValueError: Unexpected keyword arguments: `warn_on_many_detections`
2025-10-05 15:51:44,053 - INFO - Using device: cuda
2025-10-05 15:51:44,054 - INFO - Loading split dataset (train/val/test)...
2025-10-05 15:51:44,073 - INFO - Split dataset loaded successfully!
2025-10-05 15:51:44,074 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 15:51:44,074 - INFO - Initializing adaptive fusion model...
2025-10-05 15:51:44,972 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 15:51:44,973 - INFO - Start epoch: 15 | Best Val mAP50 so far: 0.4176
2025-10-05 15:51:44,973 - INFO -  Starting cattle detection training...
2025-10-05 16:14:09,269 - ERROR - Error processing batch 1438: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 16:19:10,709 - ERROR - Error processing batch 1662: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 16:20:22,234 - ERROR - Error processing batch 1715: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 16:22:34,053 - ERROR - Error processing batch 1814: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 16:23:44,872 - ERROR - Error processing batch 1866: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 16:24:47,548 - ERROR - Error processing batch 1912: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 16:24:50,443 - ERROR - Error processing batch 1913: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 16:24:56,600 - ERROR - Error processing batch 1917: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 16:26:25,663 - ERROR - Error processing batch 1983: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 16:26:48,577 - INFO - Epoch 16 | Training Loss: 0.2724
2025-10-05 16:26:48,578 - INFO - Current learning rate: 0.000095
2025-10-05 16:31:08,712 - INFO - ==========================================================================================
2025-10-05 16:31:08,712 - INFO - VAL Set Metrics:
2025-10-05 16:31:08,713 - INFO - mAP50 :  0.4265 
2025-10-05 16:31:08,713 - INFO - mAP50-95 : 0.1772
2025-10-05 16:31:08,713 - INFO - Precision : 0.3400 
2025-10-05 16:31:08,713 - INFO - Recall :    0.5841 
2025-10-05 16:31:08,713 - INFO - ==========================================================================================
2025-10-05 16:31:09,343 - INFO -  Best model saved to: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 16:31:25,262 - ERROR - Error processing batch 16: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 16:32:27,830 - ERROR - Error processing batch 71: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 16:32:44,121 - ERROR - Error processing batch 84: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 16:35:09,255 - INFO - Using device: cuda
2025-10-05 16:35:09,255 - INFO - Loading split dataset (train/val/test)...
2025-10-05 16:35:09,275 - INFO - Split dataset loaded successfully!
2025-10-05 16:35:09,275 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 16:35:09,275 - INFO - Initializing adaptive fusion model...
2025-10-05 16:35:10,184 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 16:35:10,184 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-05 16:35:10,184 - INFO -  Starting cattle detection training...
2025-10-05 16:35:12,535 - ERROR - Error processing batch 0: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:12,922 - ERROR - Error processing batch 1: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:13,378 - ERROR - Error processing batch 2: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:13,763 - ERROR - Error processing batch 3: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:14,146 - ERROR - Error processing batch 4: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:14,516 - ERROR - Error processing batch 5: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:14,853 - ERROR - Error processing batch 6: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:15,214 - ERROR - Error processing batch 7: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:15,573 - ERROR - Error processing batch 8: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:15,938 - ERROR - Error processing batch 9: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:16,291 - ERROR - Error processing batch 10: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:16,668 - ERROR - Error processing batch 11: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:17,050 - ERROR - Error processing batch 12: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:17,418 - ERROR - Error processing batch 13: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:17,821 - ERROR - Error processing batch 14: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:18,253 - ERROR - Error processing batch 15: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:18,655 - ERROR - Error processing batch 16: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:19,026 - ERROR - Error processing batch 17: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:19,424 - ERROR - Error processing batch 18: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:19,774 - ERROR - Error processing batch 19: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:20,131 - ERROR - Error processing batch 20: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:20,490 - ERROR - Error processing batch 21: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:20,938 - ERROR - Error processing batch 22: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:21,458 - ERROR - Error processing batch 23: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:21,843 - ERROR - Error processing batch 24: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:22,224 - ERROR - Error processing batch 25: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:22,591 - ERROR - Error processing batch 26: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:22,986 - ERROR - Error processing batch 27: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:23,366 - ERROR - Error processing batch 28: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:23,752 - ERROR - Error processing batch 29: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:24,149 - ERROR - Error processing batch 30: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:35:24,511 - ERROR - Error processing batch 31: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-10-05 16:38:59,960 - INFO - Using device: cuda
2025-10-05 16:38:59,961 - INFO - Loading split dataset (train/val/test)...
2025-10-05 16:38:59,982 - INFO - Split dataset loaded successfully!
2025-10-05 16:38:59,982 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 16:38:59,982 - INFO - Initializing adaptive fusion model...
2025-10-05 16:39:00,885 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 16:39:00,885 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-05 16:39:00,885 - INFO -  Starting cattle detection training...
2025-10-05 16:39:01,154 - ERROR - Device mismatch in batch 0
2025-10-05 16:39:01,154 - ERROR - Images device: cuda:0
2025-10-05 16:39:01,154 - ERROR - Targets device: cuda:0
2025-10-05 16:39:01,376 - ERROR - Device mismatch in batch 1
2025-10-05 16:39:01,377 - ERROR - Images device: cuda:0
2025-10-05 16:39:01,377 - ERROR - Targets device: cuda:0
2025-10-05 16:39:01,568 - ERROR - Device mismatch in batch 2
2025-10-05 16:39:01,569 - ERROR - Images device: cuda:0
2025-10-05 16:39:01,569 - ERROR - Targets device: cuda:0
2025-10-05 16:39:01,787 - ERROR - Device mismatch in batch 3
2025-10-05 16:39:01,787 - ERROR - Images device: cuda:0
2025-10-05 16:39:01,787 - ERROR - Targets device: cuda:0
2025-10-05 16:39:02,040 - ERROR - Device mismatch in batch 4
2025-10-05 16:39:02,041 - ERROR - Images device: cuda:0
2025-10-05 16:39:02,041 - ERROR - Targets device: cuda:0
2025-10-05 16:39:02,285 - ERROR - Device mismatch in batch 5
2025-10-05 16:39:02,285 - ERROR - Images device: cuda:0
2025-10-05 16:39:02,286 - ERROR - Targets device: cuda:0
2025-10-05 16:39:02,502 - ERROR - Device mismatch in batch 6
2025-10-05 16:39:02,502 - ERROR - Images device: cuda:0
2025-10-05 16:39:02,503 - ERROR - Targets device: cuda:0
2025-10-05 16:39:02,722 - ERROR - Device mismatch in batch 7
2025-10-05 16:39:02,722 - ERROR - Images device: cuda:0
2025-10-05 16:39:02,722 - ERROR - Targets device: cuda:0
2025-10-05 16:39:02,903 - ERROR - Device mismatch in batch 8
2025-10-05 16:39:02,904 - ERROR - Images device: cuda:0
2025-10-05 16:39:02,904 - ERROR - Targets device: cuda:0
2025-10-05 16:39:03,109 - ERROR - Device mismatch in batch 9
2025-10-05 16:39:03,109 - ERROR - Images device: cuda:0
2025-10-05 16:39:03,109 - ERROR - Targets device: cuda:0
2025-10-05 16:39:03,367 - ERROR - Device mismatch in batch 10
2025-10-05 16:39:03,367 - ERROR - Images device: cuda:0
2025-10-05 16:39:03,367 - ERROR - Targets device: cuda:0
2025-10-05 16:39:03,600 - ERROR - Device mismatch in batch 11
2025-10-05 16:39:03,600 - ERROR - Images device: cuda:0
2025-10-05 16:39:03,600 - ERROR - Targets device: cuda:0
2025-10-05 16:39:03,834 - ERROR - Device mismatch in batch 12
2025-10-05 16:39:03,834 - ERROR - Images device: cuda:0
2025-10-05 16:39:03,834 - ERROR - Targets device: cuda:0
2025-10-05 16:39:04,053 - ERROR - Device mismatch in batch 13
2025-10-05 16:39:04,053 - ERROR - Images device: cuda:0
2025-10-05 16:39:04,053 - ERROR - Targets device: cuda:0
2025-10-05 16:39:04,268 - ERROR - Device mismatch in batch 14
2025-10-05 16:39:04,269 - ERROR - Images device: cuda:0
2025-10-05 16:39:04,269 - ERROR - Targets device: cuda:0
2025-10-05 16:39:04,456 - ERROR - Device mismatch in batch 15
2025-10-05 16:39:04,456 - ERROR - Images device: cuda:0
2025-10-05 16:39:04,456 - ERROR - Targets device: cuda:0
2025-10-05 16:39:04,701 - ERROR - Device mismatch in batch 16
2025-10-05 16:39:04,701 - ERROR - Images device: cuda:0
2025-10-05 16:39:04,701 - ERROR - Targets device: cuda:0
2025-10-05 16:39:04,894 - ERROR - Device mismatch in batch 17
2025-10-05 16:39:04,894 - ERROR - Images device: cuda:0
2025-10-05 16:39:04,894 - ERROR - Targets device: cuda:0
2025-10-05 16:39:05,139 - ERROR - Device mismatch in batch 18
2025-10-05 16:39:05,139 - ERROR - Images device: cuda:0
2025-10-05 16:39:05,139 - ERROR - Targets device: cuda:0
2025-10-05 16:39:05,366 - ERROR - Device mismatch in batch 19
2025-10-05 16:39:05,366 - ERROR - Images device: cuda:0
2025-10-05 16:39:05,366 - ERROR - Targets device: cuda:0
2025-10-05 16:39:05,579 - ERROR - Device mismatch in batch 20
2025-10-05 16:39:05,580 - ERROR - Images device: cuda:0
2025-10-05 16:39:05,580 - ERROR - Targets device: cuda:0
2025-10-05 16:39:05,803 - ERROR - Device mismatch in batch 21
2025-10-05 16:39:05,803 - ERROR - Images device: cuda:0
2025-10-05 16:39:05,803 - ERROR - Targets device: cuda:0
2025-10-05 16:39:06,034 - ERROR - Device mismatch in batch 22
2025-10-05 16:39:06,035 - ERROR - Images device: cuda:0
2025-10-05 16:39:06,035 - ERROR - Targets device: cuda:0
2025-10-05 16:39:06,226 - ERROR - Device mismatch in batch 23
2025-10-05 16:39:06,227 - ERROR - Images device: cuda:0
2025-10-05 16:39:06,227 - ERROR - Targets device: cuda:0
2025-10-05 16:39:06,463 - ERROR - Device mismatch in batch 24
2025-10-05 16:39:06,463 - ERROR - Images device: cuda:0
2025-10-05 16:39:06,464 - ERROR - Targets device: cuda:0
2025-10-05 16:39:06,677 - ERROR - Device mismatch in batch 25
2025-10-05 16:39:06,677 - ERROR - Images device: cuda:0
2025-10-05 16:39:06,677 - ERROR - Targets device: cuda:0
2025-10-05 16:39:06,906 - ERROR - Device mismatch in batch 26
2025-10-05 16:39:06,907 - ERROR - Images device: cuda:0
2025-10-05 16:39:06,907 - ERROR - Targets device: cuda:0
2025-10-05 16:39:07,106 - ERROR - Device mismatch in batch 27
2025-10-05 16:39:07,106 - ERROR - Images device: cuda:0
2025-10-05 16:39:07,107 - ERROR - Targets device: cuda:0
2025-10-05 16:39:07,306 - ERROR - Device mismatch in batch 28
2025-10-05 16:39:07,306 - ERROR - Images device: cuda:0
2025-10-05 16:39:07,307 - ERROR - Targets device: cuda:0
2025-10-05 16:39:07,513 - ERROR - Device mismatch in batch 29
2025-10-05 16:39:07,514 - ERROR - Images device: cuda:0
2025-10-05 16:39:07,514 - ERROR - Targets device: cuda:0
2025-10-05 16:39:07,810 - ERROR - Device mismatch in batch 30
2025-10-05 16:39:07,811 - ERROR - Images device: cuda:0
2025-10-05 16:39:07,811 - ERROR - Targets device: cuda:0
2025-10-05 16:39:08,137 - ERROR - Device mismatch in batch 31
2025-10-05 16:39:08,137 - ERROR - Images device: cuda:0
2025-10-05 16:39:08,138 - ERROR - Targets device: cuda:0
2025-10-05 16:39:08,420 - ERROR - Device mismatch in batch 32
2025-10-05 16:39:08,420 - ERROR - Images device: cuda:0
2025-10-05 16:39:08,420 - ERROR - Targets device: cuda:0
2025-10-05 16:39:08,606 - ERROR - Device mismatch in batch 33
2025-10-05 16:39:08,607 - ERROR - Images device: cuda:0
2025-10-05 16:39:08,607 - ERROR - Targets device: cuda:0
2025-10-05 16:39:08,815 - ERROR - Device mismatch in batch 34
2025-10-05 16:39:08,815 - ERROR - Images device: cuda:0
2025-10-05 16:39:08,816 - ERROR - Targets device: cuda:0
2025-10-05 16:39:09,036 - ERROR - Device mismatch in batch 35
2025-10-05 16:39:09,036 - ERROR - Images device: cuda:0
2025-10-05 16:39:09,036 - ERROR - Targets device: cuda:0
2025-10-05 16:39:09,256 - ERROR - Device mismatch in batch 36
2025-10-05 16:39:09,256 - ERROR - Images device: cuda:0
2025-10-05 16:39:09,256 - ERROR - Targets device: cuda:0
2025-10-05 16:39:09,472 - ERROR - Device mismatch in batch 37
2025-10-05 16:39:09,472 - ERROR - Images device: cuda:0
2025-10-05 16:39:09,472 - ERROR - Targets device: cuda:0
2025-10-05 16:39:09,707 - ERROR - Device mismatch in batch 38
2025-10-05 16:39:09,707 - ERROR - Images device: cuda:0
2025-10-05 16:39:09,708 - ERROR - Targets device: cuda:0
2025-10-05 16:39:09,948 - ERROR - Device mismatch in batch 39
2025-10-05 16:39:09,948 - ERROR - Images device: cuda:0
2025-10-05 16:39:09,948 - ERROR - Targets device: cuda:0
2025-10-05 16:39:10,151 - ERROR - Device mismatch in batch 40
2025-10-05 16:39:10,151 - ERROR - Images device: cuda:0
2025-10-05 16:39:10,152 - ERROR - Targets device: cuda:0
2025-10-05 16:39:10,407 - ERROR - Device mismatch in batch 41
2025-10-05 16:39:10,407 - ERROR - Images device: cuda:0
2025-10-05 16:39:10,407 - ERROR - Targets device: cuda:0
2025-10-05 16:39:10,628 - ERROR - Device mismatch in batch 42
2025-10-05 16:39:10,638 - ERROR - Images device: cuda:0
2025-10-05 16:39:10,638 - ERROR - Targets device: cuda:0
2025-10-05 16:39:10,866 - ERROR - Device mismatch in batch 43
2025-10-05 16:39:10,867 - ERROR - Images device: cuda:0
2025-10-05 16:39:10,867 - ERROR - Targets device: cuda:0
2025-10-05 16:39:11,093 - ERROR - Device mismatch in batch 44
2025-10-05 16:39:11,094 - ERROR - Images device: cuda:0
2025-10-05 16:39:11,094 - ERROR - Targets device: cuda:0
2025-10-05 16:39:11,293 - ERROR - Device mismatch in batch 45
2025-10-05 16:39:11,294 - ERROR - Images device: cuda:0
2025-10-05 16:39:11,294 - ERROR - Targets device: cuda:0
2025-10-05 16:39:11,529 - ERROR - Device mismatch in batch 46
2025-10-05 16:39:11,529 - ERROR - Images device: cuda:0
2025-10-05 16:39:11,529 - ERROR - Targets device: cuda:0
2025-10-05 16:39:11,722 - ERROR - Device mismatch in batch 47
2025-10-05 16:39:11,722 - ERROR - Images device: cuda:0
2025-10-05 16:39:11,722 - ERROR - Targets device: cuda:0
2025-10-05 16:39:11,934 - ERROR - Device mismatch in batch 48
2025-10-05 16:39:11,934 - ERROR - Images device: cuda:0
2025-10-05 16:39:11,934 - ERROR - Targets device: cuda:0
2025-10-05 16:39:12,124 - ERROR - Device mismatch in batch 49
2025-10-05 16:39:12,124 - ERROR - Images device: cuda:0
2025-10-05 16:39:12,124 - ERROR - Targets device: cuda:0
2025-10-05 16:39:12,383 - ERROR - Device mismatch in batch 50
2025-10-05 16:39:12,383 - ERROR - Images device: cuda:0
2025-10-05 16:39:12,383 - ERROR - Targets device: cuda:0
2025-10-05 16:39:12,588 - ERROR - Device mismatch in batch 51
2025-10-05 16:39:12,588 - ERROR - Images device: cuda:0
2025-10-05 16:39:12,588 - ERROR - Targets device: cuda:0
2025-10-05 16:39:12,883 - ERROR - Device mismatch in batch 52
2025-10-05 16:39:12,883 - ERROR - Images device: cuda:0
2025-10-05 16:39:12,883 - ERROR - Targets device: cuda:0
2025-10-05 16:39:13,123 - ERROR - Device mismatch in batch 53
2025-10-05 16:39:13,123 - ERROR - Images device: cuda:0
2025-10-05 16:39:13,123 - ERROR - Targets device: cuda:0
2025-10-05 16:39:13,348 - ERROR - Device mismatch in batch 54
2025-10-05 16:39:13,348 - ERROR - Images device: cuda:0
2025-10-05 16:39:13,348 - ERROR - Targets device: cuda:0
2025-10-05 16:39:13,573 - ERROR - Device mismatch in batch 55
2025-10-05 16:39:13,573 - ERROR - Images device: cuda:0
2025-10-05 16:39:13,573 - ERROR - Targets device: cuda:0
2025-10-05 16:39:13,796 - ERROR - Device mismatch in batch 56
2025-10-05 16:39:13,796 - ERROR - Images device: cuda:0
2025-10-05 16:39:13,796 - ERROR - Targets device: cuda:0
2025-10-05 16:39:13,997 - ERROR - Device mismatch in batch 57
2025-10-05 16:39:13,997 - ERROR - Images device: cuda:0
2025-10-05 16:39:13,997 - ERROR - Targets device: cuda:0
2025-10-05 16:39:14,238 - ERROR - Device mismatch in batch 58
2025-10-05 16:39:14,238 - ERROR - Images device: cuda:0
2025-10-05 16:39:14,238 - ERROR - Targets device: cuda:0
2025-10-05 16:39:14,502 - ERROR - Device mismatch in batch 59
2025-10-05 16:39:14,502 - ERROR - Images device: cuda:0
2025-10-05 16:39:14,502 - ERROR - Targets device: cuda:0
2025-10-05 16:39:14,719 - ERROR - Device mismatch in batch 60
2025-10-05 16:39:14,720 - ERROR - Images device: cuda:0
2025-10-05 16:39:14,720 - ERROR - Targets device: cuda:0
2025-10-05 16:39:14,929 - ERROR - Device mismatch in batch 61
2025-10-05 16:39:14,930 - ERROR - Images device: cuda:0
2025-10-05 16:39:14,930 - ERROR - Targets device: cuda:0
2025-10-05 16:39:15,193 - ERROR - Device mismatch in batch 62
2025-10-05 16:39:15,193 - ERROR - Images device: cuda:0
2025-10-05 16:39:15,194 - ERROR - Targets device: cuda:0
2025-10-05 16:39:15,388 - ERROR - Device mismatch in batch 63
2025-10-05 16:39:15,388 - ERROR - Images device: cuda:0
2025-10-05 16:39:15,388 - ERROR - Targets device: cuda:0
2025-10-05 16:39:15,615 - ERROR - Device mismatch in batch 64
2025-10-05 16:39:15,616 - ERROR - Images device: cuda:0
2025-10-05 16:39:15,616 - ERROR - Targets device: cuda:0
2025-10-05 16:39:15,866 - ERROR - Device mismatch in batch 65
2025-10-05 16:39:15,867 - ERROR - Images device: cuda:0
2025-10-05 16:39:15,867 - ERROR - Targets device: cuda:0
2025-10-05 16:39:16,087 - ERROR - Device mismatch in batch 66
2025-10-05 16:39:16,088 - ERROR - Images device: cuda:0
2025-10-05 16:39:16,088 - ERROR - Targets device: cuda:0
2025-10-05 16:39:16,274 - ERROR - Device mismatch in batch 67
2025-10-05 16:39:16,274 - ERROR - Images device: cuda:0
2025-10-05 16:39:16,274 - ERROR - Targets device: cuda:0
2025-10-05 16:39:16,470 - ERROR - Device mismatch in batch 68
2025-10-05 16:39:16,470 - ERROR - Images device: cuda:0
2025-10-05 16:39:16,471 - ERROR - Targets device: cuda:0
2025-10-05 16:39:16,662 - ERROR - Device mismatch in batch 69
2025-10-05 16:39:16,663 - ERROR - Images device: cuda:0
2025-10-05 16:39:16,663 - ERROR - Targets device: cuda:0
2025-10-05 16:39:16,855 - ERROR - Device mismatch in batch 70
2025-10-05 16:39:16,856 - ERROR - Images device: cuda:0
2025-10-05 16:39:16,856 - ERROR - Targets device: cuda:0
2025-10-05 16:39:17,066 - ERROR - Device mismatch in batch 71
2025-10-05 16:39:17,067 - ERROR - Images device: cuda:0
2025-10-05 16:39:17,067 - ERROR - Targets device: cuda:0
2025-10-05 16:39:17,276 - ERROR - Device mismatch in batch 72
2025-10-05 16:39:17,276 - ERROR - Images device: cuda:0
2025-10-05 16:39:17,276 - ERROR - Targets device: cuda:0
2025-10-05 16:39:17,504 - ERROR - Device mismatch in batch 73
2025-10-05 16:39:17,505 - ERROR - Images device: cuda:0
2025-10-05 16:39:17,505 - ERROR - Targets device: cuda:0
2025-10-05 16:39:17,791 - ERROR - Device mismatch in batch 74
2025-10-05 16:39:17,791 - ERROR - Images device: cuda:0
2025-10-05 16:39:17,792 - ERROR - Targets device: cuda:0
2025-10-05 16:39:18,012 - ERROR - Device mismatch in batch 75
2025-10-05 16:39:18,013 - ERROR - Images device: cuda:0
2025-10-05 16:39:18,013 - ERROR - Targets device: cuda:0
2025-10-05 16:39:18,285 - ERROR - Device mismatch in batch 76
2025-10-05 16:39:18,286 - ERROR - Images device: cuda:0
2025-10-05 16:39:18,286 - ERROR - Targets device: cuda:0
2025-10-05 16:39:18,504 - ERROR - Device mismatch in batch 77
2025-10-05 16:39:18,504 - ERROR - Images device: cuda:0
2025-10-05 16:39:18,504 - ERROR - Targets device: cuda:0
2025-10-05 16:39:18,715 - ERROR - Device mismatch in batch 78
2025-10-05 16:39:18,715 - ERROR - Images device: cuda:0
2025-10-05 16:39:18,716 - ERROR - Targets device: cuda:0
2025-10-05 16:39:18,941 - ERROR - Device mismatch in batch 79
2025-10-05 16:39:18,941 - ERROR - Images device: cuda:0
2025-10-05 16:39:18,941 - ERROR - Targets device: cuda:0
2025-10-05 16:39:19,163 - ERROR - Device mismatch in batch 80
2025-10-05 16:39:19,163 - ERROR - Images device: cuda:0
2025-10-05 16:39:19,163 - ERROR - Targets device: cuda:0
2025-10-05 16:39:19,380 - ERROR - Device mismatch in batch 81
2025-10-05 16:39:19,380 - ERROR - Images device: cuda:0
2025-10-05 16:39:19,380 - ERROR - Targets device: cuda:0
2025-10-05 16:39:19,620 - ERROR - Device mismatch in batch 82
2025-10-05 16:39:19,620 - ERROR - Images device: cuda:0
2025-10-05 16:39:19,621 - ERROR - Targets device: cuda:0
2025-10-05 16:39:19,883 - ERROR - Device mismatch in batch 83
2025-10-05 16:39:19,883 - ERROR - Images device: cuda:0
2025-10-05 16:39:19,884 - ERROR - Targets device: cuda:0
2025-10-05 16:39:20,120 - ERROR - Device mismatch in batch 84
2025-10-05 16:39:20,120 - ERROR - Images device: cuda:0
2025-10-05 16:39:20,120 - ERROR - Targets device: cuda:0
2025-10-05 16:39:20,369 - ERROR - Device mismatch in batch 85
2025-10-05 16:39:20,369 - ERROR - Images device: cuda:0
2025-10-05 16:39:20,369 - ERROR - Targets device: cuda:0
2025-10-05 16:39:20,592 - ERROR - Device mismatch in batch 86
2025-10-05 16:39:20,592 - ERROR - Images device: cuda:0
2025-10-05 16:39:20,592 - ERROR - Targets device: cuda:0
2025-10-05 16:39:20,903 - ERROR - Device mismatch in batch 87
2025-10-05 16:39:20,903 - ERROR - Images device: cuda:0
2025-10-05 16:39:20,903 - ERROR - Targets device: cuda:0
2025-10-05 16:39:21,134 - ERROR - Device mismatch in batch 88
2025-10-05 16:39:21,134 - ERROR - Images device: cuda:0
2025-10-05 16:39:21,134 - ERROR - Targets device: cuda:0
2025-10-05 16:39:21,380 - ERROR - Device mismatch in batch 89
2025-10-05 16:39:21,380 - ERROR - Images device: cuda:0
2025-10-05 16:39:21,381 - ERROR - Targets device: cuda:0
2025-10-05 16:39:21,600 - ERROR - Device mismatch in batch 90
2025-10-05 16:39:21,600 - ERROR - Images device: cuda:0
2025-10-05 16:39:21,600 - ERROR - Targets device: cuda:0
2025-10-05 16:39:21,811 - ERROR - Device mismatch in batch 91
2025-10-05 16:39:21,812 - ERROR - Images device: cuda:0
2025-10-05 16:39:21,812 - ERROR - Targets device: cuda:0
2025-10-05 16:39:22,011 - ERROR - Device mismatch in batch 92
2025-10-05 16:39:22,011 - ERROR - Images device: cuda:0
2025-10-05 16:39:22,012 - ERROR - Targets device: cuda:0
2025-10-05 16:39:22,212 - ERROR - Device mismatch in batch 93
2025-10-05 16:39:22,212 - ERROR - Images device: cuda:0
2025-10-05 16:39:22,212 - ERROR - Targets device: cuda:0
2025-10-05 16:39:22,477 - ERROR - Device mismatch in batch 94
2025-10-05 16:39:22,477 - ERROR - Images device: cuda:0
2025-10-05 16:39:22,477 - ERROR - Targets device: cuda:0
2025-10-05 16:39:22,707 - ERROR - Device mismatch in batch 95
2025-10-05 16:39:22,707 - ERROR - Images device: cuda:0
2025-10-05 16:39:22,707 - ERROR - Targets device: cuda:0
2025-10-05 16:39:22,939 - ERROR - Device mismatch in batch 96
2025-10-05 16:39:22,940 - ERROR - Images device: cuda:0
2025-10-05 16:39:22,940 - ERROR - Targets device: cuda:0
2025-10-05 16:39:23,203 - ERROR - Device mismatch in batch 97
2025-10-05 16:39:23,203 - ERROR - Images device: cuda:0
2025-10-05 16:39:23,203 - ERROR - Targets device: cuda:0
2025-10-05 16:39:23,469 - ERROR - Device mismatch in batch 98
2025-10-05 16:39:23,469 - ERROR - Images device: cuda:0
2025-10-05 16:39:23,469 - ERROR - Targets device: cuda:0
2025-10-05 16:39:23,715 - ERROR - Device mismatch in batch 99
2025-10-05 16:39:23,716 - ERROR - Images device: cuda:0
2025-10-05 16:39:23,716 - ERROR - Targets device: cuda:0
2025-10-05 16:39:23,934 - ERROR - Device mismatch in batch 100
2025-10-05 16:39:23,935 - ERROR - Images device: cuda:0
2025-10-05 16:39:23,935 - ERROR - Targets device: cuda:0
2025-10-05 16:39:24,158 - ERROR - Device mismatch in batch 101
2025-10-05 16:39:24,158 - ERROR - Images device: cuda:0
2025-10-05 16:39:24,158 - ERROR - Targets device: cuda:0
2025-10-05 16:39:24,383 - ERROR - Device mismatch in batch 102
2025-10-05 16:39:24,383 - ERROR - Images device: cuda:0
2025-10-05 16:39:24,384 - ERROR - Targets device: cuda:0
2025-10-05 16:39:24,662 - ERROR - Device mismatch in batch 103
2025-10-05 16:39:24,662 - ERROR - Images device: cuda:0
2025-10-05 16:39:24,662 - ERROR - Targets device: cuda:0
2025-10-05 16:39:24,869 - ERROR - Device mismatch in batch 104
2025-10-05 16:39:24,869 - ERROR - Images device: cuda:0
2025-10-05 16:39:24,869 - ERROR - Targets device: cuda:0
2025-10-05 16:39:25,170 - ERROR - Device mismatch in batch 105
2025-10-05 16:39:25,170 - ERROR - Images device: cuda:0
2025-10-05 16:39:25,170 - ERROR - Targets device: cuda:0
2025-10-05 16:39:25,419 - ERROR - Device mismatch in batch 106
2025-10-05 16:39:25,419 - ERROR - Images device: cuda:0
2025-10-05 16:39:25,419 - ERROR - Targets device: cuda:0
2025-10-05 16:39:25,704 - ERROR - Device mismatch in batch 107
2025-10-05 16:39:25,704 - ERROR - Images device: cuda:0
2025-10-05 16:39:25,704 - ERROR - Targets device: cuda:0
2025-10-05 16:39:25,950 - ERROR - Device mismatch in batch 108
2025-10-05 16:39:25,950 - ERROR - Images device: cuda:0
2025-10-05 16:39:25,951 - ERROR - Targets device: cuda:0
2025-10-05 16:39:26,170 - ERROR - Device mismatch in batch 109
2025-10-05 16:39:26,170 - ERROR - Images device: cuda:0
2025-10-05 16:39:26,170 - ERROR - Targets device: cuda:0
2025-10-05 16:39:26,390 - ERROR - Device mismatch in batch 110
2025-10-05 16:39:26,390 - ERROR - Images device: cuda:0
2025-10-05 16:39:26,390 - ERROR - Targets device: cuda:0
2025-10-05 16:39:26,608 - ERROR - Device mismatch in batch 111
2025-10-05 16:39:26,609 - ERROR - Images device: cuda:0
2025-10-05 16:39:26,609 - ERROR - Targets device: cuda:0
2025-10-05 16:39:26,907 - ERROR - Device mismatch in batch 112
2025-10-05 16:39:26,907 - ERROR - Images device: cuda:0
2025-10-05 16:39:26,908 - ERROR - Targets device: cuda:0
2025-10-05 16:39:27,148 - ERROR - Device mismatch in batch 113
2025-10-05 16:39:27,148 - ERROR - Images device: cuda:0
2025-10-05 16:39:27,149 - ERROR - Targets device: cuda:0
2025-10-05 16:39:27,428 - ERROR - Device mismatch in batch 114
2025-10-05 16:39:27,428 - ERROR - Images device: cuda:0
2025-10-05 16:39:27,429 - ERROR - Targets device: cuda:0
2025-10-05 16:39:27,710 - ERROR - Device mismatch in batch 115
2025-10-05 16:39:27,710 - ERROR - Images device: cuda:0
2025-10-05 16:39:27,711 - ERROR - Targets device: cuda:0
2025-10-05 16:39:27,934 - ERROR - Device mismatch in batch 116
2025-10-05 16:39:27,935 - ERROR - Images device: cuda:0
2025-10-05 16:39:27,935 - ERROR - Targets device: cuda:0
2025-10-05 16:39:28,172 - ERROR - Device mismatch in batch 117
2025-10-05 16:39:28,172 - ERROR - Images device: cuda:0
2025-10-05 16:39:28,172 - ERROR - Targets device: cuda:0
2025-10-05 16:39:28,435 - ERROR - Device mismatch in batch 118
2025-10-05 16:39:28,436 - ERROR - Images device: cuda:0
2025-10-05 16:39:28,436 - ERROR - Targets device: cuda:0
2025-10-05 16:39:28,696 - ERROR - Device mismatch in batch 119
2025-10-05 16:39:28,696 - ERROR - Images device: cuda:0
2025-10-05 16:39:28,696 - ERROR - Targets device: cuda:0
2025-10-05 16:39:28,937 - ERROR - Device mismatch in batch 120
2025-10-05 16:39:28,937 - ERROR - Images device: cuda:0
2025-10-05 16:39:28,937 - ERROR - Targets device: cuda:0
2025-10-05 16:39:29,218 - ERROR - Device mismatch in batch 121
2025-10-05 16:39:29,219 - ERROR - Images device: cuda:0
2025-10-05 16:39:29,219 - ERROR - Targets device: cuda:0
2025-10-05 16:39:29,477 - ERROR - Device mismatch in batch 122
2025-10-05 16:39:29,477 - ERROR - Images device: cuda:0
2025-10-05 16:39:29,477 - ERROR - Targets device: cuda:0
2025-10-05 16:39:29,709 - ERROR - Device mismatch in batch 123
2025-10-05 16:39:29,709 - ERROR - Images device: cuda:0
2025-10-05 16:39:29,710 - ERROR - Targets device: cuda:0
2025-10-05 16:39:29,933 - ERROR - Device mismatch in batch 124
2025-10-05 16:39:29,933 - ERROR - Images device: cuda:0
2025-10-05 16:39:29,933 - ERROR - Targets device: cuda:0
2025-10-05 16:39:30,151 - ERROR - Device mismatch in batch 125
2025-10-05 16:39:30,151 - ERROR - Images device: cuda:0
2025-10-05 16:39:30,151 - ERROR - Targets device: cuda:0
2025-10-05 16:39:30,370 - ERROR - Device mismatch in batch 126
2025-10-05 16:39:30,370 - ERROR - Images device: cuda:0
2025-10-05 16:39:30,370 - ERROR - Targets device: cuda:0
2025-10-05 16:39:30,663 - ERROR - Device mismatch in batch 127
2025-10-05 16:39:30,664 - ERROR - Images device: cuda:0
2025-10-05 16:39:30,665 - ERROR - Targets device: cuda:0
2025-10-05 16:39:30,899 - ERROR - Device mismatch in batch 128
2025-10-05 16:39:30,899 - ERROR - Images device: cuda:0
2025-10-05 16:39:30,899 - ERROR - Targets device: cuda:0
2025-10-05 16:39:31,158 - ERROR - Device mismatch in batch 129
2025-10-05 16:39:31,158 - ERROR - Images device: cuda:0
2025-10-05 16:39:31,158 - ERROR - Targets device: cuda:0
2025-10-05 16:39:31,374 - ERROR - Device mismatch in batch 130
2025-10-05 16:39:31,375 - ERROR - Images device: cuda:0
2025-10-05 16:39:31,375 - ERROR - Targets device: cuda:0
2025-10-05 16:39:31,579 - ERROR - Device mismatch in batch 131
2025-10-05 16:39:31,579 - ERROR - Images device: cuda:0
2025-10-05 16:39:31,579 - ERROR - Targets device: cuda:0
2025-10-05 16:39:31,805 - ERROR - Device mismatch in batch 132
2025-10-05 16:39:31,805 - ERROR - Images device: cuda:0
2025-10-05 16:39:31,805 - ERROR - Targets device: cuda:0
2025-10-05 16:39:32,075 - ERROR - Device mismatch in batch 133
2025-10-05 16:39:32,075 - ERROR - Images device: cuda:0
2025-10-05 16:39:32,075 - ERROR - Targets device: cuda:0
2025-10-05 16:39:32,392 - ERROR - Device mismatch in batch 134
2025-10-05 16:39:32,392 - ERROR - Images device: cuda:0
2025-10-05 16:39:32,393 - ERROR - Targets device: cuda:0
2025-10-05 16:39:32,673 - ERROR - Device mismatch in batch 135
2025-10-05 16:39:32,673 - ERROR - Images device: cuda:0
2025-10-05 16:39:32,673 - ERROR - Targets device: cuda:0
2025-10-05 16:39:32,917 - ERROR - Device mismatch in batch 136
2025-10-05 16:39:32,918 - ERROR - Images device: cuda:0
2025-10-05 16:39:32,918 - ERROR - Targets device: cuda:0
2025-10-05 16:39:33,141 - ERROR - Device mismatch in batch 137
2025-10-05 16:39:33,142 - ERROR - Images device: cuda:0
2025-10-05 16:39:33,142 - ERROR - Targets device: cuda:0
2025-10-05 16:39:33,372 - ERROR - Device mismatch in batch 138
2025-10-05 16:39:33,373 - ERROR - Images device: cuda:0
2025-10-05 16:39:33,373 - ERROR - Targets device: cuda:0
2025-10-05 16:39:33,559 - ERROR - Device mismatch in batch 139
2025-10-05 16:39:33,566 - ERROR - Images device: cuda:0
2025-10-05 16:39:33,566 - ERROR - Targets device: cuda:0
2025-10-05 16:39:33,810 - ERROR - Device mismatch in batch 140
2025-10-05 16:39:33,810 - ERROR - Images device: cuda:0
2025-10-05 16:39:33,810 - ERROR - Targets device: cuda:0
2025-10-05 16:39:34,031 - ERROR - Device mismatch in batch 141
2025-10-05 16:39:34,032 - ERROR - Images device: cuda:0
2025-10-05 16:39:34,032 - ERROR - Targets device: cuda:0
2025-10-05 16:39:34,287 - ERROR - Device mismatch in batch 142
2025-10-05 16:39:34,287 - ERROR - Images device: cuda:0
2025-10-05 16:39:34,287 - ERROR - Targets device: cuda:0
2025-10-05 16:39:34,537 - ERROR - Device mismatch in batch 143
2025-10-05 16:39:34,538 - ERROR - Images device: cuda:0
2025-10-05 16:39:34,538 - ERROR - Targets device: cuda:0
2025-10-05 16:39:34,803 - ERROR - Device mismatch in batch 144
2025-10-05 16:39:34,803 - ERROR - Images device: cuda:0
2025-10-05 16:39:34,804 - ERROR - Targets device: cuda:0
2025-10-05 16:39:35,018 - ERROR - Device mismatch in batch 145
2025-10-05 16:39:35,018 - ERROR - Images device: cuda:0
2025-10-05 16:39:35,018 - ERROR - Targets device: cuda:0
2025-10-05 16:39:35,248 - ERROR - Device mismatch in batch 146
2025-10-05 16:39:35,248 - ERROR - Images device: cuda:0
2025-10-05 16:39:35,248 - ERROR - Targets device: cuda:0
2025-10-05 16:39:35,481 - ERROR - Device mismatch in batch 147
2025-10-05 16:39:35,481 - ERROR - Images device: cuda:0
2025-10-05 16:39:35,481 - ERROR - Targets device: cuda:0
2025-10-05 16:39:35,696 - ERROR - Device mismatch in batch 148
2025-10-05 16:39:35,696 - ERROR - Images device: cuda:0
2025-10-05 16:39:35,696 - ERROR - Targets device: cuda:0
2025-10-05 16:39:35,957 - ERROR - Device mismatch in batch 149
2025-10-05 16:39:35,957 - ERROR - Images device: cuda:0
2025-10-05 16:39:35,957 - ERROR - Targets device: cuda:0
2025-10-05 16:39:36,211 - ERROR - Device mismatch in batch 150
2025-10-05 16:39:36,212 - ERROR - Images device: cuda:0
2025-10-05 16:39:36,212 - ERROR - Targets device: cuda:0
2025-10-05 16:39:36,440 - ERROR - Device mismatch in batch 151
2025-10-05 16:39:36,440 - ERROR - Images device: cuda:0
2025-10-05 16:39:36,440 - ERROR - Targets device: cuda:0
2025-10-05 16:39:36,686 - ERROR - Device mismatch in batch 152
2025-10-05 16:39:36,687 - ERROR - Images device: cuda:0
2025-10-05 16:39:36,687 - ERROR - Targets device: cuda:0
2025-10-05 16:39:36,917 - ERROR - Device mismatch in batch 153
2025-10-05 16:39:36,917 - ERROR - Images device: cuda:0
2025-10-05 16:39:36,917 - ERROR - Targets device: cuda:0
2025-10-05 16:39:37,147 - ERROR - Device mismatch in batch 154
2025-10-05 16:39:37,147 - ERROR - Images device: cuda:0
2025-10-05 16:39:37,147 - ERROR - Targets device: cuda:0
2025-10-05 16:39:37,374 - ERROR - Device mismatch in batch 155
2025-10-05 16:39:37,375 - ERROR - Images device: cuda:0
2025-10-05 16:39:37,375 - ERROR - Targets device: cuda:0
2025-10-05 16:39:37,593 - ERROR - Device mismatch in batch 156
2025-10-05 16:39:37,593 - ERROR - Images device: cuda:0
2025-10-05 16:39:37,594 - ERROR - Targets device: cuda:0
2025-10-05 16:39:37,857 - ERROR - Device mismatch in batch 157
2025-10-05 16:39:37,857 - ERROR - Images device: cuda:0
2025-10-05 16:39:37,857 - ERROR - Targets device: cuda:0
2025-10-05 16:39:38,154 - ERROR - Device mismatch in batch 158
2025-10-05 16:39:38,154 - ERROR - Images device: cuda:0
2025-10-05 16:39:38,155 - ERROR - Targets device: cuda:0
2025-10-05 16:39:38,364 - ERROR - Device mismatch in batch 159
2025-10-05 16:39:38,364 - ERROR - Images device: cuda:0
2025-10-05 16:39:38,365 - ERROR - Targets device: cuda:0
2025-10-05 16:39:38,595 - ERROR - Device mismatch in batch 160
2025-10-05 16:39:38,595 - ERROR - Images device: cuda:0
2025-10-05 16:39:38,595 - ERROR - Targets device: cuda:0
2025-10-05 16:39:38,824 - ERROR - Device mismatch in batch 161
2025-10-05 16:39:38,824 - ERROR - Images device: cuda:0
2025-10-05 16:39:38,824 - ERROR - Targets device: cuda:0
2025-10-05 16:39:39,059 - ERROR - Device mismatch in batch 162
2025-10-05 16:39:39,059 - ERROR - Images device: cuda:0
2025-10-05 16:39:39,059 - ERROR - Targets device: cuda:0
2025-10-05 16:39:39,310 - ERROR - Device mismatch in batch 163
2025-10-05 16:39:39,310 - ERROR - Images device: cuda:0
2025-10-05 16:39:39,311 - ERROR - Targets device: cuda:0
2025-10-05 16:39:39,515 - ERROR - Device mismatch in batch 164
2025-10-05 16:39:39,515 - ERROR - Images device: cuda:0
2025-10-05 16:39:39,515 - ERROR - Targets device: cuda:0
2025-10-05 16:39:39,733 - ERROR - Device mismatch in batch 165
2025-10-05 16:39:39,733 - ERROR - Images device: cuda:0
2025-10-05 16:39:39,734 - ERROR - Targets device: cuda:0
2025-10-05 16:39:39,988 - ERROR - Device mismatch in batch 166
2025-10-05 16:39:39,989 - ERROR - Images device: cuda:0
2025-10-05 16:39:39,989 - ERROR - Targets device: cuda:0
2025-10-05 16:39:40,252 - ERROR - Device mismatch in batch 167
2025-10-05 16:39:40,252 - ERROR - Images device: cuda:0
2025-10-05 16:39:40,252 - ERROR - Targets device: cuda:0
2025-10-05 16:39:40,464 - ERROR - Device mismatch in batch 168
2025-10-05 16:39:40,465 - ERROR - Images device: cuda:0
2025-10-05 16:39:40,465 - ERROR - Targets device: cuda:0
2025-10-05 16:39:40,721 - ERROR - Device mismatch in batch 169
2025-10-05 16:39:40,722 - ERROR - Images device: cuda:0
2025-10-05 16:39:40,722 - ERROR - Targets device: cuda:0
2025-10-05 16:39:41,030 - ERROR - Device mismatch in batch 170
2025-10-05 16:39:41,030 - ERROR - Images device: cuda:0
2025-10-05 16:39:41,030 - ERROR - Targets device: cuda:0
2025-10-05 16:39:41,250 - ERROR - Device mismatch in batch 171
2025-10-05 16:39:41,250 - ERROR - Images device: cuda:0
2025-10-05 16:39:41,251 - ERROR - Targets device: cuda:0
2025-10-05 16:39:41,495 - ERROR - Device mismatch in batch 172
2025-10-05 16:39:41,495 - ERROR - Images device: cuda:0
2025-10-05 16:39:41,495 - ERROR - Targets device: cuda:0
2025-10-05 16:39:41,726 - ERROR - Device mismatch in batch 173
2025-10-05 16:39:41,733 - ERROR - Images device: cuda:0
2025-10-05 16:39:41,734 - ERROR - Targets device: cuda:0
2025-10-05 16:39:42,011 - ERROR - Device mismatch in batch 174
2025-10-05 16:39:42,011 - ERROR - Images device: cuda:0
2025-10-05 16:39:42,011 - ERROR - Targets device: cuda:0
2025-10-05 16:39:42,269 - ERROR - Device mismatch in batch 175
2025-10-05 16:39:42,269 - ERROR - Images device: cuda:0
2025-10-05 16:39:42,269 - ERROR - Targets device: cuda:0
2025-10-05 16:39:42,506 - ERROR - Device mismatch in batch 176
2025-10-05 16:39:42,507 - ERROR - Images device: cuda:0
2025-10-05 16:39:42,507 - ERROR - Targets device: cuda:0
2025-10-05 16:39:42,748 - ERROR - Device mismatch in batch 177
2025-10-05 16:39:42,748 - ERROR - Images device: cuda:0
2025-10-05 16:39:42,748 - ERROR - Targets device: cuda:0
2025-10-05 16:39:42,973 - ERROR - Device mismatch in batch 178
2025-10-05 16:39:42,973 - ERROR - Images device: cuda:0
2025-10-05 16:39:42,974 - ERROR - Targets device: cuda:0
2025-10-05 16:39:43,230 - ERROR - Device mismatch in batch 179
2025-10-05 16:39:43,231 - ERROR - Images device: cuda:0
2025-10-05 16:39:43,231 - ERROR - Targets device: cuda:0
2025-10-05 16:39:43,470 - ERROR - Device mismatch in batch 180
2025-10-05 16:39:43,470 - ERROR - Images device: cuda:0
2025-10-05 16:39:43,470 - ERROR - Targets device: cuda:0
2025-10-05 16:39:43,683 - ERROR - Device mismatch in batch 181
2025-10-05 16:39:43,684 - ERROR - Images device: cuda:0
2025-10-05 16:39:43,684 - ERROR - Targets device: cuda:0
2025-10-05 16:39:43,911 - ERROR - Device mismatch in batch 182
2025-10-05 16:39:43,912 - ERROR - Images device: cuda:0
2025-10-05 16:39:43,912 - ERROR - Targets device: cuda:0
2025-10-05 16:39:44,184 - ERROR - Device mismatch in batch 183
2025-10-05 16:39:44,184 - ERROR - Images device: cuda:0
2025-10-05 16:39:44,184 - ERROR - Targets device: cuda:0
2025-10-05 16:39:44,462 - ERROR - Device mismatch in batch 184
2025-10-05 16:39:44,462 - ERROR - Images device: cuda:0
2025-10-05 16:39:44,463 - ERROR - Targets device: cuda:0
2025-10-05 16:39:44,752 - ERROR - Device mismatch in batch 185
2025-10-05 16:39:44,753 - ERROR - Images device: cuda:0
2025-10-05 16:39:44,753 - ERROR - Targets device: cuda:0
2025-10-05 16:39:44,951 - ERROR - Device mismatch in batch 186
2025-10-05 16:39:44,951 - ERROR - Images device: cuda:0
2025-10-05 16:39:44,952 - ERROR - Targets device: cuda:0
2025-10-05 16:39:45,176 - ERROR - Device mismatch in batch 187
2025-10-05 16:39:45,177 - ERROR - Images device: cuda:0
2025-10-05 16:39:45,177 - ERROR - Targets device: cuda:0
2025-10-05 16:39:45,412 - ERROR - Device mismatch in batch 188
2025-10-05 16:39:45,412 - ERROR - Images device: cuda:0
2025-10-05 16:39:45,412 - ERROR - Targets device: cuda:0
2025-10-05 16:39:45,635 - ERROR - Device mismatch in batch 189
2025-10-05 16:39:45,635 - ERROR - Images device: cuda:0
2025-10-05 16:39:45,635 - ERROR - Targets device: cuda:0
2025-10-05 16:39:45,857 - ERROR - Device mismatch in batch 190
2025-10-05 16:39:45,857 - ERROR - Images device: cuda:0
2025-10-05 16:39:45,857 - ERROR - Targets device: cuda:0
2025-10-05 16:39:46,084 - ERROR - Device mismatch in batch 191
2025-10-05 16:39:46,084 - ERROR - Images device: cuda:0
2025-10-05 16:39:46,084 - ERROR - Targets device: cuda:0
2025-10-05 16:39:46,284 - ERROR - Device mismatch in batch 192
2025-10-05 16:39:46,284 - ERROR - Images device: cuda:0
2025-10-05 16:39:46,285 - ERROR - Targets device: cuda:0
2025-10-05 16:39:46,574 - ERROR - Device mismatch in batch 193
2025-10-05 16:39:46,574 - ERROR - Images device: cuda:0
2025-10-05 16:39:46,574 - ERROR - Targets device: cuda:0
2025-10-05 16:39:46,812 - ERROR - Device mismatch in batch 194
2025-10-05 16:39:46,812 - ERROR - Images device: cuda:0
2025-10-05 16:39:46,812 - ERROR - Targets device: cuda:0
2025-10-05 16:39:47,017 - ERROR - Device mismatch in batch 195
2025-10-05 16:39:47,018 - ERROR - Images device: cuda:0
2025-10-05 16:39:47,018 - ERROR - Targets device: cuda:0
2025-10-05 16:39:47,238 - ERROR - Device mismatch in batch 196
2025-10-05 16:39:47,238 - ERROR - Images device: cuda:0
2025-10-05 16:39:47,238 - ERROR - Targets device: cuda:0
2025-10-05 16:39:47,478 - ERROR - Device mismatch in batch 197
2025-10-05 16:39:47,478 - ERROR - Images device: cuda:0
2025-10-05 16:39:47,479 - ERROR - Targets device: cuda:0
2025-10-05 16:39:47,712 - ERROR - Device mismatch in batch 198
2025-10-05 16:39:47,712 - ERROR - Images device: cuda:0
2025-10-05 16:39:47,712 - ERROR - Targets device: cuda:0
2025-10-05 16:39:47,963 - ERROR - Device mismatch in batch 199
2025-10-05 16:39:47,963 - ERROR - Images device: cuda:0
2025-10-05 16:39:47,963 - ERROR - Targets device: cuda:0
2025-10-05 16:39:48,215 - ERROR - Device mismatch in batch 200
2025-10-05 16:39:48,216 - ERROR - Images device: cuda:0
2025-10-05 16:39:48,216 - ERROR - Targets device: cuda:0
2025-10-05 16:39:48,501 - ERROR - Device mismatch in batch 201
2025-10-05 16:39:48,502 - ERROR - Images device: cuda:0
2025-10-05 16:39:48,502 - ERROR - Targets device: cuda:0
2025-10-05 16:39:48,723 - ERROR - Device mismatch in batch 202
2025-10-05 16:39:48,723 - ERROR - Images device: cuda:0
2025-10-05 16:39:48,723 - ERROR - Targets device: cuda:0
2025-10-05 16:39:49,006 - ERROR - Device mismatch in batch 203
2025-10-05 16:39:49,007 - ERROR - Images device: cuda:0
2025-10-05 16:39:49,007 - ERROR - Targets device: cuda:0
2025-10-05 16:39:49,233 - ERROR - Device mismatch in batch 204
2025-10-05 16:39:49,233 - ERROR - Images device: cuda:0
2025-10-05 16:39:49,233 - ERROR - Targets device: cuda:0
2025-10-05 16:39:49,443 - ERROR - Device mismatch in batch 205
2025-10-05 16:39:49,443 - ERROR - Images device: cuda:0
2025-10-05 16:39:49,443 - ERROR - Targets device: cuda:0
2025-10-05 16:39:49,683 - ERROR - Device mismatch in batch 206
2025-10-05 16:39:49,683 - ERROR - Images device: cuda:0
2025-10-05 16:39:49,683 - ERROR - Targets device: cuda:0
2025-10-05 16:39:49,937 - ERROR - Device mismatch in batch 207
2025-10-05 16:39:49,937 - ERROR - Images device: cuda:0
2025-10-05 16:39:49,937 - ERROR - Targets device: cuda:0
2025-10-05 16:39:50,132 - ERROR - Device mismatch in batch 208
2025-10-05 16:39:50,133 - ERROR - Images device: cuda:0
2025-10-05 16:39:50,133 - ERROR - Targets device: cuda:0
2025-10-05 16:39:50,376 - ERROR - Device mismatch in batch 209
2025-10-05 16:39:50,376 - ERROR - Images device: cuda:0
2025-10-05 16:39:50,377 - ERROR - Targets device: cuda:0
2025-10-05 16:39:50,628 - ERROR - Device mismatch in batch 210
2025-10-05 16:39:50,628 - ERROR - Images device: cuda:0
2025-10-05 16:39:50,629 - ERROR - Targets device: cuda:0
2025-10-05 16:39:50,857 - ERROR - Device mismatch in batch 211
2025-10-05 16:39:50,857 - ERROR - Images device: cuda:0
2025-10-05 16:39:50,858 - ERROR - Targets device: cuda:0
2025-10-05 16:39:51,092 - ERROR - Device mismatch in batch 212
2025-10-05 16:39:51,093 - ERROR - Images device: cuda:0
2025-10-05 16:39:51,093 - ERROR - Targets device: cuda:0
2025-10-05 16:39:51,315 - ERROR - Device mismatch in batch 213
2025-10-05 16:39:51,315 - ERROR - Images device: cuda:0
2025-10-05 16:39:51,315 - ERROR - Targets device: cuda:0
2025-10-05 16:39:51,565 - ERROR - Device mismatch in batch 214
2025-10-05 16:39:51,566 - ERROR - Images device: cuda:0
2025-10-05 16:39:51,566 - ERROR - Targets device: cuda:0
2025-10-05 16:39:51,800 - ERROR - Device mismatch in batch 215
2025-10-05 16:39:51,801 - ERROR - Images device: cuda:0
2025-10-05 16:39:51,801 - ERROR - Targets device: cuda:0
2025-10-05 16:39:52,021 - ERROR - Device mismatch in batch 216
2025-10-05 16:39:52,022 - ERROR - Images device: cuda:0
2025-10-05 16:39:52,022 - ERROR - Targets device: cuda:0
2025-10-05 16:39:52,239 - ERROR - Device mismatch in batch 217
2025-10-05 16:39:52,239 - ERROR - Images device: cuda:0
2025-10-05 16:39:52,239 - ERROR - Targets device: cuda:0
2025-10-05 16:39:52,436 - ERROR - Device mismatch in batch 218
2025-10-05 16:39:52,436 - ERROR - Images device: cuda:0
2025-10-05 16:39:52,436 - ERROR - Targets device: cuda:0
2025-10-05 16:39:52,708 - ERROR - Device mismatch in batch 219
2025-10-05 16:39:52,708 - ERROR - Images device: cuda:0
2025-10-05 16:39:52,709 - ERROR - Targets device: cuda:0
2025-10-05 16:39:52,932 - ERROR - Device mismatch in batch 220
2025-10-05 16:39:52,933 - ERROR - Images device: cuda:0
2025-10-05 16:39:52,933 - ERROR - Targets device: cuda:0
2025-10-05 16:39:53,147 - ERROR - Device mismatch in batch 221
2025-10-05 16:39:53,147 - ERROR - Images device: cuda:0
2025-10-05 16:39:53,147 - ERROR - Targets device: cuda:0
2025-10-05 16:39:53,419 - ERROR - Device mismatch in batch 222
2025-10-05 16:39:53,419 - ERROR - Images device: cuda:0
2025-10-05 16:39:53,419 - ERROR - Targets device: cuda:0
2025-10-05 16:39:53,656 - ERROR - Device mismatch in batch 223
2025-10-05 16:39:53,657 - ERROR - Images device: cuda:0
2025-10-05 16:39:53,657 - ERROR - Targets device: cuda:0
2025-10-05 16:39:53,932 - ERROR - Device mismatch in batch 224
2025-10-05 16:39:53,932 - ERROR - Images device: cuda:0
2025-10-05 16:39:53,932 - ERROR - Targets device: cuda:0
2025-10-05 16:39:54,129 - ERROR - Device mismatch in batch 225
2025-10-05 16:39:54,129 - ERROR - Images device: cuda:0
2025-10-05 16:39:54,130 - ERROR - Targets device: cuda:0
2025-10-05 16:39:54,377 - ERROR - Device mismatch in batch 226
2025-10-05 16:39:54,378 - ERROR - Images device: cuda:0
2025-10-05 16:39:54,378 - ERROR - Targets device: cuda:0
2025-10-05 16:39:54,612 - ERROR - Device mismatch in batch 227
2025-10-05 16:39:54,612 - ERROR - Images device: cuda:0
2025-10-05 16:39:54,612 - ERROR - Targets device: cuda:0
2025-10-05 16:39:54,840 - ERROR - Device mismatch in batch 228
2025-10-05 16:39:54,840 - ERROR - Images device: cuda:0
2025-10-05 16:39:54,841 - ERROR - Targets device: cuda:0
2025-10-05 16:39:55,059 - ERROR - Device mismatch in batch 229
2025-10-05 16:39:55,060 - ERROR - Images device: cuda:0
2025-10-05 16:39:55,060 - ERROR - Targets device: cuda:0
2025-10-05 16:39:55,287 - ERROR - Device mismatch in batch 230
2025-10-05 16:39:55,287 - ERROR - Images device: cuda:0
2025-10-05 16:39:55,288 - ERROR - Targets device: cuda:0
2025-10-05 16:39:55,504 - ERROR - Device mismatch in batch 231
2025-10-05 16:39:55,504 - ERROR - Images device: cuda:0
2025-10-05 16:39:55,505 - ERROR - Targets device: cuda:0
2025-10-05 16:39:55,733 - ERROR - Device mismatch in batch 232
2025-10-05 16:39:55,733 - ERROR - Images device: cuda:0
2025-10-05 16:39:55,734 - ERROR - Targets device: cuda:0
2025-10-05 16:39:55,960 - ERROR - Device mismatch in batch 233
2025-10-05 16:39:55,960 - ERROR - Images device: cuda:0
2025-10-05 16:39:55,960 - ERROR - Targets device: cuda:0
2025-10-05 16:39:56,196 - ERROR - Device mismatch in batch 234
2025-10-05 16:39:56,196 - ERROR - Images device: cuda:0
2025-10-05 16:39:56,197 - ERROR - Targets device: cuda:0
2025-10-05 16:39:56,424 - ERROR - Device mismatch in batch 235
2025-10-05 16:39:56,424 - ERROR - Images device: cuda:0
2025-10-05 16:39:56,424 - ERROR - Targets device: cuda:0
2025-10-05 16:39:56,686 - ERROR - Device mismatch in batch 236
2025-10-05 16:39:56,686 - ERROR - Images device: cuda:0
2025-10-05 16:39:56,686 - ERROR - Targets device: cuda:0
2025-10-05 16:39:56,954 - ERROR - Device mismatch in batch 237
2025-10-05 16:39:56,954 - ERROR - Images device: cuda:0
2025-10-05 16:39:56,954 - ERROR - Targets device: cuda:0
2025-10-05 16:39:57,201 - ERROR - Device mismatch in batch 238
2025-10-05 16:39:57,201 - ERROR - Images device: cuda:0
2025-10-05 16:39:57,202 - ERROR - Targets device: cuda:0
2025-10-05 16:39:57,439 - ERROR - Device mismatch in batch 239
2025-10-05 16:39:57,440 - ERROR - Images device: cuda:0
2025-10-05 16:39:57,440 - ERROR - Targets device: cuda:0
2025-10-05 16:39:57,696 - ERROR - Device mismatch in batch 240
2025-10-05 16:39:57,696 - ERROR - Images device: cuda:0
2025-10-05 16:39:57,696 - ERROR - Targets device: cuda:0
2025-10-05 16:39:57,994 - ERROR - Device mismatch in batch 241
2025-10-05 16:39:57,994 - ERROR - Images device: cuda:0
2025-10-05 16:39:57,994 - ERROR - Targets device: cuda:0
2025-10-05 16:39:58,246 - ERROR - Device mismatch in batch 242
2025-10-05 16:39:58,247 - ERROR - Images device: cuda:0
2025-10-05 16:39:58,247 - ERROR - Targets device: cuda:0
2025-10-05 16:39:58,499 - ERROR - Device mismatch in batch 243
2025-10-05 16:39:58,499 - ERROR - Images device: cuda:0
2025-10-05 16:39:58,499 - ERROR - Targets device: cuda:0
2025-10-05 16:39:58,741 - ERROR - Device mismatch in batch 244
2025-10-05 16:39:58,741 - ERROR - Images device: cuda:0
2025-10-05 16:39:58,741 - ERROR - Targets device: cuda:0
2025-10-05 16:39:58,954 - ERROR - Device mismatch in batch 245
2025-10-05 16:39:58,955 - ERROR - Images device: cuda:0
2025-10-05 16:39:58,955 - ERROR - Targets device: cuda:0
2025-10-05 16:39:59,133 - ERROR - Device mismatch in batch 246
2025-10-05 16:39:59,134 - ERROR - Images device: cuda:0
2025-10-05 16:39:59,134 - ERROR - Targets device: cuda:0
2025-10-05 16:39:59,379 - ERROR - Device mismatch in batch 247
2025-10-05 16:39:59,379 - ERROR - Images device: cuda:0
2025-10-05 16:39:59,379 - ERROR - Targets device: cuda:0
2025-10-05 16:39:59,593 - ERROR - Device mismatch in batch 248
2025-10-05 16:39:59,593 - ERROR - Images device: cuda:0
2025-10-05 16:39:59,594 - ERROR - Targets device: cuda:0
2025-10-05 16:39:59,809 - ERROR - Device mismatch in batch 249
2025-10-05 16:39:59,809 - ERROR - Images device: cuda:0
2025-10-05 16:39:59,809 - ERROR - Targets device: cuda:0
2025-10-05 16:40:00,061 - ERROR - Device mismatch in batch 250
2025-10-05 16:40:00,061 - ERROR - Images device: cuda:0
2025-10-05 16:40:00,061 - ERROR - Targets device: cuda:0
2025-10-05 16:40:00,279 - ERROR - Device mismatch in batch 251
2025-10-05 16:40:00,280 - ERROR - Images device: cuda:0
2025-10-05 16:40:00,280 - ERROR - Targets device: cuda:0
2025-10-05 16:40:00,496 - ERROR - Device mismatch in batch 252
2025-10-05 16:40:00,496 - ERROR - Images device: cuda:0
2025-10-05 16:40:00,497 - ERROR - Targets device: cuda:0
2025-10-05 16:40:00,729 - ERROR - Device mismatch in batch 253
2025-10-05 16:40:00,730 - ERROR - Images device: cuda:0
2025-10-05 16:40:00,730 - ERROR - Targets device: cuda:0
2025-10-05 16:40:01,003 - ERROR - Device mismatch in batch 254
2025-10-05 16:40:01,004 - ERROR - Images device: cuda:0
2025-10-05 16:40:01,004 - ERROR - Targets device: cuda:0
2025-10-05 16:40:01,254 - ERROR - Device mismatch in batch 255
2025-10-05 16:40:01,255 - ERROR - Images device: cuda:0
2025-10-05 16:40:01,255 - ERROR - Targets device: cuda:0
2025-10-05 16:40:01,502 - ERROR - Device mismatch in batch 256
2025-10-05 16:40:01,502 - ERROR - Images device: cuda:0
2025-10-05 16:40:01,503 - ERROR - Targets device: cuda:0
2025-10-05 16:40:01,732 - ERROR - Device mismatch in batch 257
2025-10-05 16:40:01,732 - ERROR - Images device: cuda:0
2025-10-05 16:40:01,732 - ERROR - Targets device: cuda:0
2025-10-05 16:40:01,987 - ERROR - Device mismatch in batch 258
2025-10-05 16:40:01,988 - ERROR - Images device: cuda:0
2025-10-05 16:40:01,988 - ERROR - Targets device: cuda:0
2025-10-05 16:40:02,208 - ERROR - Device mismatch in batch 259
2025-10-05 16:40:02,209 - ERROR - Images device: cuda:0
2025-10-05 16:40:02,209 - ERROR - Targets device: cuda:0
2025-10-05 16:40:02,431 - ERROR - Device mismatch in batch 260
2025-10-05 16:40:02,431 - ERROR - Images device: cuda:0
2025-10-05 16:40:02,432 - ERROR - Targets device: cuda:0
2025-10-05 16:40:02,645 - ERROR - Device mismatch in batch 261
2025-10-05 16:40:02,646 - ERROR - Images device: cuda:0
2025-10-05 16:40:02,646 - ERROR - Targets device: cuda:0
2025-10-05 16:40:02,957 - ERROR - Device mismatch in batch 262
2025-10-05 16:40:02,957 - ERROR - Images device: cuda:0
2025-10-05 16:40:02,957 - ERROR - Targets device: cuda:0
2025-10-05 16:40:03,168 - ERROR - Device mismatch in batch 263
2025-10-05 16:40:03,168 - ERROR - Images device: cuda:0
2025-10-05 16:40:03,168 - ERROR - Targets device: cuda:0
2025-10-05 16:40:03,423 - ERROR - Device mismatch in batch 264
2025-10-05 16:40:03,423 - ERROR - Images device: cuda:0
2025-10-05 16:40:03,423 - ERROR - Targets device: cuda:0
2025-10-05 16:40:03,639 - ERROR - Device mismatch in batch 265
2025-10-05 16:40:03,639 - ERROR - Images device: cuda:0
2025-10-05 16:40:03,639 - ERROR - Targets device: cuda:0
2025-10-05 16:40:03,893 - ERROR - Device mismatch in batch 266
2025-10-05 16:40:03,893 - ERROR - Images device: cuda:0
2025-10-05 16:40:03,893 - ERROR - Targets device: cuda:0
2025-10-05 16:40:04,139 - ERROR - Device mismatch in batch 267
2025-10-05 16:40:04,139 - ERROR - Images device: cuda:0
2025-10-05 16:40:04,140 - ERROR - Targets device: cuda:0
2025-10-05 16:40:04,354 - ERROR - Device mismatch in batch 268
2025-10-05 16:40:04,354 - ERROR - Images device: cuda:0
2025-10-05 16:40:04,355 - ERROR - Targets device: cuda:0
2025-10-05 16:40:04,593 - ERROR - Device mismatch in batch 269
2025-10-05 16:40:04,593 - ERROR - Images device: cuda:0
2025-10-05 16:40:04,593 - ERROR - Targets device: cuda:0
2025-10-05 16:40:04,816 - ERROR - Device mismatch in batch 270
2025-10-05 16:40:04,816 - ERROR - Images device: cuda:0
2025-10-05 16:40:04,817 - ERROR - Targets device: cuda:0
2025-10-05 16:40:05,025 - ERROR - Device mismatch in batch 271
2025-10-05 16:40:05,025 - ERROR - Images device: cuda:0
2025-10-05 16:40:05,026 - ERROR - Targets device: cuda:0
2025-10-05 16:40:05,274 - ERROR - Device mismatch in batch 272
2025-10-05 16:40:05,275 - ERROR - Images device: cuda:0
2025-10-05 16:40:05,275 - ERROR - Targets device: cuda:0
2025-10-05 16:40:05,563 - ERROR - Device mismatch in batch 273
2025-10-05 16:40:05,563 - ERROR - Images device: cuda:0
2025-10-05 16:40:05,563 - ERROR - Targets device: cuda:0
2025-10-05 16:40:05,822 - ERROR - Device mismatch in batch 274
2025-10-05 16:40:05,822 - ERROR - Images device: cuda:0
2025-10-05 16:40:05,822 - ERROR - Targets device: cuda:0
2025-10-05 16:40:06,033 - ERROR - Device mismatch in batch 275
2025-10-05 16:40:06,033 - ERROR - Images device: cuda:0
2025-10-05 16:40:06,034 - ERROR - Targets device: cuda:0
2025-10-05 16:40:06,276 - ERROR - Device mismatch in batch 276
2025-10-05 16:40:06,277 - ERROR - Images device: cuda:0
2025-10-05 16:40:06,277 - ERROR - Targets device: cuda:0
2025-10-05 16:40:06,530 - ERROR - Device mismatch in batch 277
2025-10-05 16:40:06,530 - ERROR - Images device: cuda:0
2025-10-05 16:40:06,530 - ERROR - Targets device: cuda:0
2025-10-05 16:40:06,741 - ERROR - Device mismatch in batch 278
2025-10-05 16:40:06,741 - ERROR - Images device: cuda:0
2025-10-05 16:40:06,741 - ERROR - Targets device: cuda:0
2025-10-05 16:40:07,018 - ERROR - Device mismatch in batch 279
2025-10-05 16:40:07,019 - ERROR - Images device: cuda:0
2025-10-05 16:40:07,019 - ERROR - Targets device: cuda:0
2025-10-05 16:40:07,260 - ERROR - Device mismatch in batch 280
2025-10-05 16:40:07,261 - ERROR - Images device: cuda:0
2025-10-05 16:40:07,261 - ERROR - Targets device: cuda:0
2025-10-05 16:40:07,469 - ERROR - Device mismatch in batch 281
2025-10-05 16:40:07,469 - ERROR - Images device: cuda:0
2025-10-05 16:40:07,469 - ERROR - Targets device: cuda:0
2025-10-05 16:40:07,707 - ERROR - Device mismatch in batch 282
2025-10-05 16:40:07,707 - ERROR - Images device: cuda:0
2025-10-05 16:40:07,707 - ERROR - Targets device: cuda:0
2025-10-05 16:40:07,917 - ERROR - Device mismatch in batch 283
2025-10-05 16:40:07,917 - ERROR - Images device: cuda:0
2025-10-05 16:40:07,917 - ERROR - Targets device: cuda:0
2025-10-05 16:40:08,137 - ERROR - Device mismatch in batch 284
2025-10-05 16:40:08,137 - ERROR - Images device: cuda:0
2025-10-05 16:40:08,137 - ERROR - Targets device: cuda:0
2025-10-05 16:40:08,365 - ERROR - Device mismatch in batch 285
2025-10-05 16:40:08,366 - ERROR - Images device: cuda:0
2025-10-05 16:40:08,366 - ERROR - Targets device: cuda:0
2025-10-05 16:40:08,563 - ERROR - Device mismatch in batch 286
2025-10-05 16:40:08,564 - ERROR - Images device: cuda:0
2025-10-05 16:40:08,564 - ERROR - Targets device: cuda:0
2025-10-05 16:40:08,763 - ERROR - Device mismatch in batch 287
2025-10-05 16:40:08,764 - ERROR - Images device: cuda:0
2025-10-05 16:40:08,764 - ERROR - Targets device: cuda:0
2025-10-05 16:40:08,964 - ERROR - Device mismatch in batch 288
2025-10-05 16:40:08,965 - ERROR - Images device: cuda:0
2025-10-05 16:40:08,965 - ERROR - Targets device: cuda:0
2025-10-05 16:40:09,186 - ERROR - Device mismatch in batch 289
2025-10-05 16:40:09,186 - ERROR - Images device: cuda:0
2025-10-05 16:40:09,186 - ERROR - Targets device: cuda:0
2025-10-05 16:40:09,426 - ERROR - Device mismatch in batch 290
2025-10-05 16:40:09,427 - ERROR - Images device: cuda:0
2025-10-05 16:40:09,427 - ERROR - Targets device: cuda:0
2025-10-05 16:40:09,651 - ERROR - Device mismatch in batch 291
2025-10-05 16:40:09,652 - ERROR - Images device: cuda:0
2025-10-05 16:40:09,652 - ERROR - Targets device: cuda:0
2025-10-05 16:40:09,905 - ERROR - Device mismatch in batch 292
2025-10-05 16:40:09,905 - ERROR - Images device: cuda:0
2025-10-05 16:40:09,905 - ERROR - Targets device: cuda:0
2025-10-05 16:40:10,119 - ERROR - Device mismatch in batch 293
2025-10-05 16:40:10,120 - ERROR - Images device: cuda:0
2025-10-05 16:40:10,120 - ERROR - Targets device: cuda:0
2025-10-05 16:40:10,377 - ERROR - Device mismatch in batch 294
2025-10-05 16:40:10,377 - ERROR - Images device: cuda:0
2025-10-05 16:40:10,377 - ERROR - Targets device: cuda:0
2025-10-05 16:40:10,704 - ERROR - Device mismatch in batch 295
2025-10-05 16:40:10,704 - ERROR - Images device: cuda:0
2025-10-05 16:40:10,705 - ERROR - Targets device: cuda:0
2025-10-05 16:40:10,905 - ERROR - Device mismatch in batch 296
2025-10-05 16:40:10,906 - ERROR - Images device: cuda:0
2025-10-05 16:40:10,906 - ERROR - Targets device: cuda:0
2025-10-05 16:40:11,106 - ERROR - Device mismatch in batch 297
2025-10-05 16:40:11,107 - ERROR - Images device: cuda:0
2025-10-05 16:40:11,107 - ERROR - Targets device: cuda:0
2025-10-05 16:40:11,356 - ERROR - Device mismatch in batch 298
2025-10-05 16:40:11,356 - ERROR - Images device: cuda:0
2025-10-05 16:40:11,356 - ERROR - Targets device: cuda:0
2025-10-05 16:40:11,595 - ERROR - Device mismatch in batch 299
2025-10-05 16:40:11,596 - ERROR - Images device: cuda:0
2025-10-05 16:40:11,596 - ERROR - Targets device: cuda:0
2025-10-05 16:40:11,815 - ERROR - Device mismatch in batch 300
2025-10-05 16:40:11,816 - ERROR - Images device: cuda:0
2025-10-05 16:40:11,816 - ERROR - Targets device: cuda:0
2025-10-05 16:40:12,050 - ERROR - Device mismatch in batch 301
2025-10-05 16:40:12,050 - ERROR - Images device: cuda:0
2025-10-05 16:40:12,050 - ERROR - Targets device: cuda:0
2025-10-05 16:40:12,280 - ERROR - Device mismatch in batch 302
2025-10-05 16:40:12,280 - ERROR - Images device: cuda:0
2025-10-05 16:40:12,280 - ERROR - Targets device: cuda:0
2025-10-05 16:40:12,543 - ERROR - Device mismatch in batch 303
2025-10-05 16:40:12,544 - ERROR - Images device: cuda:0
2025-10-05 16:40:12,544 - ERROR - Targets device: cuda:0
2025-10-05 16:40:12,780 - ERROR - Device mismatch in batch 304
2025-10-05 16:40:12,781 - ERROR - Images device: cuda:0
2025-10-05 16:40:12,781 - ERROR - Targets device: cuda:0
2025-10-05 16:40:12,998 - ERROR - Device mismatch in batch 305
2025-10-05 16:40:12,998 - ERROR - Images device: cuda:0
2025-10-05 16:40:12,998 - ERROR - Targets device: cuda:0
2025-10-05 16:40:13,226 - ERROR - Device mismatch in batch 306
2025-10-05 16:40:13,226 - ERROR - Images device: cuda:0
2025-10-05 16:40:13,227 - ERROR - Targets device: cuda:0
2025-10-05 16:40:13,471 - ERROR - Device mismatch in batch 307
2025-10-05 16:40:13,471 - ERROR - Images device: cuda:0
2025-10-05 16:40:13,471 - ERROR - Targets device: cuda:0
2025-10-05 16:40:13,741 - ERROR - Device mismatch in batch 308
2025-10-05 16:40:13,741 - ERROR - Images device: cuda:0
2025-10-05 16:40:13,741 - ERROR - Targets device: cuda:0
2025-10-05 16:40:14,005 - ERROR - Device mismatch in batch 309
2025-10-05 16:40:14,006 - ERROR - Images device: cuda:0
2025-10-05 16:40:14,006 - ERROR - Targets device: cuda:0
2025-10-05 16:40:14,254 - ERROR - Device mismatch in batch 310
2025-10-05 16:40:14,254 - ERROR - Images device: cuda:0
2025-10-05 16:40:14,254 - ERROR - Targets device: cuda:0
2025-10-05 16:40:14,556 - ERROR - Device mismatch in batch 311
2025-10-05 16:40:14,556 - ERROR - Images device: cuda:0
2025-10-05 16:40:14,556 - ERROR - Targets device: cuda:0
2025-10-05 16:40:14,802 - ERROR - Device mismatch in batch 312
2025-10-05 16:40:14,802 - ERROR - Images device: cuda:0
2025-10-05 16:40:14,802 - ERROR - Targets device: cuda:0
2025-10-05 16:40:15,078 - ERROR - Device mismatch in batch 313
2025-10-05 16:40:15,078 - ERROR - Images device: cuda:0
2025-10-05 16:40:15,078 - ERROR - Targets device: cuda:0
2025-10-05 16:40:15,338 - ERROR - Device mismatch in batch 314
2025-10-05 16:40:15,338 - ERROR - Images device: cuda:0
2025-10-05 16:40:15,338 - ERROR - Targets device: cuda:0
2025-10-05 16:40:15,623 - ERROR - Device mismatch in batch 315
2025-10-05 16:40:15,623 - ERROR - Images device: cuda:0
2025-10-05 16:40:15,623 - ERROR - Targets device: cuda:0
2025-10-05 16:40:15,855 - ERROR - Device mismatch in batch 316
2025-10-05 16:40:15,855 - ERROR - Images device: cuda:0
2025-10-05 16:40:15,856 - ERROR - Targets device: cuda:0
2025-10-05 16:40:16,087 - ERROR - Device mismatch in batch 317
2025-10-05 16:40:16,087 - ERROR - Images device: cuda:0
2025-10-05 16:40:16,087 - ERROR - Targets device: cuda:0
2025-10-05 16:40:16,372 - ERROR - Device mismatch in batch 318
2025-10-05 16:40:16,372 - ERROR - Images device: cuda:0
2025-10-05 16:40:16,372 - ERROR - Targets device: cuda:0
2025-10-05 16:40:16,606 - ERROR - Device mismatch in batch 319
2025-10-05 16:40:16,606 - ERROR - Images device: cuda:0
2025-10-05 16:40:16,606 - ERROR - Targets device: cuda:0
2025-10-05 16:40:16,817 - ERROR - Device mismatch in batch 320
2025-10-05 16:40:16,817 - ERROR - Images device: cuda:0
2025-10-05 16:40:16,817 - ERROR - Targets device: cuda:0
2025-10-05 16:40:17,015 - ERROR - Device mismatch in batch 321
2025-10-05 16:40:17,016 - ERROR - Images device: cuda:0
2025-10-05 16:40:17,016 - ERROR - Targets device: cuda:0
2025-10-05 16:40:17,233 - ERROR - Device mismatch in batch 322
2025-10-05 16:40:17,233 - ERROR - Images device: cuda:0
2025-10-05 16:40:17,234 - ERROR - Targets device: cuda:0
2025-10-05 16:40:17,450 - ERROR - Device mismatch in batch 323
2025-10-05 16:40:17,451 - ERROR - Images device: cuda:0
2025-10-05 16:40:17,451 - ERROR - Targets device: cuda:0
2025-10-05 16:40:17,741 - ERROR - Device mismatch in batch 324
2025-10-05 16:40:17,742 - ERROR - Images device: cuda:0
2025-10-05 16:40:17,742 - ERROR - Targets device: cuda:0
2025-10-05 16:40:17,983 - ERROR - Device mismatch in batch 325
2025-10-05 16:40:17,983 - ERROR - Images device: cuda:0
2025-10-05 16:40:17,984 - ERROR - Targets device: cuda:0
2025-10-05 16:40:18,221 - ERROR - Device mismatch in batch 326
2025-10-05 16:40:18,221 - ERROR - Images device: cuda:0
2025-10-05 16:40:18,221 - ERROR - Targets device: cuda:0
2025-10-05 16:40:18,458 - ERROR - Device mismatch in batch 327
2025-10-05 16:40:18,458 - ERROR - Images device: cuda:0
2025-10-05 16:40:18,458 - ERROR - Targets device: cuda:0
2025-10-05 16:40:18,704 - ERROR - Device mismatch in batch 328
2025-10-05 16:40:18,704 - ERROR - Images device: cuda:0
2025-10-05 16:40:18,704 - ERROR - Targets device: cuda:0
2025-10-05 16:40:18,939 - ERROR - Device mismatch in batch 329
2025-10-05 16:40:18,939 - ERROR - Images device: cuda:0
2025-10-05 16:40:18,940 - ERROR - Targets device: cuda:0
2025-10-05 16:40:19,178 - ERROR - Device mismatch in batch 330
2025-10-05 16:40:19,178 - ERROR - Images device: cuda:0
2025-10-05 16:40:19,178 - ERROR - Targets device: cuda:0
2025-10-05 16:40:19,450 - ERROR - Device mismatch in batch 331
2025-10-05 16:40:19,450 - ERROR - Images device: cuda:0
2025-10-05 16:40:19,450 - ERROR - Targets device: cuda:0
2025-10-05 16:40:19,693 - ERROR - Device mismatch in batch 332
2025-10-05 16:40:19,694 - ERROR - Images device: cuda:0
2025-10-05 16:40:19,694 - ERROR - Targets device: cuda:0
2025-10-05 16:40:19,955 - ERROR - Device mismatch in batch 333
2025-10-05 16:40:19,955 - ERROR - Images device: cuda:0
2025-10-05 16:40:19,956 - ERROR - Targets device: cuda:0
2025-10-05 16:40:20,182 - ERROR - Device mismatch in batch 334
2025-10-05 16:40:20,182 - ERROR - Images device: cuda:0
2025-10-05 16:40:20,182 - ERROR - Targets device: cuda:0
2025-10-05 16:40:20,408 - ERROR - Device mismatch in batch 335
2025-10-05 16:40:20,408 - ERROR - Images device: cuda:0
2025-10-05 16:40:20,408 - ERROR - Targets device: cuda:0
2025-10-05 16:40:20,632 - ERROR - Device mismatch in batch 336
2025-10-05 16:40:20,632 - ERROR - Images device: cuda:0
2025-10-05 16:40:20,632 - ERROR - Targets device: cuda:0
2025-10-05 16:40:20,852 - ERROR - Device mismatch in batch 337
2025-10-05 16:40:20,853 - ERROR - Images device: cuda:0
2025-10-05 16:40:20,853 - ERROR - Targets device: cuda:0
2025-10-05 16:40:21,112 - ERROR - Device mismatch in batch 338
2025-10-05 16:40:21,112 - ERROR - Images device: cuda:0
2025-10-05 16:40:21,112 - ERROR - Targets device: cuda:0
2025-10-05 16:40:21,355 - ERROR - Device mismatch in batch 339
2025-10-05 16:40:21,355 - ERROR - Images device: cuda:0
2025-10-05 16:40:21,356 - ERROR - Targets device: cuda:0
2025-10-05 16:41:30,097 - INFO - Using device: cuda
2025-10-05 16:41:30,098 - INFO - Loading split dataset (train/val/test)...
2025-10-05 16:41:30,116 - INFO - Split dataset loaded successfully!
2025-10-05 16:41:30,117 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 16:41:30,117 - INFO - Initializing adaptive fusion model...
2025-10-05 16:41:31,016 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 16:41:31,016 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-05 16:41:31,017 - INFO -  Starting cattle detection training...
2025-10-05 16:41:31,272 - ERROR - Genuine device mismatch in batch 0: Images on cuda:0 instead of cuda
2025-10-05 16:41:31,480 - ERROR - Genuine device mismatch in batch 1: Images on cuda:0 instead of cuda
2025-10-05 16:41:31,671 - ERROR - Genuine device mismatch in batch 2: Images on cuda:0 instead of cuda
2025-10-05 16:41:31,898 - ERROR - Genuine device mismatch in batch 3: Images on cuda:0 instead of cuda
2025-10-05 16:41:32,139 - ERROR - Genuine device mismatch in batch 4: Images on cuda:0 instead of cuda
2025-10-05 16:41:32,353 - ERROR - Genuine device mismatch in batch 5: Images on cuda:0 instead of cuda
2025-10-05 16:41:32,568 - ERROR - Genuine device mismatch in batch 6: Images on cuda:0 instead of cuda
2025-10-05 16:41:32,803 - ERROR - Genuine device mismatch in batch 7: Images on cuda:0 instead of cuda
2025-10-05 16:41:33,038 - ERROR - Genuine device mismatch in batch 8: Images on cuda:0 instead of cuda
2025-10-05 16:41:33,254 - ERROR - Genuine device mismatch in batch 9: Images on cuda:0 instead of cuda
2025-10-05 16:41:33,438 - ERROR - Genuine device mismatch in batch 10: Images on cuda:0 instead of cuda
2025-10-05 16:41:33,657 - ERROR - Genuine device mismatch in batch 11: Images on cuda:0 instead of cuda
2025-10-05 16:41:33,884 - ERROR - Genuine device mismatch in batch 12: Images on cuda:0 instead of cuda
2025-10-05 16:41:34,092 - ERROR - Genuine device mismatch in batch 13: Images on cuda:0 instead of cuda
2025-10-05 16:41:34,321 - ERROR - Genuine device mismatch in batch 14: Images on cuda:0 instead of cuda
2025-10-05 16:41:34,587 - ERROR - Genuine device mismatch in batch 15: Images on cuda:0 instead of cuda
2025-10-05 16:41:34,818 - ERROR - Genuine device mismatch in batch 16: Images on cuda:0 instead of cuda
2025-10-05 16:41:35,075 - ERROR - Genuine device mismatch in batch 17: Images on cuda:0 instead of cuda
2025-10-05 16:41:35,300 - ERROR - Genuine device mismatch in batch 18: Images on cuda:0 instead of cuda
2025-10-05 16:41:35,555 - ERROR - Genuine device mismatch in batch 19: Images on cuda:0 instead of cuda
2025-10-05 16:41:35,725 - ERROR - Genuine device mismatch in batch 20: Images on cuda:0 instead of cuda
2025-10-05 16:41:35,905 - ERROR - Genuine device mismatch in batch 21: Images on cuda:0 instead of cuda
2025-10-05 16:41:36,129 - ERROR - Genuine device mismatch in batch 22: Images on cuda:0 instead of cuda
2025-10-05 16:41:36,332 - ERROR - Genuine device mismatch in batch 23: Images on cuda:0 instead of cuda
2025-10-05 16:41:36,551 - ERROR - Genuine device mismatch in batch 24: Images on cuda:0 instead of cuda
2025-10-05 16:41:36,783 - ERROR - Genuine device mismatch in batch 25: Images on cuda:0 instead of cuda
2025-10-05 16:41:37,020 - ERROR - Genuine device mismatch in batch 26: Images on cuda:0 instead of cuda
2025-10-05 16:41:37,230 - ERROR - Genuine device mismatch in batch 27: Images on cuda:0 instead of cuda
2025-10-05 16:41:37,435 - ERROR - Genuine device mismatch in batch 28: Images on cuda:0 instead of cuda
2025-10-05 16:41:37,670 - ERROR - Genuine device mismatch in batch 29: Images on cuda:0 instead of cuda
2025-10-05 16:41:37,917 - ERROR - Genuine device mismatch in batch 30: Images on cuda:0 instead of cuda
2025-10-05 16:41:38,160 - ERROR - Genuine device mismatch in batch 31: Images on cuda:0 instead of cuda
2025-10-05 16:41:38,475 - ERROR - Genuine device mismatch in batch 32: Images on cuda:0 instead of cuda
2025-10-05 16:41:38,722 - ERROR - Genuine device mismatch in batch 33: Images on cuda:0 instead of cuda
2025-10-05 16:41:39,009 - ERROR - Genuine device mismatch in batch 34: Images on cuda:0 instead of cuda
2025-10-05 16:41:39,248 - ERROR - Genuine device mismatch in batch 35: Images on cuda:0 instead of cuda
2025-10-05 16:41:39,454 - ERROR - Genuine device mismatch in batch 36: Images on cuda:0 instead of cuda
2025-10-05 16:41:39,651 - ERROR - Genuine device mismatch in batch 37: Images on cuda:0 instead of cuda
2025-10-05 16:41:39,861 - ERROR - Genuine device mismatch in batch 38: Images on cuda:0 instead of cuda
2025-10-05 16:41:40,100 - ERROR - Genuine device mismatch in batch 39: Images on cuda:0 instead of cuda
2025-10-05 16:41:40,314 - ERROR - Genuine device mismatch in batch 40: Images on cuda:0 instead of cuda
2025-10-05 16:41:40,535 - ERROR - Genuine device mismatch in batch 41: Images on cuda:0 instead of cuda
2025-10-05 16:41:40,727 - ERROR - Genuine device mismatch in batch 42: Images on cuda:0 instead of cuda
2025-10-05 16:41:40,928 - ERROR - Genuine device mismatch in batch 43: Images on cuda:0 instead of cuda
2025-10-05 16:41:41,118 - ERROR - Genuine device mismatch in batch 44: Images on cuda:0 instead of cuda
2025-10-05 16:41:41,364 - ERROR - Genuine device mismatch in batch 45: Images on cuda:0 instead of cuda
2025-10-05 16:41:41,571 - ERROR - Genuine device mismatch in batch 46: Images on cuda:0 instead of cuda
2025-10-05 16:41:41,793 - ERROR - Genuine device mismatch in batch 47: Images on cuda:0 instead of cuda
2025-10-05 16:41:42,019 - ERROR - Genuine device mismatch in batch 48: Images on cuda:0 instead of cuda
2025-10-05 16:41:42,218 - ERROR - Genuine device mismatch in batch 49: Images on cuda:0 instead of cuda
2025-10-05 16:41:42,415 - ERROR - Genuine device mismatch in batch 50: Images on cuda:0 instead of cuda
2025-10-05 16:41:42,629 - ERROR - Genuine device mismatch in batch 51: Images on cuda:0 instead of cuda
2025-10-05 16:41:42,863 - ERROR - Genuine device mismatch in batch 52: Images on cuda:0 instead of cuda
2025-10-05 16:41:43,082 - ERROR - Genuine device mismatch in batch 53: Images on cuda:0 instead of cuda
2025-10-05 16:44:06,839 - INFO - Using device: cuda
2025-10-05 16:44:06,840 - INFO - Loading split dataset (train/val/test)...
2025-10-05 16:44:06,859 - INFO - Split dataset loaded successfully!
2025-10-05 16:44:06,859 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 16:44:06,859 - INFO - Initializing adaptive fusion model...
2025-10-05 16:44:07,761 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 16:44:07,761 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-05 16:44:07,762 - INFO -  Starting cattle detection training...
2025-10-05 16:50:16,162 - INFO - Using device: cuda
2025-10-05 16:50:16,162 - INFO - Loading split dataset (train/val/test)...
2025-10-05 16:50:16,182 - INFO - Split dataset loaded successfully!
2025-10-05 16:50:16,182 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 16:50:16,182 - INFO - Initializing adaptive fusion model...
2025-10-05 16:50:17,083 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 16:50:17,084 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-05 16:50:17,084 - INFO -  Starting cattle detection training...
2025-10-05 16:50:27,137 - WARNING - NaN in loss_classifier for batch 5, replacing with 0
2025-10-05 16:50:27,138 - WARNING - NaN in loss_objectness for batch 5, replacing with 0
2025-10-05 16:52:07,524 - WARNING - NaN in loss_classifier for batch 113, replacing with 0
2025-10-05 16:52:07,525 - WARNING - NaN in loss_objectness for batch 113, replacing with 0
2025-10-05 16:52:39,135 - WARNING - NaN in loss_classifier for batch 145, replacing with 0
2025-10-05 16:52:39,135 - WARNING - NaN in loss_objectness for batch 145, replacing with 0
2025-10-05 16:53:31,459 - WARNING - NaN in loss_classifier for batch 200, replacing with 0
2025-10-05 16:53:31,459 - WARNING - NaN in loss_box_reg for batch 200, replacing with 0
2025-10-05 16:53:31,460 - WARNING - NaN in loss_objectness for batch 200, replacing with 0
2025-10-05 16:54:00,081 - WARNING - NaN in loss_classifier for batch 230, replacing with 0
2025-10-05 16:54:00,081 - WARNING - NaN in loss_objectness for batch 230, replacing with 0
2025-10-05 16:54:01,016 - WARNING - NaN in loss_classifier for batch 231, replacing with 0
2025-10-05 16:54:01,017 - WARNING - NaN in loss_objectness for batch 231, replacing with 0
2025-10-05 16:54:02,958 - WARNING - NaN in loss_classifier for batch 233, replacing with 0
2025-10-05 16:54:02,958 - WARNING - NaN in loss_objectness for batch 233, replacing with 0
2025-10-05 16:54:08,643 - WARNING - NaN in loss_classifier for batch 239, replacing with 0
2025-10-05 16:54:08,644 - WARNING - NaN in loss_objectness for batch 239, replacing with 0
2025-10-05 16:54:21,968 - WARNING - NaN in loss_classifier for batch 253, replacing with 0
2025-10-05 16:54:21,968 - WARNING - NaN in loss_objectness for batch 253, replacing with 0
2025-10-05 16:54:27,736 - WARNING - NaN in loss_classifier for batch 259, replacing with 0
2025-10-05 16:54:27,737 - WARNING - NaN in loss_objectness for batch 259, replacing with 0
2025-10-05 16:54:37,388 - WARNING - NaN in loss_classifier for batch 269, replacing with 0
2025-10-05 16:54:37,389 - WARNING - NaN in loss_objectness for batch 269, replacing with 0
2025-10-05 16:54:56,565 - WARNING - NaN in loss_classifier for batch 289, replacing with 0
2025-10-05 16:54:56,566 - WARNING - NaN in loss_objectness for batch 289, replacing with 0
2025-10-05 16:54:59,373 - WARNING - NaN in loss_classifier for batch 292, replacing with 0
2025-10-05 16:54:59,374 - WARNING - NaN in loss_objectness for batch 292, replacing with 0
2025-10-05 16:58:07,213 - INFO - Using device: cuda
2025-10-05 16:58:07,213 - INFO - Loading split dataset (train/val/test)...
2025-10-05 16:58:07,232 - INFO - Split dataset loaded successfully!
2025-10-05 16:58:07,232 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 16:58:07,232 - INFO - Initializing adaptive fusion model...
2025-10-05 16:58:08,126 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 16:58:08,126 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-05 16:58:08,126 - INFO -  Starting cattle detection training...
2025-10-05 16:58:08,130 - INFO - Reduced learning rate to 0.000090
2025-10-05 16:58:39,907 - WARNING - NaN/inf in loss_classifier for batch 28, using fallback
2025-10-05 16:58:39,908 - WARNING - NaN/inf in loss_objectness for batch 28, using fallback
2025-10-05 17:02:00,761 - INFO - Using device: cuda
2025-10-05 17:02:00,761 - INFO - Loading split dataset (train/val/test)...
2025-10-05 17:02:00,780 - INFO - Split dataset loaded successfully!
2025-10-05 17:02:00,780 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 17:02:00,780 - INFO - Initializing adaptive fusion model...
2025-10-05 17:02:01,677 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 17:02:01,677 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-05 17:02:01,677 - INFO -  Starting cattle detection training...
2025-10-05 17:02:01,681 - INFO - Adjusted learning rate to 0.000092
2025-10-05 17:02:17,188 - WARNING - NaN/inf in loss_classifier (batch 11) - using fallback: 0.0808
2025-10-05 17:02:17,189 - WARNING - NaN/inf in loss_box_reg (batch 11) - using fallback: 0.0837
2025-10-05 17:02:17,189 - WARNING - NaN/inf in loss_objectness (batch 11) - using fallback: 0.0653
2025-10-05 17:02:17,407 - ERROR - Error processing batch 11: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.
2025-10-05 17:07:33,731 - INFO - Using device: cuda
2025-10-05 17:07:33,731 - INFO - Loading split dataset (train/val/test)...
2025-10-05 17:07:33,751 - INFO - Split dataset loaded successfully!
2025-10-05 17:07:33,751 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 17:07:33,751 - INFO - Initializing adaptive fusion model...
2025-10-05 17:07:34,657 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 17:07:34,657 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-05 17:07:34,657 - INFO -  Starting cattle detection training...
2025-10-05 17:07:34,660 - INFO - Adjusted learning rate to 0.000093
2025-10-05 17:07:56,133 - WARNING - NaN/inf in loss_classifier (batch 17) - using fallback: 0.0789
2025-10-05 17:07:56,133 - WARNING - NaN/inf in loss_box_reg (batch 17) - using fallback: 0.0780
2025-10-05 17:07:56,134 - WARNING - NaN/inf in loss_objectness (batch 17) - using fallback: 0.0641
2025-10-05 17:07:56,443 - ERROR - Error processing batch 17: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.
2025-10-05 17:08:05,631 - WARNING - NaN/inf in loss_classifier (batch 22) - using fallback: 0.0748
2025-10-05 17:08:05,632 - WARNING - NaN/inf in loss_box_reg (batch 22) - using fallback: 0.0758
2025-10-05 17:08:05,633 - WARNING - NaN/inf in loss_objectness (batch 22) - using fallback: 0.0545
2025-10-05 17:08:07,262 - ERROR - Error processing batch 22: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.
2025-10-05 17:08:32,245 - WARNING - NaN/inf in loss_classifier (batch 29) - using fallback: 0.0692
2025-10-05 17:08:32,246 - WARNING - NaN/inf in loss_objectness (batch 29) - using fallback: 0.0458
2025-10-05 17:08:34,906 - ERROR - Error processing batch 29: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.
2025-10-05 17:11:03,866 - INFO - Using device: cuda
2025-10-05 17:11:03,866 - INFO - Loading split dataset (train/val/test)...
2025-10-05 17:11:03,885 - INFO - Split dataset loaded successfully!
2025-10-05 17:11:03,886 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 17:11:03,886 - INFO - Initializing adaptive fusion model...
2025-10-05 17:11:04,818 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 17:11:04,819 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-05 17:11:04,819 - INFO -  Starting cattle detection training...
2025-10-05 17:11:04,823 - INFO - Adjusted learning rate to 0.000093
2025-10-05 17:25:22,933 - WARNING - NaN/inf in loss_classifier (batch 91) - using fallback: 0.0585
2025-10-05 17:25:22,934 - WARNING - NaN/inf in loss_objectness (batch 91) - using fallback: 0.0238
2025-10-05 17:25:22,991 - ERROR - Error processing batch 91: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.
2025-10-05 17:25:37,049 - WARNING - NaN/inf in loss_classifier (batch 92) - using fallback: 0.0585
2025-10-05 17:25:37,050 - WARNING - NaN/inf in loss_box_reg (batch 92) - using fallback: 0.0643
2025-10-05 17:25:37,050 - WARNING - NaN/inf in loss_objectness (batch 92) - using fallback: 0.0238
2025-10-05 17:25:37,109 - ERROR - Error processing batch 92: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.
2025-10-05 17:29:54,506 - INFO - Using device: cuda
2025-10-05 17:29:54,507 - INFO - Loading split dataset (train/val/test)...
2025-10-05 17:29:54,527 - INFO - Split dataset loaded successfully!
2025-10-05 17:29:54,527 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 17:29:54,527 - INFO - Initializing adaptive fusion model...
2025-10-05 17:29:55,526 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 17:29:55,526 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-05 17:29:55,527 - INFO -  Starting cattle detection training...
2025-10-05 17:29:55,531 - INFO - Using learning rate: 0.000095
2025-10-05 17:31:20,139 - WARNING - NaN/inf in loss_classifier (batch 49) - using fallback: 0.0615
2025-10-05 17:31:20,140 - WARNING - NaN/inf in loss_box_reg (batch 49) - using fallback: 0.0674
2025-10-05 17:31:20,140 - WARNING - NaN/inf in loss_objectness (batch 49) - using fallback: 0.0284
2025-10-05 17:31:20,177 - ERROR - Error processing batch 49: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.
2025-10-05 17:33:04,547 - INFO - Using device: cuda
2025-10-05 17:33:04,547 - INFO - Loading split dataset (train/val/test)...
2025-10-05 17:33:04,568 - INFO - Split dataset loaded successfully!
2025-10-05 17:33:04,568 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 17:33:04,568 - INFO - Initializing adaptive fusion model...
2025-10-05 17:33:05,457 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 17:33:05,457 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-05 17:33:05,457 - INFO -  Starting cattle detection training...
2025-10-05 17:33:05,461 - INFO - Using learning rate: 0.000095
2025-10-05 17:33:47,923 - WARNING - NaN/inf in loss_classifier (batch 46) - using fallback: 0.0650
2025-10-05 17:33:47,924 - WARNING - NaN/inf in loss_box_reg (batch 46) - using fallback: 0.0688
2025-10-05 17:33:47,924 - WARNING - NaN/inf in loss_objectness (batch 46) - using fallback: 0.0293
2025-10-05 17:33:51,866 - WARNING - NaN/inf in loss_classifier (batch 51) - using fallback: 0.0640
2025-10-05 17:33:51,867 - WARNING - NaN/inf in loss_objectness (batch 51) - using fallback: 0.0291
2025-10-05 17:34:12,741 - WARNING - NaN/inf in loss_classifier (batch 77) - using fallback: 0.0632
2025-10-05 17:34:12,742 - WARNING - NaN/inf in loss_objectness (batch 77) - using fallback: 0.0190
2025-10-05 17:34:30,963 - WARNING - NaN/inf in loss_classifier (batch 99) - using fallback: 0.0599
2025-10-05 17:34:30,964 - WARNING - NaN/inf in loss_box_reg (batch 99) - using fallback: 0.0651
2025-10-05 17:34:30,964 - WARNING - NaN/inf in loss_objectness (batch 99) - using fallback: 0.0137
2025-10-05 17:34:43,000 - WARNING - NaN/inf in loss_classifier (batch 113) - using fallback: 0.0627
2025-10-05 17:34:43,000 - WARNING - NaN/inf in loss_box_reg (batch 113) - using fallback: 0.0686
2025-10-05 17:34:43,001 - WARNING - NaN/inf in loss_objectness (batch 113) - using fallback: 0.0134
2025-10-05 17:36:13,815 - INFO - Using device: cuda
2025-10-05 17:36:13,816 - INFO - Loading split dataset (train/val/test)...
2025-10-05 17:36:13,836 - INFO - Split dataset loaded successfully!
2025-10-05 17:36:13,836 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 17:36:13,836 - INFO - Initializing adaptive fusion model...
2025-10-05 17:36:14,748 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 17:36:14,748 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-05 17:36:14,749 - INFO -  Starting cattle detection training...
2025-10-05 17:36:14,753 - INFO - Using learning rate: 0.000095
2025-10-05 17:37:00,122 - WARNING - NaN/inf in loss_classifier (batch 51) - using fallback: 0.0559 (count: 1)
2025-10-05 17:37:00,122 - WARNING - NaN/inf in loss_box_reg (batch 51) - using fallback: 0.0665 (count: 1)
2025-10-05 17:37:00,123 - WARNING - NaN/inf in loss_objectness (batch 51) - using fallback: 0.0357 (count: 1)
2025-10-05 17:37:07,959 - WARNING - NaN/inf in loss_classifier (batch 61) - using fallback: 0.0559 (count: 1)
2025-10-05 17:37:07,960 - WARNING - NaN/inf in loss_box_reg (batch 61) - using fallback: 0.0658 (count: 1)
2025-10-05 17:37:07,960 - WARNING - NaN/inf in loss_objectness (batch 61) - using fallback: 0.0319 (count: 1)
2025-10-05 17:37:24,210 - WARNING - NaN/inf in loss_classifier (batch 81) - using fallback: 0.0571 (count: 1)
2025-10-05 17:37:24,211 - WARNING - NaN/inf in loss_objectness (batch 81) - using fallback: 0.0290 (count: 1)
2025-10-05 17:38:20,884 - WARNING - NaN/inf in loss_classifier (batch 150) - using fallback: 0.0555 (count: 1)
2025-10-05 17:38:20,885 - WARNING - NaN/inf in loss_objectness (batch 150) - using fallback: 0.0221 (count: 1)
2025-10-05 17:38:21,634 - WARNING - NaN/inf in loss_classifier (batch 151) - using fallback: 0.0555 (count: 2)
2025-10-05 17:38:21,634 - WARNING - NaN/inf in loss_box_reg (batch 151) - using fallback: 0.0616 (count: 1)
2025-10-05 17:38:21,635 - WARNING - NaN/inf in loss_objectness (batch 151) - using fallback: 0.0221 (count: 2)
2025-10-05 17:38:37,891 - WARNING - NaN/inf in loss_classifier (batch 171) - using fallback: 0.0546 (count: 1)
2025-10-05 17:38:37,893 - WARNING - NaN/inf in loss_objectness (batch 171) - using fallback: 0.0233 (count: 1)
2025-10-05 17:38:46,898 - WARNING - NaN/inf in loss_classifier (batch 182) - using fallback: 0.0543 (count: 1)
2025-10-05 17:38:46,900 - WARNING - NaN/inf in loss_objectness (batch 182) - using fallback: 0.0231 (count: 1)
2025-10-05 17:38:54,483 - WARNING - NaN/inf in loss_classifier (batch 191) - using fallback: 0.0553 (count: 1)
2025-10-05 17:38:54,484 - WARNING - NaN/inf in loss_objectness (batch 191) - using fallback: 0.0227 (count: 1)
2025-10-05 17:39:32,696 - WARNING - NaN/inf in loss_classifier (batch 237) - using fallback: 0.0574 (count: 1)
2025-10-05 17:39:32,697 - WARNING - NaN/inf in loss_box_reg (batch 237) - using fallback: 0.0646 (count: 1)
2025-10-05 17:39:32,697 - WARNING - NaN/inf in loss_objectness (batch 237) - using fallback: 0.0197 (count: 1)
2025-10-05 17:40:15,585 - WARNING - NaN/inf in loss_classifier (batch 290) - using fallback: 0.0582 (count: 1)
2025-10-05 17:40:15,587 - WARNING - NaN/inf in loss_objectness (batch 290) - using fallback: 0.0203 (count: 1)
2025-10-05 17:40:18,747 - WARNING - NaN/inf in loss_classifier (batch 294) - using fallback: 0.0587 (count: 1)
2025-10-05 17:40:18,748 - WARNING - NaN/inf in loss_box_reg (batch 294) - using fallback: 0.0661 (count: 1)
2025-10-05 17:40:18,749 - WARNING - NaN/inf in loss_objectness (batch 294) - using fallback: 0.0199 (count: 1)
2025-10-05 17:40:21,978 - WARNING - NaN/inf in loss_classifier (batch 298) - using fallback: 0.0580 (count: 1)
2025-10-05 17:40:21,978 - WARNING - NaN/inf in loss_objectness (batch 298) - using fallback: 0.0200 (count: 1)
2025-10-05 17:40:29,305 - WARNING - NaN/inf in loss_classifier (batch 307) - using fallback: 0.0577 (count: 1)
2025-10-05 17:40:29,306 - WARNING - NaN/inf in loss_objectness (batch 307) - using fallback: 0.0187 (count: 1)
2025-10-05 17:40:35,090 - WARNING - NaN/inf in loss_classifier (batch 314) - using fallback: 0.0583 (count: 1)
2025-10-05 17:40:35,092 - WARNING - NaN/inf in loss_objectness (batch 314) - using fallback: 0.0181 (count: 1)
2025-10-05 17:41:17,083 - WARNING - NaN/inf in loss_classifier (batch 366) - using fallback: 0.0568 (count: 1)
2025-10-05 17:41:17,084 - WARNING - NaN/inf in loss_box_reg (batch 366) - using fallback: 0.0666 (count: 1)
2025-10-05 17:41:17,084 - WARNING - NaN/inf in loss_objectness (batch 366) - using fallback: 0.0269 (count: 1)
2025-10-05 17:41:20,988 - WARNING - NaN/inf in loss_classifier (batch 371) - using fallback: 0.0572 (count: 1)
2025-10-05 17:41:20,989 - WARNING - NaN/inf in loss_box_reg (batch 371) - using fallback: 0.0679 (count: 1)
2025-10-05 17:41:20,989 - WARNING - NaN/inf in loss_objectness (batch 371) - using fallback: 0.0270 (count: 1)
2025-10-05 17:41:28,678 - WARNING - NaN/inf in loss_classifier (batch 381) - using fallback: 0.0558 (count: 1)
2025-10-05 17:41:28,678 - WARNING - NaN/inf in loss_box_reg (batch 381) - using fallback: 0.0644 (count: 1)
2025-10-05 17:41:28,679 - WARNING - NaN/inf in loss_objectness (batch 381) - using fallback: 0.0244 (count: 1)
2025-10-05 17:41:30,911 - WARNING - NaN/inf in loss_classifier (batch 384) - using fallback: 0.0559 (count: 1)
2025-10-05 17:41:30,911 - WARNING - NaN/inf in loss_objectness (batch 384) - using fallback: 0.0241 (count: 1)
2025-10-05 17:41:35,606 - WARNING - NaN/inf in loss_classifier (batch 390) - using fallback: 0.0547 (count: 1)
2025-10-05 17:41:35,607 - WARNING - NaN/inf in loss_objectness (batch 390) - using fallback: 0.0241 (count: 1)
2025-10-05 17:41:41,769 - WARNING - NaN/inf in loss_classifier (batch 398) - using fallback: 0.0548 (count: 1)
2025-10-05 17:41:41,769 - WARNING - NaN/inf in loss_objectness (batch 398) - using fallback: 0.0271 (count: 1)
2025-10-05 17:41:50,511 - WARNING - NaN/inf in loss_classifier (batch 409) - using fallback: 0.0566 (count: 1)
2025-10-05 17:41:50,511 - WARNING - NaN/inf in loss_objectness (batch 409) - using fallback: 0.0280 (count: 1)
2025-10-05 17:41:51,343 - WARNING - NaN/inf in loss_classifier (batch 410) - using fallback: 0.0566 (count: 2)
2025-10-05 17:41:51,344 - WARNING - NaN/inf in loss_objectness (batch 410) - using fallback: 0.0280 (count: 2)
2025-10-05 17:41:53,740 - WARNING - NaN/inf in loss_classifier (batch 413) - using fallback: 0.0564 (count: 1)
2025-10-05 17:41:53,740 - WARNING - NaN/inf in loss_box_reg (batch 413) - using fallback: 0.0633 (count: 1)
2025-10-05 17:41:53,741 - WARNING - NaN/inf in loss_objectness (batch 413) - using fallback: 0.0270 (count: 1)
2025-10-05 17:42:10,075 - WARNING - NaN/inf in loss_classifier (batch 433) - using fallback: 0.0575 (count: 1)
2025-10-05 17:42:10,075 - WARNING - NaN/inf in loss_box_reg (batch 433) - using fallback: 0.0638 (count: 1)
2025-10-05 17:42:10,076 - WARNING - NaN/inf in loss_objectness (batch 433) - using fallback: 0.0277 (count: 1)
2025-10-05 17:42:12,535 - WARNING - NaN/inf in loss_classifier (batch 436) - using fallback: 0.0574 (count: 1)
2025-10-05 17:42:12,536 - WARNING - NaN/inf in loss_objectness (batch 436) - using fallback: 0.0273 (count: 1)
2025-10-05 17:42:19,765 - WARNING - NaN/inf in loss_classifier (batch 445) - using fallback: 0.0565 (count: 1)
2025-10-05 17:42:19,766 - WARNING - NaN/inf in loss_box_reg (batch 445) - using fallback: 0.0618 (count: 1)
2025-10-05 17:42:19,766 - WARNING - NaN/inf in loss_objectness (batch 445) - using fallback: 0.0265 (count: 1)
2025-10-05 17:42:29,315 - WARNING - NaN/inf in loss_classifier (batch 457) - using fallback: 0.0556 (count: 1)
2025-10-05 17:42:29,316 - WARNING - NaN/inf in loss_box_reg (batch 457) - using fallback: 0.0617 (count: 1)
2025-10-05 17:42:29,316 - WARNING - NaN/inf in loss_objectness (batch 457) - using fallback: 0.0237 (count: 1)
2025-10-05 17:42:31,592 - WARNING - NaN/inf in loss_classifier (batch 460) - using fallback: 0.0562 (count: 1)
2025-10-05 17:42:31,592 - WARNING - NaN/inf in loss_box_reg (batch 460) - using fallback: 0.0613 (count: 1)
2025-10-05 17:42:31,592 - WARNING - NaN/inf in loss_objectness (batch 460) - using fallback: 0.0236 (count: 1)
2025-10-05 17:42:33,918 - WARNING - NaN/inf in loss_classifier (batch 463) - using fallback: 0.0569 (count: 1)
2025-10-05 17:42:33,919 - WARNING - NaN/inf in loss_box_reg (batch 463) - using fallback: 0.0618 (count: 1)
2025-10-05 17:42:33,920 - WARNING - NaN/inf in loss_objectness (batch 463) - using fallback: 0.0244 (count: 1)
2025-10-05 17:42:39,535 - WARNING - NaN/inf in loss_classifier (batch 470) - using fallback: 0.0563 (count: 1)
2025-10-05 17:42:39,535 - WARNING - NaN/inf in loss_objectness (batch 470) - using fallback: 0.0241 (count: 1)
2025-10-05 17:42:45,293 - WARNING - NaN/inf in loss_classifier (batch 477) - using fallback: 0.0555 (count: 1)
2025-10-05 17:42:45,294 - WARNING - NaN/inf in loss_objectness (batch 477) - using fallback: 0.0251 (count: 1)
2025-10-05 17:42:46,078 - WARNING - NaN/inf in loss_classifier (batch 478) - using fallback: 0.0555 (count: 2)
2025-10-05 17:42:46,079 - WARNING - NaN/inf in loss_objectness (batch 478) - using fallback: 0.0251 (count: 2)
2025-10-05 17:42:59,600 - WARNING - NaN/inf in loss_classifier (batch 495) - using fallback: 0.0547 (count: 1)
2025-10-05 17:42:59,601 - WARNING - NaN/inf in loss_box_reg (batch 495) - using fallback: 0.0610 (count: 1)
2025-10-05 17:42:59,601 - WARNING - NaN/inf in loss_objectness (batch 495) - using fallback: 0.0242 (count: 1)
2025-10-05 17:43:05,059 - WARNING - NaN/inf in loss_classifier (batch 502) - using fallback: 0.0547 (count: 1)
2025-10-05 17:43:05,060 - WARNING - NaN/inf in loss_box_reg (batch 502) - using fallback: 0.0596 (count: 1)
2025-10-05 17:43:05,060 - WARNING - NaN/inf in loss_objectness (batch 502) - using fallback: 0.0228 (count: 1)
2025-10-05 17:43:31,444 - WARNING - NaN/inf in loss_classifier (batch 535) - using fallback: 0.0552 (count: 1)
2025-10-05 17:43:31,445 - WARNING - NaN/inf in loss_box_reg (batch 535) - using fallback: 0.0599 (count: 1)
2025-10-05 17:43:31,446 - WARNING - NaN/inf in loss_objectness (batch 535) - using fallback: 0.0240 (count: 1)
2025-10-05 17:43:32,184 - WARNING - NaN/inf in loss_classifier (batch 536) - using fallback: 0.0552 (count: 2)
2025-10-05 17:43:32,184 - WARNING - NaN/inf in loss_box_reg (batch 536) - using fallback: 0.0599 (count: 2)
2025-10-05 17:43:32,185 - WARNING - NaN/inf in loss_objectness (batch 536) - using fallback: 0.0240 (count: 2)
2025-10-05 17:43:33,651 - WARNING - NaN/inf in loss_classifier (batch 538) - using fallback: 0.0548 (count: 1)
2025-10-05 17:43:33,652 - WARNING - NaN/inf in loss_objectness (batch 538) - using fallback: 0.0235 (count: 1)
2025-10-05 17:43:38,449 - WARNING - NaN/inf in loss_classifier (batch 544) - using fallback: 0.0547 (count: 1)
2025-10-05 17:43:38,450 - WARNING - NaN/inf in loss_objectness (batch 544) - using fallback: 0.0231 (count: 1)
2025-10-05 17:43:51,637 - WARNING - NaN/inf in loss_classifier (batch 561) - using fallback: 0.0555 (count: 1)
2025-10-05 17:43:51,638 - WARNING - NaN/inf in loss_box_reg (batch 561) - using fallback: 0.0620 (count: 1)
2025-10-05 17:43:51,639 - WARNING - NaN/inf in loss_objectness (batch 561) - using fallback: 0.0204 (count: 1)
2025-10-05 17:44:06,243 - WARNING - NaN/inf in loss_classifier (batch 580) - using fallback: 0.0577 (count: 1)
2025-10-05 17:44:06,244 - WARNING - NaN/inf in loss_box_reg (batch 580) - using fallback: 0.0653 (count: 1)
2025-10-05 17:44:06,244 - WARNING - NaN/inf in loss_objectness (batch 580) - using fallback: 0.0238 (count: 1)
2025-10-05 17:44:06,942 - WARNING - NaN/inf in loss_classifier (batch 581) - using fallback: 0.0577 (count: 2)
2025-10-05 17:44:06,943 - WARNING - NaN/inf in loss_objectness (batch 581) - using fallback: 0.0238 (count: 2)
2025-10-05 17:44:16,862 - WARNING - NaN/inf in loss_classifier (batch 594) - using fallback: 0.0581 (count: 1)
2025-10-05 17:44:16,862 - WARNING - NaN/inf in loss_objectness (batch 594) - using fallback: 0.0284 (count: 1)
2025-10-05 17:44:19,147 - WARNING - NaN/inf in loss_classifier (batch 597) - using fallback: 0.0586 (count: 1)
2025-10-05 17:44:19,147 - WARNING - NaN/inf in loss_box_reg (batch 597) - using fallback: 0.0648 (count: 1)
2025-10-05 17:44:19,148 - WARNING - NaN/inf in loss_objectness (batch 597) - using fallback: 0.0282 (count: 1)
2025-10-05 17:44:23,721 - WARNING - NaN/inf in loss_classifier (batch 603) - using fallback: 0.0581 (count: 1)
2025-10-05 17:44:23,722 - WARNING - NaN/inf in loss_objectness (batch 603) - using fallback: 0.0275 (count: 1)
2025-10-05 17:44:31,456 - WARNING - NaN/inf in loss_classifier (batch 613) - using fallback: 0.0590 (count: 1)
2025-10-05 17:44:31,457 - WARNING - NaN/inf in loss_objectness (batch 613) - using fallback: 0.0266 (count: 1)
2025-10-05 17:44:32,248 - WARNING - NaN/inf in loss_classifier (batch 614) - using fallback: 0.0590 (count: 2)
2025-10-05 17:44:32,249 - WARNING - NaN/inf in loss_box_reg (batch 614) - using fallback: 0.0627 (count: 1)
2025-10-05 17:44:32,249 - WARNING - NaN/inf in loss_objectness (batch 614) - using fallback: 0.0266 (count: 2)
2025-10-05 17:44:34,459 - WARNING - NaN/inf in loss_classifier (batch 617) - using fallback: 0.0585 (count: 1)
2025-10-05 17:44:34,460 - WARNING - NaN/inf in loss_objectness (batch 617) - using fallback: 0.0257 (count: 1)
2025-10-05 17:44:41,343 - WARNING - NaN/inf in loss_classifier (batch 626) - using fallback: 0.0584 (count: 1)
2025-10-05 17:44:41,344 - WARNING - NaN/inf in loss_box_reg (batch 626) - using fallback: 0.0642 (count: 1)
2025-10-05 17:44:41,344 - WARNING - NaN/inf in loss_objectness (batch 626) - using fallback: 0.0237 (count: 1)
2025-10-05 17:44:48,159 - WARNING - NaN/inf in loss_classifier (batch 635) - using fallback: 0.0579 (count: 1)
2025-10-05 17:44:48,160 - WARNING - NaN/inf in loss_objectness (batch 635) - using fallback: 0.0237 (count: 1)
2025-10-05 17:44:49,696 - WARNING - NaN/inf in loss_classifier (batch 637) - using fallback: 0.0574 (count: 1)
2025-10-05 17:44:49,697 - WARNING - NaN/inf in loss_box_reg (batch 637) - using fallback: 0.0628 (count: 1)
2025-10-05 17:44:49,697 - WARNING - NaN/inf in loss_objectness (batch 637) - using fallback: 0.0234 (count: 1)
2025-10-05 17:44:58,231 - WARNING - NaN/inf in loss_classifier (batch 648) - using fallback: 0.0572 (count: 1)
2025-10-05 17:44:58,232 - WARNING - NaN/inf in loss_objectness (batch 648) - using fallback: 0.0218 (count: 1)
2025-10-05 17:45:08,056 - WARNING - NaN/inf in loss_classifier (batch 661) - using fallback: 0.0578 (count: 1)
2025-10-05 17:45:08,057 - WARNING - NaN/inf in loss_objectness (batch 661) - using fallback: 0.0215 (count: 1)
2025-10-05 17:45:10,342 - WARNING - NaN/inf in loss_classifier (batch 664) - using fallback: 0.0572 (count: 1)
2025-10-05 17:45:10,342 - WARNING - NaN/inf in loss_box_reg (batch 664) - using fallback: 0.0640 (count: 1)
2025-10-05 17:45:10,343 - WARNING - NaN/inf in loss_objectness (batch 664) - using fallback: 0.0212 (count: 1)
2025-10-05 17:45:11,740 - WARNING - NaN/inf in loss_classifier (batch 666) - using fallback: 0.0578 (count: 1)
2025-10-05 17:45:11,741 - WARNING - NaN/inf in loss_box_reg (batch 666) - using fallback: 0.0659 (count: 1)
2025-10-05 17:45:11,741 - WARNING - NaN/inf in loss_objectness (batch 666) - using fallback: 0.0214 (count: 1)
2025-10-05 17:45:15,329 - WARNING - NaN/inf in loss_classifier (batch 671) - using fallback: 0.0584 (count: 1)
2025-10-05 17:45:15,330 - WARNING - NaN/inf in loss_box_reg (batch 671) - using fallback: 0.0661 (count: 1)
2025-10-05 17:45:15,330 - WARNING - NaN/inf in loss_objectness (batch 671) - using fallback: 0.0215 (count: 1)
2025-10-05 17:45:16,741 - WARNING - NaN/inf in loss_classifier (batch 673) - using fallback: 0.0592 (count: 1)
2025-10-05 17:45:16,742 - WARNING - NaN/inf in loss_box_reg (batch 673) - using fallback: 0.0670 (count: 1)
2025-10-05 17:45:16,742 - WARNING - NaN/inf in loss_objectness (batch 673) - using fallback: 0.0213 (count: 1)
2025-10-05 17:45:22,056 - WARNING - NaN/inf in loss_classifier (batch 680) - using fallback: 0.0573 (count: 1)
2025-10-05 17:45:22,057 - WARNING - NaN/inf in loss_box_reg (batch 680) - using fallback: 0.0649 (count: 1)
2025-10-05 17:45:22,057 - WARNING - NaN/inf in loss_objectness (batch 680) - using fallback: 0.0211 (count: 1)
2025-10-05 17:45:24,999 - WARNING - NaN/inf in loss_classifier (batch 684) - using fallback: 0.0581 (count: 1)
2025-10-05 17:45:25,000 - WARNING - NaN/inf in loss_objectness (batch 684) - using fallback: 0.0204 (count: 1)
2025-10-05 17:45:25,768 - WARNING - NaN/inf in loss_classifier (batch 685) - using fallback: 0.0581 (count: 2)
2025-10-05 17:45:25,769 - WARNING - NaN/inf in loss_objectness (batch 685) - using fallback: 0.0204 (count: 2)
2025-10-05 17:45:31,797 - WARNING - NaN/inf in loss_classifier (batch 693) - using fallback: 0.0579 (count: 1)
2025-10-05 17:45:31,798 - WARNING - NaN/inf in loss_box_reg (batch 693) - using fallback: 0.0650 (count: 1)
2025-10-05 17:45:31,798 - WARNING - NaN/inf in loss_objectness (batch 693) - using fallback: 0.0206 (count: 1)
2025-10-05 17:45:32,468 - WARNING - NaN/inf in loss_classifier (batch 694) - using fallback: 0.0579 (count: 2)
2025-10-05 17:45:32,469 - WARNING - NaN/inf in loss_objectness (batch 694) - using fallback: 0.0206 (count: 2)
2025-10-05 17:45:36,267 - WARNING - NaN/inf in loss_classifier (batch 699) - using fallback: 0.0588 (count: 1)
2025-10-05 17:45:36,268 - WARNING - NaN/inf in loss_objectness (batch 699) - using fallback: 0.0239 (count: 1)
2025-10-05 17:45:43,912 - WARNING - NaN/inf in loss_classifier (batch 709) - using fallback: 0.0582 (count: 1)
2025-10-05 17:45:43,913 - WARNING - NaN/inf in loss_box_reg (batch 709) - using fallback: 0.0631 (count: 1)
2025-10-05 17:45:43,913 - WARNING - NaN/inf in loss_objectness (batch 709) - using fallback: 0.0219 (count: 1)
2025-10-05 17:45:44,604 - WARNING - NaN/inf in loss_classifier (batch 710) - using fallback: 0.0582 (count: 2)
2025-10-05 17:45:44,605 - WARNING - NaN/inf in loss_objectness (batch 710) - using fallback: 0.0219 (count: 2)
2025-10-05 17:45:46,066 - WARNING - NaN/inf in loss_classifier (batch 712) - using fallback: 0.0585 (count: 1)
2025-10-05 17:45:46,067 - WARNING - NaN/inf in loss_objectness (batch 712) - using fallback: 0.0229 (count: 1)
2025-10-05 17:45:55,042 - WARNING - NaN/inf in loss_classifier (batch 724) - using fallback: 0.0594 (count: 1)
2025-10-05 17:45:55,043 - WARNING - NaN/inf in loss_box_reg (batch 724) - using fallback: 0.0644 (count: 1)
2025-10-05 17:45:55,043 - WARNING - NaN/inf in loss_objectness (batch 724) - using fallback: 0.0229 (count: 1)
2025-10-05 17:46:02,582 - WARNING - NaN/inf in loss_classifier (batch 734) - using fallback: 0.0599 (count: 1)
2025-10-05 17:46:02,583 - WARNING - NaN/inf in loss_objectness (batch 734) - using fallback: 0.0211 (count: 1)
2025-10-05 17:46:12,619 - WARNING - NaN/inf in loss_classifier (batch 747) - using fallback: 0.0595 (count: 1)
2025-10-05 17:46:12,619 - WARNING - NaN/inf in loss_box_reg (batch 747) - using fallback: 0.0663 (count: 1)
2025-10-05 17:46:12,620 - WARNING - NaN/inf in loss_objectness (batch 747) - using fallback: 0.0281 (count: 1)
2025-10-05 17:46:29,280 - WARNING - NaN/inf in loss_classifier (batch 769) - using fallback: 0.0590 (count: 1)
2025-10-05 17:46:29,281 - WARNING - NaN/inf in loss_box_reg (batch 769) - using fallback: 0.0622 (count: 1)
2025-10-05 17:46:29,281 - WARNING - NaN/inf in loss_objectness (batch 769) - using fallback: 0.0260 (count: 1)
2025-10-05 17:46:29,994 - WARNING - NaN/inf in loss_classifier (batch 770) - using fallback: 0.0590 (count: 2)
2025-10-05 17:46:29,994 - WARNING - NaN/inf in loss_objectness (batch 770) - using fallback: 0.0260 (count: 2)
2025-10-05 17:46:52,988 - WARNING - NaN/inf in loss_classifier (batch 800) - using fallback: 0.0596 (count: 1)
2025-10-05 17:46:52,989 - WARNING - NaN/inf in loss_box_reg (batch 800) - using fallback: 0.0646 (count: 1)
2025-10-05 17:46:52,989 - WARNING - NaN/inf in loss_objectness (batch 800) - using fallback: 0.0259 (count: 1)
2025-10-05 17:46:59,814 - WARNING - NaN/inf in loss_classifier (batch 809) - using fallback: 0.0570 (count: 1)
2025-10-05 17:46:59,814 - WARNING - NaN/inf in loss_objectness (batch 809) - using fallback: 0.0235 (count: 1)
2025-10-05 17:47:00,576 - WARNING - NaN/inf in loss_classifier (batch 810) - using fallback: 0.0570 (count: 2)
2025-10-05 17:47:00,576 - WARNING - NaN/inf in loss_box_reg (batch 810) - using fallback: 0.0621 (count: 1)
2025-10-05 17:47:00,577 - WARNING - NaN/inf in loss_objectness (batch 810) - using fallback: 0.0235 (count: 2)
2025-10-05 17:47:21,133 - WARNING - NaN/inf in loss_classifier (batch 837) - using fallback: 0.0586 (count: 1)
2025-10-05 17:47:21,133 - WARNING - NaN/inf in loss_objectness (batch 837) - using fallback: 0.0400 (count: 1)
2025-10-05 17:47:27,857 - WARNING - NaN/inf in loss_classifier (batch 846) - using fallback: 0.0591 (count: 1)
2025-10-05 17:47:27,858 - WARNING - NaN/inf in loss_objectness (batch 846) - using fallback: 0.0357 (count: 1)
2025-10-05 17:47:31,621 - WARNING - NaN/inf in loss_classifier (batch 851) - using fallback: 0.0609 (count: 1)
2025-10-05 17:47:31,621 - WARNING - NaN/inf in loss_box_reg (batch 851) - using fallback: 0.0673 (count: 1)
2025-10-05 17:47:31,622 - WARNING - NaN/inf in loss_objectness (batch 851) - using fallback: 0.0340 (count: 1)
2025-10-05 17:47:32,270 - WARNING - NaN/inf in loss_classifier (batch 852) - using fallback: 0.0609 (count: 2)
2025-10-05 17:47:32,271 - WARNING - NaN/inf in loss_box_reg (batch 852) - using fallback: 0.0673 (count: 2)
2025-10-05 17:47:32,271 - WARNING - NaN/inf in loss_objectness (batch 852) - using fallback: 0.0340 (count: 2)
2025-10-05 17:47:43,079 - WARNING - NaN/inf in loss_classifier (batch 866) - using fallback: 0.0601 (count: 1)
2025-10-05 17:47:43,080 - WARNING - NaN/inf in loss_box_reg (batch 866) - using fallback: 0.0647 (count: 1)
2025-10-05 17:47:43,080 - WARNING - NaN/inf in loss_objectness (batch 866) - using fallback: 0.0305 (count: 1)
2025-10-05 17:47:43,804 - WARNING - NaN/inf in loss_classifier (batch 867) - using fallback: 0.0601 (count: 2)
2025-10-05 17:47:43,805 - WARNING - NaN/inf in loss_objectness (batch 867) - using fallback: 0.0305 (count: 2)
2025-10-05 17:47:46,035 - WARNING - NaN/inf in loss_classifier (batch 870) - using fallback: 0.0596 (count: 1)
2025-10-05 17:47:46,036 - WARNING - NaN/inf in loss_box_reg (batch 870) - using fallback: 0.0633 (count: 1)
2025-10-05 17:47:46,036 - WARNING - NaN/inf in loss_objectness (batch 870) - using fallback: 0.0304 (count: 1)
2025-10-05 17:47:48,267 - WARNING - NaN/inf in loss_classifier (batch 873) - using fallback: 0.0593 (count: 1)
2025-10-05 17:47:48,267 - WARNING - NaN/inf in loss_box_reg (batch 873) - using fallback: 0.0623 (count: 1)
2025-10-05 17:47:48,268 - WARNING - NaN/inf in loss_objectness (batch 873) - using fallback: 0.0296 (count: 1)
2025-10-05 17:47:55,132 - WARNING - NaN/inf in loss_classifier (batch 882) - using fallback: 0.0588 (count: 1)
2025-10-05 17:47:55,134 - WARNING - NaN/inf in loss_objectness (batch 882) - using fallback: 0.0272 (count: 1)
2025-10-05 17:47:59,085 - WARNING - NaN/inf in loss_classifier (batch 887) - using fallback: 0.0585 (count: 1)
2025-10-05 17:47:59,087 - WARNING - NaN/inf in loss_objectness (batch 887) - using fallback: 0.0270 (count: 1)
2025-10-05 17:48:03,629 - WARNING - NaN/inf in loss_classifier (batch 893) - using fallback: 0.0586 (count: 1)
2025-10-05 17:48:03,630 - WARNING - NaN/inf in loss_objectness (batch 893) - using fallback: 0.0270 (count: 1)
2025-10-05 17:48:09,820 - WARNING - NaN/inf in loss_classifier (batch 901) - using fallback: 0.0592 (count: 1)
2025-10-05 17:48:09,821 - WARNING - NaN/inf in loss_objectness (batch 901) - using fallback: 0.0270 (count: 1)
2025-10-05 17:48:20,614 - WARNING - NaN/inf in loss_classifier (batch 915) - using fallback: 0.0577 (count: 1)
2025-10-05 17:48:20,615 - WARNING - NaN/inf in loss_box_reg (batch 915) - using fallback: 0.0628 (count: 1)
2025-10-05 17:48:20,616 - WARNING - NaN/inf in loss_objectness (batch 915) - using fallback: 0.0228 (count: 1)
2025-10-05 17:48:26,007 - WARNING - NaN/inf in loss_classifier (batch 922) - using fallback: 0.0581 (count: 1)
2025-10-05 17:48:26,008 - WARNING - NaN/inf in loss_objectness (batch 922) - using fallback: 0.0234 (count: 1)
2025-10-05 17:48:26,781 - WARNING - NaN/inf in loss_classifier (batch 923) - using fallback: 0.0581 (count: 2)
2025-10-05 17:48:26,782 - WARNING - NaN/inf in loss_objectness (batch 923) - using fallback: 0.0234 (count: 2)
2025-10-05 17:48:44,085 - WARNING - NaN/inf in loss_classifier (batch 945) - using fallback: 0.0576 (count: 1)
2025-10-05 17:48:44,087 - WARNING - NaN/inf in loss_objectness (batch 945) - using fallback: 0.0236 (count: 1)
2025-10-05 17:48:49,503 - WARNING - NaN/inf in loss_classifier (batch 952) - using fallback: 0.0568 (count: 1)
2025-10-05 17:48:49,504 - WARNING - NaN/inf in loss_box_reg (batch 952) - using fallback: 0.0600 (count: 1)
2025-10-05 17:48:49,505 - WARNING - NaN/inf in loss_objectness (batch 952) - using fallback: 0.0222 (count: 1)
2025-10-05 17:48:51,780 - WARNING - NaN/inf in loss_classifier (batch 955) - using fallback: 0.0568 (count: 1)
2025-10-05 17:48:51,781 - WARNING - NaN/inf in loss_objectness (batch 955) - using fallback: 0.0216 (count: 1)
2025-10-05 17:48:56,376 - WARNING - NaN/inf in loss_classifier (batch 961) - using fallback: 0.0584 (count: 1)
2025-10-05 17:48:56,378 - WARNING - NaN/inf in loss_objectness (batch 961) - using fallback: 0.0213 (count: 1)
2025-10-05 17:48:57,865 - WARNING - NaN/inf in loss_classifier (batch 963) - using fallback: 0.0585 (count: 1)
2025-10-05 17:48:57,866 - WARNING - NaN/inf in loss_objectness (batch 963) - using fallback: 0.0217 (count: 1)
2025-10-05 17:49:00,899 - WARNING - NaN/inf in loss_classifier (batch 967) - using fallback: 0.0577 (count: 1)
2025-10-05 17:49:00,900 - WARNING - NaN/inf in loss_objectness (batch 967) - using fallback: 0.0212 (count: 1)
2025-10-05 17:49:25,504 - WARNING - NaN/inf in loss_classifier (batch 999) - using fallback: 0.0562 (count: 1)
2025-10-05 17:49:25,505 - WARNING - NaN/inf in loss_objectness (batch 999) - using fallback: 0.0205 (count: 1)
2025-10-05 17:49:29,347 - WARNING - NaN/inf in loss_classifier (batch 1004) - using fallback: 0.0567 (count: 1)
2025-10-05 17:49:29,347 - WARNING - NaN/inf in loss_box_reg (batch 1004) - using fallback: 0.0595 (count: 1)
2025-10-05 17:49:29,348 - WARNING - NaN/inf in loss_objectness (batch 1004) - using fallback: 0.0208 (count: 1)
2025-10-05 17:49:48,499 - WARNING - NaN/inf in loss_classifier (batch 1029) - using fallback: 0.0591 (count: 1)
2025-10-05 17:49:48,500 - WARNING - NaN/inf in loss_objectness (batch 1029) - using fallback: 0.0423 (count: 1)
2025-10-05 17:49:49,214 - WARNING - NaN/inf in loss_classifier (batch 1030) - using fallback: 0.0591 (count: 2)
2025-10-05 17:49:49,215 - WARNING - NaN/inf in loss_objectness (batch 1030) - using fallback: 0.0423 (count: 2)
2025-10-05 17:49:55,473 - WARNING - NaN/inf in loss_classifier (batch 1038) - using fallback: 0.0583 (count: 1)
2025-10-05 17:49:55,473 - WARNING - NaN/inf in loss_box_reg (batch 1038) - using fallback: 0.0625 (count: 1)
2025-10-05 17:49:55,474 - WARNING - NaN/inf in loss_objectness (batch 1038) - using fallback: 0.0380 (count: 1)
2025-10-05 17:50:02,468 - WARNING - NaN/inf in loss_classifier (batch 1047) - using fallback: 0.0586 (count: 1)
2025-10-05 17:50:02,469 - WARNING - NaN/inf in loss_box_reg (batch 1047) - using fallback: 0.0623 (count: 1)
2025-10-05 17:50:02,469 - WARNING - NaN/inf in loss_objectness (batch 1047) - using fallback: 0.0352 (count: 1)
2025-10-05 17:50:17,988 - WARNING - NaN/inf in loss_classifier (batch 1067) - using fallback: 0.0593 (count: 1)
2025-10-05 17:50:17,989 - WARNING - NaN/inf in loss_objectness (batch 1067) - using fallback: 0.0295 (count: 1)
2025-10-05 17:50:19,469 - WARNING - NaN/inf in loss_classifier (batch 1069) - using fallback: 0.0592 (count: 1)
2025-10-05 17:50:19,470 - WARNING - NaN/inf in loss_objectness (batch 1069) - using fallback: 0.0291 (count: 1)
2025-10-05 17:50:23,263 - WARNING - NaN/inf in loss_classifier (batch 1074) - using fallback: 0.0589 (count: 1)
2025-10-05 17:50:23,263 - WARNING - NaN/inf in loss_box_reg (batch 1074) - using fallback: 0.0634 (count: 1)
2025-10-05 17:50:23,264 - WARNING - NaN/inf in loss_objectness (batch 1074) - using fallback: 0.0280 (count: 1)
2025-10-05 17:50:24,717 - WARNING - NaN/inf in loss_classifier (batch 1076) - using fallback: 0.0593 (count: 1)
2025-10-05 17:50:24,718 - WARNING - NaN/inf in loss_objectness (batch 1076) - using fallback: 0.0277 (count: 1)
2025-10-05 17:50:26,249 - WARNING - NaN/inf in loss_classifier (batch 1078) - using fallback: 0.0589 (count: 1)
2025-10-05 17:50:26,250 - WARNING - NaN/inf in loss_objectness (batch 1078) - using fallback: 0.0273 (count: 1)
2025-10-05 17:50:34,522 - WARNING - NaN/inf in loss_classifier (batch 1089) - using fallback: 0.0593 (count: 1)
2025-10-05 17:50:34,522 - WARNING - NaN/inf in loss_box_reg (batch 1089) - using fallback: 0.0633 (count: 1)
2025-10-05 17:50:34,523 - WARNING - NaN/inf in loss_objectness (batch 1089) - using fallback: 0.0253 (count: 1)
2025-10-05 17:50:35,210 - WARNING - NaN/inf in loss_classifier (batch 1090) - using fallback: 0.0593 (count: 2)
2025-10-05 17:50:35,210 - WARNING - NaN/inf in loss_box_reg (batch 1090) - using fallback: 0.0633 (count: 2)
2025-10-05 17:50:35,210 - WARNING - NaN/inf in loss_objectness (batch 1090) - using fallback: 0.0253 (count: 2)
2025-10-05 17:50:50,303 - WARNING - NaN/inf in loss_classifier (batch 1110) - using fallback: 0.0579 (count: 1)
2025-10-05 17:50:50,304 - WARNING - NaN/inf in loss_objectness (batch 1110) - using fallback: 0.0254 (count: 1)
2025-10-05 17:50:51,757 - WARNING - NaN/inf in loss_classifier (batch 1112) - using fallback: 0.0583 (count: 1)
2025-10-05 17:50:51,758 - WARNING - NaN/inf in loss_objectness (batch 1112) - using fallback: 0.0252 (count: 1)
2025-10-05 17:50:58,021 - WARNING - NaN/inf in loss_classifier (batch 1120) - using fallback: 0.0608 (count: 1)
2025-10-05 17:50:58,022 - WARNING - NaN/inf in loss_objectness (batch 1120) - using fallback: 0.0237 (count: 1)
2025-10-05 17:51:18,693 - WARNING - NaN/inf in loss_classifier (batch 1147) - using fallback: 0.0609 (count: 1)
2025-10-05 17:51:18,693 - WARNING - NaN/inf in loss_box_reg (batch 1147) - using fallback: 0.0667 (count: 1)
2025-10-05 17:51:18,694 - WARNING - NaN/inf in loss_objectness (batch 1147) - using fallback: 0.0198 (count: 1)
2025-10-05 17:51:20,082 - WARNING - NaN/inf in loss_classifier (batch 1149) - using fallback: 0.0613 (count: 1)
2025-10-05 17:51:20,083 - WARNING - NaN/inf in loss_box_reg (batch 1149) - using fallback: 0.0669 (count: 1)
2025-10-05 17:51:20,083 - WARNING - NaN/inf in loss_objectness (batch 1149) - using fallback: 0.0196 (count: 1)
2025-10-05 17:51:34,289 - WARNING - NaN/inf in loss_classifier (batch 1168) - using fallback: 0.0615 (count: 1)
2025-10-05 17:51:34,289 - WARNING - NaN/inf in loss_box_reg (batch 1168) - using fallback: 0.0655 (count: 1)
2025-10-05 17:51:34,289 - WARNING - NaN/inf in loss_objectness (batch 1168) - using fallback: 0.0188 (count: 1)
2025-10-05 17:51:38,847 - WARNING - NaN/inf in loss_classifier (batch 1174) - using fallback: 0.0617 (count: 1)
2025-10-05 17:51:38,847 - WARNING - NaN/inf in loss_box_reg (batch 1174) - using fallback: 0.0660 (count: 1)
2025-10-05 17:51:38,848 - WARNING - NaN/inf in loss_objectness (batch 1174) - using fallback: 0.0193 (count: 1)
2025-10-05 17:51:42,542 - WARNING - NaN/inf in loss_classifier (batch 1179) - using fallback: 0.0615 (count: 1)
2025-10-05 17:51:42,542 - WARNING - NaN/inf in loss_box_reg (batch 1179) - using fallback: 0.0643 (count: 1)
2025-10-05 17:51:42,543 - WARNING - NaN/inf in loss_objectness (batch 1179) - using fallback: 0.0199 (count: 1)
2025-10-05 17:51:44,767 - WARNING - NaN/inf in loss_classifier (batch 1182) - using fallback: 0.0607 (count: 1)
2025-10-05 17:51:44,768 - WARNING - NaN/inf in loss_objectness (batch 1182) - using fallback: 0.0198 (count: 1)
2025-10-05 17:51:50,065 - WARNING - NaN/inf in loss_classifier (batch 1189) - using fallback: 0.0607 (count: 1)
2025-10-05 17:51:50,066 - WARNING - NaN/inf in loss_objectness (batch 1189) - using fallback: 0.0201 (count: 1)
2025-10-05 17:51:52,406 - WARNING - NaN/inf in loss_classifier (batch 1192) - using fallback: 0.0600 (count: 1)
2025-10-05 17:51:52,406 - WARNING - NaN/inf in loss_objectness (batch 1192) - using fallback: 0.0197 (count: 1)
2025-10-05 17:51:53,925 - WARNING - NaN/inf in loss_classifier (batch 1194) - using fallback: 0.0599 (count: 1)
2025-10-05 17:51:53,926 - WARNING - NaN/inf in loss_objectness (batch 1194) - using fallback: 0.0196 (count: 1)
2025-10-05 17:51:57,645 - WARNING - NaN/inf in loss_classifier (batch 1199) - using fallback: 0.0594 (count: 1)
2025-10-05 17:51:57,646 - WARNING - NaN/inf in loss_objectness (batch 1199) - using fallback: 0.0189 (count: 1)
2025-10-05 17:51:59,895 - WARNING - NaN/inf in loss_classifier (batch 1202) - using fallback: 0.0595 (count: 1)
2025-10-05 17:51:59,896 - WARNING - NaN/inf in loss_objectness (batch 1202) - using fallback: 0.0185 (count: 1)
2025-10-05 17:52:13,483 - WARNING - NaN/inf in loss_classifier (batch 1220) - using fallback: 0.0581 (count: 1)
2025-10-05 17:52:13,483 - WARNING - NaN/inf in loss_box_reg (batch 1220) - using fallback: 0.0612 (count: 1)
2025-10-05 17:52:13,484 - WARNING - NaN/inf in loss_objectness (batch 1220) - using fallback: 0.0180 (count: 1)
2025-10-05 17:52:14,962 - WARNING - NaN/inf in loss_classifier (batch 1222) - using fallback: 0.0581 (count: 1)
2025-10-05 17:52:14,963 - WARNING - NaN/inf in loss_box_reg (batch 1222) - using fallback: 0.0611 (count: 1)
2025-10-05 17:52:14,963 - WARNING - NaN/inf in loss_objectness (batch 1222) - using fallback: 0.0186 (count: 1)
2025-10-05 17:52:20,257 - WARNING - NaN/inf in loss_classifier (batch 1229) - using fallback: 0.0599 (count: 1)
2025-10-05 17:52:20,258 - WARNING - NaN/inf in loss_objectness (batch 1229) - using fallback: 0.0216 (count: 1)
2025-10-05 17:52:22,528 - WARNING - NaN/inf in loss_classifier (batch 1232) - using fallback: 0.0603 (count: 1)
2025-10-05 17:52:22,528 - WARNING - NaN/inf in loss_box_reg (batch 1232) - using fallback: 0.0624 (count: 1)
2025-10-05 17:52:22,529 - WARNING - NaN/inf in loss_objectness (batch 1232) - using fallback: 0.0211 (count: 1)
2025-10-05 17:52:24,793 - WARNING - NaN/inf in loss_classifier (batch 1235) - using fallback: 0.0610 (count: 1)
2025-10-05 17:52:24,794 - WARNING - NaN/inf in loss_objectness (batch 1235) - using fallback: 0.0206 (count: 1)
2025-10-05 17:52:36,884 - WARNING - NaN/inf in loss_classifier (batch 1251) - using fallback: 0.0604 (count: 1)
2025-10-05 17:52:36,885 - WARNING - NaN/inf in loss_objectness (batch 1251) - using fallback: 0.0199 (count: 1)
2025-10-05 17:52:41,359 - WARNING - NaN/inf in loss_classifier (batch 1257) - using fallback: 0.0603 (count: 1)
2025-10-05 17:52:41,360 - WARNING - NaN/inf in loss_box_reg (batch 1257) - using fallback: 0.0621 (count: 1)
2025-10-05 17:52:41,360 - WARNING - NaN/inf in loss_objectness (batch 1257) - using fallback: 0.0197 (count: 1)
2025-10-05 17:52:59,003 - WARNING - NaN/inf in loss_classifier (batch 1280) - using fallback: 0.0590 (count: 1)
2025-10-05 17:52:59,003 - WARNING - NaN/inf in loss_objectness (batch 1280) - using fallback: 0.0220 (count: 1)
2025-10-05 17:53:02,743 - WARNING - NaN/inf in loss_classifier (batch 1285) - using fallback: 0.0594 (count: 1)
2025-10-05 17:53:02,744 - WARNING - NaN/inf in loss_box_reg (batch 1285) - using fallback: 0.0616 (count: 1)
2025-10-05 17:53:02,745 - WARNING - NaN/inf in loss_objectness (batch 1285) - using fallback: 0.0211 (count: 1)
2025-10-05 17:53:04,144 - WARNING - NaN/inf in loss_classifier (batch 1287) - using fallback: 0.0590 (count: 1)
2025-10-05 17:53:04,144 - WARNING - NaN/inf in loss_box_reg (batch 1287) - using fallback: 0.0615 (count: 1)
2025-10-05 17:53:04,145 - WARNING - NaN/inf in loss_objectness (batch 1287) - using fallback: 0.0210 (count: 1)
2025-10-05 17:53:05,576 - WARNING - NaN/inf in loss_classifier (batch 1289) - using fallback: 0.0594 (count: 1)
2025-10-05 17:53:05,576 - WARNING - NaN/inf in loss_box_reg (batch 1289) - using fallback: 0.0625 (count: 1)
2025-10-05 17:53:05,577 - WARNING - NaN/inf in loss_objectness (batch 1289) - using fallback: 0.0207 (count: 1)
2025-10-05 17:53:07,077 - WARNING - NaN/inf in loss_classifier (batch 1291) - using fallback: 0.0590 (count: 1)
2025-10-05 17:53:07,077 - WARNING - NaN/inf in loss_box_reg (batch 1291) - using fallback: 0.0619 (count: 1)
2025-10-05 17:53:07,078 - WARNING - NaN/inf in loss_objectness (batch 1291) - using fallback: 0.0207 (count: 1)
2025-10-05 17:53:27,577 - WARNING - NaN/inf in loss_classifier (batch 1318) - using fallback: 0.0608 (count: 1)
2025-10-05 17:53:27,578 - WARNING - NaN/inf in loss_objectness (batch 1318) - using fallback: 0.0179 (count: 1)
2025-10-05 17:53:28,287 - WARNING - NaN/inf in loss_classifier (batch 1319) - using fallback: 0.0608 (count: 2)
2025-10-05 17:53:28,288 - WARNING - NaN/inf in loss_objectness (batch 1319) - using fallback: 0.0179 (count: 2)
2025-10-05 17:53:39,639 - WARNING - NaN/inf in loss_classifier (batch 1334) - using fallback: 0.0605 (count: 1)
2025-10-05 17:53:39,639 - WARNING - NaN/inf in loss_objectness (batch 1334) - using fallback: 0.0196 (count: 1)
2025-10-05 17:53:41,976 - WARNING - NaN/inf in loss_classifier (batch 1337) - using fallback: 0.0609 (count: 1)
2025-10-05 17:53:41,977 - WARNING - NaN/inf in loss_objectness (batch 1337) - using fallback: 0.0190 (count: 1)
2025-10-05 17:53:57,165 - WARNING - NaN/inf in loss_classifier (batch 1357) - using fallback: 0.0609 (count: 1)
2025-10-05 17:53:57,166 - WARNING - NaN/inf in loss_objectness (batch 1357) - using fallback: 0.0210 (count: 1)
2025-10-05 17:54:00,126 - WARNING - NaN/inf in loss_classifier (batch 1361) - using fallback: 0.0605 (count: 1)
2025-10-05 17:54:00,127 - WARNING - NaN/inf in loss_box_reg (batch 1361) - using fallback: 0.0633 (count: 1)
2025-10-05 17:54:00,127 - WARNING - NaN/inf in loss_objectness (batch 1361) - using fallback: 0.0204 (count: 1)
2025-10-05 17:54:01,524 - WARNING - NaN/inf in loss_classifier (batch 1363) - using fallback: 0.0604 (count: 1)
2025-10-05 17:54:01,525 - WARNING - NaN/inf in loss_box_reg (batch 1363) - using fallback: 0.0635 (count: 1)
2025-10-05 17:54:01,525 - WARNING - NaN/inf in loss_objectness (batch 1363) - using fallback: 0.0201 (count: 1)
2025-10-05 17:54:01,525 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1363) - using fallback: 0.0251 (count: 1)
2025-10-05 17:54:01,526 - ERROR - Error processing batch 1363: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:01,970 - WARNING - NaN/inf in loss_classifier (batch 1364) - using fallback: 0.0604 (count: 2)
2025-10-05 17:54:01,971 - WARNING - NaN/inf in loss_box_reg (batch 1364) - using fallback: 0.0635 (count: 2)
2025-10-05 17:54:01,971 - WARNING - NaN/inf in loss_objectness (batch 1364) - using fallback: 0.0201 (count: 2)
2025-10-05 17:54:01,971 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1364) - using fallback: 0.0251 (count: 2)
2025-10-05 17:54:01,972 - ERROR - Error processing batch 1364: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:02,673 - WARNING - NaN/inf in loss_classifier (batch 1365) - using fallback: 0.0604 (count: 3)
2025-10-05 17:54:02,673 - WARNING - NaN/inf in loss_box_reg (batch 1365) - using fallback: 0.0635 (count: 3)
2025-10-05 17:54:02,674 - WARNING - NaN/inf in loss_objectness (batch 1365) - using fallback: 0.0201 (count: 3)
2025-10-05 17:54:02,674 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1365) - using fallback: 0.0251 (count: 3)
2025-10-05 17:54:02,675 - ERROR - Error processing batch 1365: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:03,445 - WARNING - NaN/inf in loss_classifier (batch 1366) - using fallback: 0.0604 (count: 4)
2025-10-05 17:54:03,445 - WARNING - NaN/inf in loss_box_reg (batch 1366) - using fallback: 0.0635 (count: 4)
2025-10-05 17:54:03,446 - WARNING - NaN/inf in loss_objectness (batch 1366) - using fallback: 0.0201 (count: 4)
2025-10-05 17:54:03,446 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1366) - using fallback: 0.0251 (count: 4)
2025-10-05 17:54:03,447 - ERROR - Error processing batch 1366: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:04,371 - WARNING - NaN/inf in loss_classifier (batch 1367) - using fallback: 0.0604 (count: 5)
2025-10-05 17:54:04,371 - WARNING - NaN/inf in loss_box_reg (batch 1367) - using fallback: 0.0635 (count: 5)
2025-10-05 17:54:04,372 - WARNING - NaN/inf in loss_objectness (batch 1367) - using fallback: 0.0201 (count: 5)
2025-10-05 17:54:04,372 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1367) - using fallback: 0.0251 (count: 5)
2025-10-05 17:54:04,373 - ERROR - Error processing batch 1367: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:05,456 - WARNING - NaN/inf in loss_classifier (batch 1368) - using fallback: 0.0302 (count: 6)
2025-10-05 17:54:05,457 - WARNING - NaN/inf in loss_box_reg (batch 1368) - using fallback: 0.0318 (count: 6)
2025-10-05 17:54:05,457 - WARNING - NaN/inf in loss_objectness (batch 1368) - using fallback: 0.0101 (count: 6)
2025-10-05 17:54:05,458 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1368) - using fallback: 0.0126 (count: 6)
2025-10-05 17:54:05,459 - ERROR - Error processing batch 1368: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:06,639 - WARNING - NaN/inf in loss_classifier (batch 1369) - using fallback: 0.0302 (count: 7)
2025-10-05 17:54:06,640 - WARNING - NaN/inf in loss_box_reg (batch 1369) - using fallback: 0.0318 (count: 7)
2025-10-05 17:54:06,641 - WARNING - NaN/inf in loss_objectness (batch 1369) - using fallback: 0.0101 (count: 7)
2025-10-05 17:54:06,641 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1369) - using fallback: 0.0126 (count: 7)
2025-10-05 17:54:06,642 - ERROR - Error processing batch 1369: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:07,415 - WARNING - NaN/inf in loss_classifier (batch 1370) - using fallback: 0.0302 (count: 8)
2025-10-05 17:54:07,416 - WARNING - NaN/inf in loss_box_reg (batch 1370) - using fallback: 0.0318 (count: 8)
2025-10-05 17:54:07,416 - WARNING - NaN/inf in loss_objectness (batch 1370) - using fallback: 0.0101 (count: 8)
2025-10-05 17:54:07,417 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1370) - using fallback: 0.0126 (count: 8)
2025-10-05 17:54:07,418 - ERROR - Error processing batch 1370: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:08,359 - WARNING - NaN/inf in loss_classifier (batch 1371) - using fallback: 0.0302 (count: 9)
2025-10-05 17:54:08,360 - WARNING - NaN/inf in loss_box_reg (batch 1371) - using fallback: 0.0318 (count: 9)
2025-10-05 17:54:08,361 - WARNING - NaN/inf in loss_objectness (batch 1371) - using fallback: 0.0101 (count: 9)
2025-10-05 17:54:08,361 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1371) - using fallback: 0.0126 (count: 9)
2025-10-05 17:54:08,362 - ERROR - Error processing batch 1371: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:09,500 - WARNING - NaN/inf in loss_classifier (batch 1372) - using fallback: 0.0302 (count: 10)
2025-10-05 17:54:09,501 - WARNING - NaN/inf in loss_box_reg (batch 1372) - using fallback: 0.0318 (count: 10)
2025-10-05 17:54:09,502 - WARNING - NaN/inf in loss_objectness (batch 1372) - using fallback: 0.0101 (count: 10)
2025-10-05 17:54:09,502 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1372) - using fallback: 0.0126 (count: 10)
2025-10-05 17:54:09,503 - ERROR - Error processing batch 1372: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:10,995 - WARNING - NaN/inf in loss_classifier (batch 1373) - using fallback: 0.0302 (count: 11)
2025-10-05 17:54:10,996 - WARNING - NaN/inf in loss_box_reg (batch 1373) - using fallback: 0.0318 (count: 11)
2025-10-05 17:54:10,997 - WARNING - NaN/inf in loss_objectness (batch 1373) - using fallback: 0.0101 (count: 11)
2025-10-05 17:54:10,997 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1373) - using fallback: 0.0126 (count: 11)
2025-10-05 17:54:10,998 - ERROR - Error processing batch 1373: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:11,795 - WARNING - NaN/inf in loss_classifier (batch 1374) - using fallback: 0.0302 (count: 12)
2025-10-05 17:54:11,796 - WARNING - NaN/inf in loss_box_reg (batch 1374) - using fallback: 0.0318 (count: 12)
2025-10-05 17:54:11,796 - WARNING - NaN/inf in loss_objectness (batch 1374) - using fallback: 0.0101 (count: 12)
2025-10-05 17:54:11,797 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1374) - using fallback: 0.0126 (count: 12)
2025-10-05 17:54:11,798 - ERROR - Error processing batch 1374: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:12,429 - WARNING - NaN/inf in loss_classifier (batch 1375) - using fallback: 0.0302 (count: 13)
2025-10-05 17:54:12,430 - WARNING - NaN/inf in loss_box_reg (batch 1375) - using fallback: 0.0318 (count: 13)
2025-10-05 17:54:12,431 - WARNING - NaN/inf in loss_objectness (batch 1375) - using fallback: 0.0101 (count: 13)
2025-10-05 17:54:12,432 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1375) - using fallback: 0.0126 (count: 13)
2025-10-05 17:54:12,433 - ERROR - Error processing batch 1375: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:13,131 - WARNING - NaN/inf in loss_classifier (batch 1376) - using fallback: 0.0302 (count: 14)
2025-10-05 17:54:13,132 - WARNING - NaN/inf in loss_box_reg (batch 1376) - using fallback: 0.0318 (count: 14)
2025-10-05 17:54:13,132 - WARNING - NaN/inf in loss_objectness (batch 1376) - using fallback: 0.0101 (count: 14)
2025-10-05 17:54:13,132 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1376) - using fallback: 0.0126 (count: 14)
2025-10-05 17:54:13,133 - ERROR - Error processing batch 1376: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:13,651 - WARNING - NaN/inf in loss_classifier (batch 1377) - using fallback: 0.0302 (count: 15)
2025-10-05 17:54:13,651 - WARNING - NaN/inf in loss_box_reg (batch 1377) - using fallback: 0.0318 (count: 15)
2025-10-05 17:54:13,652 - WARNING - NaN/inf in loss_objectness (batch 1377) - using fallback: 0.0101 (count: 15)
2025-10-05 17:54:13,652 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1377) - using fallback: 0.0126 (count: 15)
2025-10-05 17:54:13,653 - ERROR - Error processing batch 1377: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:15,079 - WARNING - NaN/inf in loss_classifier (batch 1378) - using fallback: 0.0302 (count: 16)
2025-10-05 17:54:15,079 - WARNING - NaN/inf in loss_box_reg (batch 1378) - using fallback: 0.0318 (count: 16)
2025-10-05 17:54:15,080 - WARNING - NaN/inf in loss_objectness (batch 1378) - using fallback: 0.0101 (count: 16)
2025-10-05 17:54:15,080 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1378) - using fallback: 0.0126 (count: 16)
2025-10-05 17:54:15,081 - ERROR - Error processing batch 1378: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:16,237 - WARNING - NaN/inf in loss_classifier (batch 1379) - using fallback: 0.0302 (count: 17)
2025-10-05 17:54:16,237 - WARNING - NaN/inf in loss_box_reg (batch 1379) - using fallback: 0.0318 (count: 17)
2025-10-05 17:54:16,238 - WARNING - NaN/inf in loss_objectness (batch 1379) - using fallback: 0.0101 (count: 17)
2025-10-05 17:54:16,238 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1379) - using fallback: 0.0126 (count: 17)
2025-10-05 17:54:16,239 - ERROR - Error processing batch 1379: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:17,469 - WARNING - NaN/inf in loss_classifier (batch 1380) - using fallback: 0.0302 (count: 18)
2025-10-05 17:54:17,470 - WARNING - NaN/inf in loss_box_reg (batch 1380) - using fallback: 0.0318 (count: 18)
2025-10-05 17:54:17,470 - WARNING - NaN/inf in loss_objectness (batch 1380) - using fallback: 0.0101 (count: 18)
2025-10-05 17:54:17,471 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1380) - using fallback: 0.0126 (count: 18)
2025-10-05 17:54:17,472 - ERROR - Error processing batch 1380: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:19,448 - WARNING - NaN/inf in loss_classifier (batch 1381) - using fallback: 0.0302 (count: 19)
2025-10-05 17:54:19,449 - WARNING - NaN/inf in loss_box_reg (batch 1381) - using fallback: 0.0318 (count: 19)
2025-10-05 17:54:19,449 - WARNING - NaN/inf in loss_objectness (batch 1381) - using fallback: 0.0101 (count: 19)
2025-10-05 17:54:19,449 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1381) - using fallback: 0.0126 (count: 19)
2025-10-05 17:54:19,450 - ERROR - Error processing batch 1381: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:20,561 - WARNING - NaN/inf in loss_classifier (batch 1382) - using fallback: 0.0302 (count: 20)
2025-10-05 17:54:20,562 - WARNING - NaN/inf in loss_box_reg (batch 1382) - using fallback: 0.0318 (count: 20)
2025-10-05 17:54:20,562 - WARNING - NaN/inf in loss_objectness (batch 1382) - using fallback: 0.0101 (count: 20)
2025-10-05 17:54:20,562 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1382) - using fallback: 0.0126 (count: 20)
2025-10-05 17:54:20,563 - ERROR - Error processing batch 1382: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:22,025 - WARNING - NaN/inf in loss_classifier (batch 1383) - using fallback: 0.0302 (count: 21)
2025-10-05 17:54:22,026 - WARNING - NaN/inf in loss_box_reg (batch 1383) - using fallback: 0.0318 (count: 21)
2025-10-05 17:54:22,026 - WARNING - NaN/inf in loss_objectness (batch 1383) - using fallback: 0.0101 (count: 21)
2025-10-05 17:54:22,027 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1383) - using fallback: 0.0126 (count: 21)
2025-10-05 17:54:22,027 - ERROR - Error processing batch 1383: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:23,616 - WARNING - NaN/inf in loss_classifier (batch 1384) - using fallback: 0.0302 (count: 22)
2025-10-05 17:54:23,617 - WARNING - NaN/inf in loss_box_reg (batch 1384) - using fallback: 0.0318 (count: 22)
2025-10-05 17:54:23,617 - WARNING - NaN/inf in loss_objectness (batch 1384) - using fallback: 0.0101 (count: 22)
2025-10-05 17:54:23,618 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1384) - using fallback: 0.0126 (count: 22)
2025-10-05 17:54:23,619 - ERROR - Error processing batch 1384: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:24,763 - WARNING - NaN/inf in loss_classifier (batch 1385) - using fallback: 0.0302 (count: 23)
2025-10-05 17:54:24,763 - WARNING - NaN/inf in loss_box_reg (batch 1385) - using fallback: 0.0318 (count: 23)
2025-10-05 17:54:24,764 - WARNING - NaN/inf in loss_objectness (batch 1385) - using fallback: 0.0101 (count: 23)
2025-10-05 17:54:24,764 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1385) - using fallback: 0.0126 (count: 23)
2025-10-05 17:54:24,765 - ERROR - Error processing batch 1385: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:26,414 - WARNING - NaN/inf in loss_classifier (batch 1386) - using fallback: 0.0302 (count: 24)
2025-10-05 17:54:26,415 - WARNING - NaN/inf in loss_box_reg (batch 1386) - using fallback: 0.0318 (count: 24)
2025-10-05 17:54:26,417 - WARNING - NaN/inf in loss_objectness (batch 1386) - using fallback: 0.0101 (count: 24)
2025-10-05 17:54:26,418 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1386) - using fallback: 0.0126 (count: 24)
2025-10-05 17:54:26,419 - ERROR - Error processing batch 1386: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:28,499 - WARNING - NaN/inf in loss_classifier (batch 1387) - using fallback: 0.0302 (count: 25)
2025-10-05 17:54:28,500 - WARNING - NaN/inf in loss_box_reg (batch 1387) - using fallback: 0.0318 (count: 25)
2025-10-05 17:54:28,500 - WARNING - NaN/inf in loss_objectness (batch 1387) - using fallback: 0.0101 (count: 25)
2025-10-05 17:54:28,500 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1387) - using fallback: 0.0126 (count: 25)
2025-10-05 17:54:28,501 - ERROR - Error processing batch 1387: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:29,811 - WARNING - NaN/inf in loss_classifier (batch 1388) - using fallback: 0.0302 (count: 26)
2025-10-05 17:54:29,811 - WARNING - NaN/inf in loss_box_reg (batch 1388) - using fallback: 0.0318 (count: 26)
2025-10-05 17:54:29,811 - WARNING - NaN/inf in loss_objectness (batch 1388) - using fallback: 0.0101 (count: 26)
2025-10-05 17:54:29,812 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1388) - using fallback: 0.0126 (count: 26)
2025-10-05 17:54:29,812 - ERROR - Error processing batch 1388: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:31,934 - WARNING - NaN/inf in loss_classifier (batch 1389) - using fallback: 0.0302 (count: 27)
2025-10-05 17:54:31,934 - WARNING - NaN/inf in loss_box_reg (batch 1389) - using fallback: 0.0318 (count: 27)
2025-10-05 17:54:31,935 - WARNING - NaN/inf in loss_objectness (batch 1389) - using fallback: 0.0101 (count: 27)
2025-10-05 17:54:31,935 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1389) - using fallback: 0.0126 (count: 27)
2025-10-05 17:54:31,936 - ERROR - Error processing batch 1389: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:33,352 - WARNING - NaN/inf in loss_classifier (batch 1390) - using fallback: 0.0302 (count: 28)
2025-10-05 17:54:33,352 - WARNING - NaN/inf in loss_box_reg (batch 1390) - using fallback: 0.0318 (count: 28)
2025-10-05 17:54:33,353 - WARNING - NaN/inf in loss_objectness (batch 1390) - using fallback: 0.0101 (count: 28)
2025-10-05 17:54:33,354 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1390) - using fallback: 0.0126 (count: 28)
2025-10-05 17:54:33,354 - ERROR - Error processing batch 1390: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:35,695 - WARNING - NaN/inf in loss_classifier (batch 1391) - using fallback: 0.0302 (count: 29)
2025-10-05 17:54:35,695 - WARNING - NaN/inf in loss_box_reg (batch 1391) - using fallback: 0.0318 (count: 29)
2025-10-05 17:54:35,696 - WARNING - NaN/inf in loss_objectness (batch 1391) - using fallback: 0.0101 (count: 29)
2025-10-05 17:54:35,697 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1391) - using fallback: 0.0126 (count: 29)
2025-10-05 17:54:35,698 - ERROR - Error processing batch 1391: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:38,090 - WARNING - NaN/inf in loss_classifier (batch 1392) - using fallback: 0.0302 (count: 30)
2025-10-05 17:54:38,091 - WARNING - NaN/inf in loss_box_reg (batch 1392) - using fallback: 0.0318 (count: 30)
2025-10-05 17:54:38,092 - WARNING - NaN/inf in loss_objectness (batch 1392) - using fallback: 0.0101 (count: 30)
2025-10-05 17:54:38,092 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1392) - using fallback: 0.0126 (count: 30)
2025-10-05 17:54:38,093 - ERROR - Error processing batch 1392: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:40,236 - WARNING - NaN/inf in loss_classifier (batch 1393) - using fallback: 0.0302 (count: 31)
2025-10-05 17:54:40,237 - WARNING - NaN/inf in loss_box_reg (batch 1393) - using fallback: 0.0318 (count: 31)
2025-10-05 17:54:40,238 - WARNING - NaN/inf in loss_objectness (batch 1393) - using fallback: 0.0101 (count: 31)
2025-10-05 17:54:40,239 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1393) - using fallback: 0.0126 (count: 31)
2025-10-05 17:54:40,239 - ERROR - Error processing batch 1393: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:42,625 - WARNING - NaN/inf in loss_classifier (batch 1394) - using fallback: 0.0302 (count: 32)
2025-10-05 17:54:42,626 - WARNING - NaN/inf in loss_box_reg (batch 1394) - using fallback: 0.0318 (count: 32)
2025-10-05 17:54:42,627 - WARNING - NaN/inf in loss_objectness (batch 1394) - using fallback: 0.0101 (count: 32)
2025-10-05 17:54:42,627 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1394) - using fallback: 0.0126 (count: 32)
2025-10-05 17:54:42,628 - ERROR - Error processing batch 1394: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:44,742 - WARNING - NaN/inf in loss_classifier (batch 1395) - using fallback: 0.0302 (count: 33)
2025-10-05 17:54:44,742 - WARNING - NaN/inf in loss_box_reg (batch 1395) - using fallback: 0.0318 (count: 33)
2025-10-05 17:54:44,743 - WARNING - NaN/inf in loss_objectness (batch 1395) - using fallback: 0.0101 (count: 33)
2025-10-05 17:54:44,744 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1395) - using fallback: 0.0126 (count: 33)
2025-10-05 17:54:44,745 - ERROR - Error processing batch 1395: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:47,026 - WARNING - NaN/inf in loss_classifier (batch 1396) - using fallback: 0.0302 (count: 34)
2025-10-05 17:54:47,027 - WARNING - NaN/inf in loss_box_reg (batch 1396) - using fallback: 0.0318 (count: 34)
2025-10-05 17:54:47,027 - WARNING - NaN/inf in loss_objectness (batch 1396) - using fallback: 0.0101 (count: 34)
2025-10-05 17:54:47,028 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1396) - using fallback: 0.0126 (count: 34)
2025-10-05 17:54:47,029 - ERROR - Error processing batch 1396: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:49,091 - WARNING - NaN/inf in loss_classifier (batch 1397) - using fallback: 0.0302 (count: 35)
2025-10-05 17:54:49,092 - WARNING - NaN/inf in loss_box_reg (batch 1397) - using fallback: 0.0318 (count: 35)
2025-10-05 17:54:49,093 - WARNING - NaN/inf in loss_objectness (batch 1397) - using fallback: 0.0101 (count: 35)
2025-10-05 17:54:49,093 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1397) - using fallback: 0.0126 (count: 35)
2025-10-05 17:54:49,094 - ERROR - Error processing batch 1397: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:51,516 - WARNING - NaN/inf in loss_classifier (batch 1398) - using fallback: 0.0302 (count: 36)
2025-10-05 17:54:51,516 - WARNING - NaN/inf in loss_box_reg (batch 1398) - using fallback: 0.0318 (count: 36)
2025-10-05 17:54:51,517 - WARNING - NaN/inf in loss_objectness (batch 1398) - using fallback: 0.0101 (count: 36)
2025-10-05 17:54:51,518 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1398) - using fallback: 0.0126 (count: 36)
2025-10-05 17:54:51,519 - ERROR - Error processing batch 1398: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:53,525 - WARNING - NaN/inf in loss_classifier (batch 1399) - using fallback: 0.0302 (count: 37)
2025-10-05 17:54:53,526 - WARNING - NaN/inf in loss_box_reg (batch 1399) - using fallback: 0.0318 (count: 37)
2025-10-05 17:54:53,527 - WARNING - NaN/inf in loss_objectness (batch 1399) - using fallback: 0.0101 (count: 37)
2025-10-05 17:54:53,527 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1399) - using fallback: 0.0126 (count: 37)
2025-10-05 17:54:53,528 - ERROR - Error processing batch 1399: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:56,131 - WARNING - NaN/inf in loss_classifier (batch 1400) - using fallback: 0.0302 (count: 38)
2025-10-05 17:54:56,132 - WARNING - NaN/inf in loss_box_reg (batch 1400) - using fallback: 0.0318 (count: 38)
2025-10-05 17:54:56,133 - WARNING - NaN/inf in loss_objectness (batch 1400) - using fallback: 0.0101 (count: 38)
2025-10-05 17:54:56,134 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1400) - using fallback: 0.0126 (count: 38)
2025-10-05 17:54:56,135 - ERROR - Error processing batch 1400: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:54:58,191 - WARNING - NaN/inf in loss_classifier (batch 1401) - using fallback: 0.0302 (count: 39)
2025-10-05 17:54:58,192 - WARNING - NaN/inf in loss_box_reg (batch 1401) - using fallback: 0.0318 (count: 39)
2025-10-05 17:54:58,193 - WARNING - NaN/inf in loss_objectness (batch 1401) - using fallback: 0.0101 (count: 39)
2025-10-05 17:54:58,194 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1401) - using fallback: 0.0126 (count: 39)
2025-10-05 17:54:58,195 - ERROR - Error processing batch 1401: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:00,787 - WARNING - NaN/inf in loss_classifier (batch 1402) - using fallback: 0.0302 (count: 40)
2025-10-05 17:55:00,788 - WARNING - NaN/inf in loss_box_reg (batch 1402) - using fallback: 0.0318 (count: 40)
2025-10-05 17:55:00,789 - WARNING - NaN/inf in loss_objectness (batch 1402) - using fallback: 0.0101 (count: 40)
2025-10-05 17:55:00,790 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1402) - using fallback: 0.0126 (count: 40)
2025-10-05 17:55:00,791 - ERROR - Error processing batch 1402: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:02,872 - WARNING - NaN/inf in loss_classifier (batch 1403) - using fallback: 0.0302 (count: 41)
2025-10-05 17:55:02,872 - WARNING - NaN/inf in loss_box_reg (batch 1403) - using fallback: 0.0318 (count: 41)
2025-10-05 17:55:02,873 - WARNING - NaN/inf in loss_objectness (batch 1403) - using fallback: 0.0101 (count: 41)
2025-10-05 17:55:02,874 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1403) - using fallback: 0.0126 (count: 41)
2025-10-05 17:55:02,875 - ERROR - Error processing batch 1403: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:05,337 - WARNING - NaN/inf in loss_classifier (batch 1404) - using fallback: 0.0302 (count: 42)
2025-10-05 17:55:05,337 - WARNING - NaN/inf in loss_box_reg (batch 1404) - using fallback: 0.0318 (count: 42)
2025-10-05 17:55:05,338 - WARNING - NaN/inf in loss_objectness (batch 1404) - using fallback: 0.0101 (count: 42)
2025-10-05 17:55:05,339 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1404) - using fallback: 0.0126 (count: 42)
2025-10-05 17:55:05,339 - ERROR - Error processing batch 1404: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:07,526 - WARNING - NaN/inf in loss_classifier (batch 1405) - using fallback: 0.0302 (count: 43)
2025-10-05 17:55:07,527 - WARNING - NaN/inf in loss_box_reg (batch 1405) - using fallback: 0.0318 (count: 43)
2025-10-05 17:55:07,528 - WARNING - NaN/inf in loss_objectness (batch 1405) - using fallback: 0.0101 (count: 43)
2025-10-05 17:55:07,528 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1405) - using fallback: 0.0126 (count: 43)
2025-10-05 17:55:07,529 - ERROR - Error processing batch 1405: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:09,525 - WARNING - NaN/inf in loss_classifier (batch 1406) - using fallback: 0.0302 (count: 44)
2025-10-05 17:55:09,525 - WARNING - NaN/inf in loss_box_reg (batch 1406) - using fallback: 0.0318 (count: 44)
2025-10-05 17:55:09,526 - WARNING - NaN/inf in loss_objectness (batch 1406) - using fallback: 0.0101 (count: 44)
2025-10-05 17:55:09,526 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1406) - using fallback: 0.0126 (count: 44)
2025-10-05 17:55:09,527 - ERROR - Error processing batch 1406: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:12,084 - WARNING - NaN/inf in loss_classifier (batch 1407) - using fallback: 0.0302 (count: 45)
2025-10-05 17:55:12,084 - WARNING - NaN/inf in loss_box_reg (batch 1407) - using fallback: 0.0318 (count: 45)
2025-10-05 17:55:12,085 - WARNING - NaN/inf in loss_objectness (batch 1407) - using fallback: 0.0101 (count: 45)
2025-10-05 17:55:12,085 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1407) - using fallback: 0.0126 (count: 45)
2025-10-05 17:55:12,086 - ERROR - Error processing batch 1407: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:14,530 - WARNING - NaN/inf in loss_classifier (batch 1408) - using fallback: 0.0302 (count: 46)
2025-10-05 17:55:14,531 - WARNING - NaN/inf in loss_box_reg (batch 1408) - using fallback: 0.0318 (count: 46)
2025-10-05 17:55:14,531 - WARNING - NaN/inf in loss_objectness (batch 1408) - using fallback: 0.0101 (count: 46)
2025-10-05 17:55:14,532 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1408) - using fallback: 0.0126 (count: 46)
2025-10-05 17:55:14,533 - ERROR - Error processing batch 1408: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:16,747 - WARNING - NaN/inf in loss_classifier (batch 1409) - using fallback: 0.0302 (count: 47)
2025-10-05 17:55:16,747 - WARNING - NaN/inf in loss_box_reg (batch 1409) - using fallback: 0.0318 (count: 47)
2025-10-05 17:55:16,748 - WARNING - NaN/inf in loss_objectness (batch 1409) - using fallback: 0.0101 (count: 47)
2025-10-05 17:55:16,749 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1409) - using fallback: 0.0126 (count: 47)
2025-10-05 17:55:16,749 - ERROR - Error processing batch 1409: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:19,017 - WARNING - NaN/inf in loss_classifier (batch 1410) - using fallback: 0.0302 (count: 48)
2025-10-05 17:55:19,018 - WARNING - NaN/inf in loss_box_reg (batch 1410) - using fallback: 0.0318 (count: 48)
2025-10-05 17:55:19,018 - WARNING - NaN/inf in loss_objectness (batch 1410) - using fallback: 0.0101 (count: 48)
2025-10-05 17:55:19,019 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1410) - using fallback: 0.0126 (count: 48)
2025-10-05 17:55:19,019 - ERROR - Error processing batch 1410: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:21,068 - WARNING - NaN/inf in loss_classifier (batch 1411) - using fallback: 0.0302 (count: 49)
2025-10-05 17:55:21,069 - WARNING - NaN/inf in loss_box_reg (batch 1411) - using fallback: 0.0318 (count: 49)
2025-10-05 17:55:21,070 - WARNING - NaN/inf in loss_objectness (batch 1411) - using fallback: 0.0101 (count: 49)
2025-10-05 17:55:21,070 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1411) - using fallback: 0.0126 (count: 49)
2025-10-05 17:55:21,071 - ERROR - Error processing batch 1411: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:23,422 - WARNING - NaN/inf in loss_classifier (batch 1412) - using fallback: 0.0302 (count: 50)
2025-10-05 17:55:23,422 - WARNING - NaN/inf in loss_box_reg (batch 1412) - using fallback: 0.0318 (count: 50)
2025-10-05 17:55:23,423 - WARNING - NaN/inf in loss_objectness (batch 1412) - using fallback: 0.0101 (count: 50)
2025-10-05 17:55:23,424 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1412) - using fallback: 0.0126 (count: 50)
2025-10-05 17:55:23,424 - ERROR - Error processing batch 1412: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:25,368 - WARNING - NaN/inf in loss_classifier (batch 1413) - using fallback: 0.0302 (count: 51)
2025-10-05 17:55:25,368 - WARNING - NaN/inf in loss_box_reg (batch 1413) - using fallback: 0.0318 (count: 51)
2025-10-05 17:55:25,369 - WARNING - NaN/inf in loss_objectness (batch 1413) - using fallback: 0.0101 (count: 51)
2025-10-05 17:55:25,369 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1413) - using fallback: 0.0126 (count: 51)
2025-10-05 17:55:25,370 - ERROR - Error processing batch 1413: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:27,539 - WARNING - NaN/inf in loss_classifier (batch 1414) - using fallback: 0.0302 (count: 52)
2025-10-05 17:55:27,540 - WARNING - NaN/inf in loss_box_reg (batch 1414) - using fallback: 0.0318 (count: 52)
2025-10-05 17:55:27,540 - WARNING - NaN/inf in loss_objectness (batch 1414) - using fallback: 0.0101 (count: 52)
2025-10-05 17:55:27,541 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1414) - using fallback: 0.0126 (count: 52)
2025-10-05 17:55:27,542 - ERROR - Error processing batch 1414: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:29,512 - WARNING - NaN/inf in loss_classifier (batch 1415) - using fallback: 0.0302 (count: 53)
2025-10-05 17:55:29,512 - WARNING - NaN/inf in loss_box_reg (batch 1415) - using fallback: 0.0318 (count: 53)
2025-10-05 17:55:29,513 - WARNING - NaN/inf in loss_objectness (batch 1415) - using fallback: 0.0101 (count: 53)
2025-10-05 17:55:29,513 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1415) - using fallback: 0.0126 (count: 53)
2025-10-05 17:55:29,514 - ERROR - Error processing batch 1415: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:31,881 - WARNING - NaN/inf in loss_classifier (batch 1416) - using fallback: 0.0302 (count: 54)
2025-10-05 17:55:31,882 - WARNING - NaN/inf in loss_box_reg (batch 1416) - using fallback: 0.0318 (count: 54)
2025-10-05 17:55:31,882 - WARNING - NaN/inf in loss_objectness (batch 1416) - using fallback: 0.0101 (count: 54)
2025-10-05 17:55:31,883 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1416) - using fallback: 0.0126 (count: 54)
2025-10-05 17:55:31,883 - ERROR - Error processing batch 1416: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:34,105 - WARNING - NaN/inf in loss_classifier (batch 1417) - using fallback: 0.0302 (count: 55)
2025-10-05 17:55:34,106 - WARNING - NaN/inf in loss_box_reg (batch 1417) - using fallback: 0.0318 (count: 55)
2025-10-05 17:55:34,106 - WARNING - NaN/inf in loss_objectness (batch 1417) - using fallback: 0.0101 (count: 55)
2025-10-05 17:55:34,107 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1417) - using fallback: 0.0126 (count: 55)
2025-10-05 17:55:34,107 - ERROR - Error processing batch 1417: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:36,384 - WARNING - NaN/inf in loss_classifier (batch 1418) - using fallback: 0.0302 (count: 56)
2025-10-05 17:55:36,385 - WARNING - NaN/inf in loss_box_reg (batch 1418) - using fallback: 0.0318 (count: 56)
2025-10-05 17:55:36,385 - WARNING - NaN/inf in loss_objectness (batch 1418) - using fallback: 0.0101 (count: 56)
2025-10-05 17:55:36,386 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1418) - using fallback: 0.0126 (count: 56)
2025-10-05 17:55:36,387 - ERROR - Error processing batch 1418: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:38,749 - WARNING - NaN/inf in loss_classifier (batch 1419) - using fallback: 0.0302 (count: 57)
2025-10-05 17:55:38,749 - WARNING - NaN/inf in loss_box_reg (batch 1419) - using fallback: 0.0318 (count: 57)
2025-10-05 17:55:38,750 - WARNING - NaN/inf in loss_objectness (batch 1419) - using fallback: 0.0101 (count: 57)
2025-10-05 17:55:38,751 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1419) - using fallback: 0.0126 (count: 57)
2025-10-05 17:55:38,751 - ERROR - Error processing batch 1419: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:40,916 - WARNING - NaN/inf in loss_classifier (batch 1420) - using fallback: 0.0302 (count: 58)
2025-10-05 17:55:40,917 - WARNING - NaN/inf in loss_box_reg (batch 1420) - using fallback: 0.0318 (count: 58)
2025-10-05 17:55:40,917 - WARNING - NaN/inf in loss_objectness (batch 1420) - using fallback: 0.0101 (count: 58)
2025-10-05 17:55:40,918 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1420) - using fallback: 0.0126 (count: 58)
2025-10-05 17:55:40,919 - ERROR - Error processing batch 1420: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:43,174 - WARNING - NaN/inf in loss_classifier (batch 1421) - using fallback: 0.0302 (count: 59)
2025-10-05 17:55:43,175 - WARNING - NaN/inf in loss_box_reg (batch 1421) - using fallback: 0.0318 (count: 59)
2025-10-05 17:55:43,175 - WARNING - NaN/inf in loss_objectness (batch 1421) - using fallback: 0.0101 (count: 59)
2025-10-05 17:55:43,176 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1421) - using fallback: 0.0126 (count: 59)
2025-10-05 17:55:43,176 - ERROR - Error processing batch 1421: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:45,636 - WARNING - NaN/inf in loss_classifier (batch 1422) - using fallback: 0.0302 (count: 60)
2025-10-05 17:55:45,637 - WARNING - NaN/inf in loss_box_reg (batch 1422) - using fallback: 0.0318 (count: 60)
2025-10-05 17:55:45,637 - WARNING - NaN/inf in loss_objectness (batch 1422) - using fallback: 0.0101 (count: 60)
2025-10-05 17:55:45,638 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1422) - using fallback: 0.0126 (count: 60)
2025-10-05 17:55:45,639 - ERROR - Error processing batch 1422: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:47,757 - WARNING - NaN/inf in loss_classifier (batch 1423) - using fallback: 0.0302 (count: 61)
2025-10-05 17:55:47,757 - WARNING - NaN/inf in loss_box_reg (batch 1423) - using fallback: 0.0318 (count: 61)
2025-10-05 17:55:47,758 - WARNING - NaN/inf in loss_objectness (batch 1423) - using fallback: 0.0101 (count: 61)
2025-10-05 17:55:47,759 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1423) - using fallback: 0.0126 (count: 61)
2025-10-05 17:55:47,760 - ERROR - Error processing batch 1423: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:50,192 - WARNING - NaN/inf in loss_classifier (batch 1424) - using fallback: 0.0302 (count: 62)
2025-10-05 17:55:50,193 - WARNING - NaN/inf in loss_box_reg (batch 1424) - using fallback: 0.0318 (count: 62)
2025-10-05 17:55:50,194 - WARNING - NaN/inf in loss_objectness (batch 1424) - using fallback: 0.0101 (count: 62)
2025-10-05 17:55:50,194 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1424) - using fallback: 0.0126 (count: 62)
2025-10-05 17:55:50,195 - ERROR - Error processing batch 1424: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:52,341 - WARNING - NaN/inf in loss_classifier (batch 1425) - using fallback: 0.0302 (count: 63)
2025-10-05 17:55:52,341 - WARNING - NaN/inf in loss_box_reg (batch 1425) - using fallback: 0.0318 (count: 63)
2025-10-05 17:55:52,342 - WARNING - NaN/inf in loss_objectness (batch 1425) - using fallback: 0.0101 (count: 63)
2025-10-05 17:55:52,343 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1425) - using fallback: 0.0126 (count: 63)
2025-10-05 17:55:52,343 - ERROR - Error processing batch 1425: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:55,070 - WARNING - NaN/inf in loss_classifier (batch 1426) - using fallback: 0.0302 (count: 64)
2025-10-05 17:55:55,071 - WARNING - NaN/inf in loss_box_reg (batch 1426) - using fallback: 0.0318 (count: 64)
2025-10-05 17:55:55,072 - WARNING - NaN/inf in loss_objectness (batch 1426) - using fallback: 0.0101 (count: 64)
2025-10-05 17:55:55,072 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1426) - using fallback: 0.0126 (count: 64)
2025-10-05 17:55:55,073 - ERROR - Error processing batch 1426: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:57,109 - WARNING - NaN/inf in loss_classifier (batch 1427) - using fallback: 0.0302 (count: 65)
2025-10-05 17:55:57,109 - WARNING - NaN/inf in loss_box_reg (batch 1427) - using fallback: 0.0318 (count: 65)
2025-10-05 17:55:57,110 - WARNING - NaN/inf in loss_objectness (batch 1427) - using fallback: 0.0101 (count: 65)
2025-10-05 17:55:57,110 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1427) - using fallback: 0.0126 (count: 65)
2025-10-05 17:55:57,111 - ERROR - Error processing batch 1427: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:55:59,379 - WARNING - NaN/inf in loss_classifier (batch 1428) - using fallback: 0.0302 (count: 66)
2025-10-05 17:55:59,380 - WARNING - NaN/inf in loss_box_reg (batch 1428) - using fallback: 0.0318 (count: 66)
2025-10-05 17:55:59,380 - WARNING - NaN/inf in loss_objectness (batch 1428) - using fallback: 0.0101 (count: 66)
2025-10-05 17:55:59,381 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1428) - using fallback: 0.0126 (count: 66)
2025-10-05 17:55:59,381 - ERROR - Error processing batch 1428: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:01,422 - WARNING - NaN/inf in loss_classifier (batch 1429) - using fallback: 0.0302 (count: 67)
2025-10-05 17:56:01,423 - WARNING - NaN/inf in loss_box_reg (batch 1429) - using fallback: 0.0318 (count: 67)
2025-10-05 17:56:01,424 - WARNING - NaN/inf in loss_objectness (batch 1429) - using fallback: 0.0101 (count: 67)
2025-10-05 17:56:01,424 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1429) - using fallback: 0.0126 (count: 67)
2025-10-05 17:56:01,425 - ERROR - Error processing batch 1429: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:03,699 - WARNING - NaN/inf in loss_classifier (batch 1430) - using fallback: 0.0302 (count: 68)
2025-10-05 17:56:03,700 - WARNING - NaN/inf in loss_box_reg (batch 1430) - using fallback: 0.0318 (count: 68)
2025-10-05 17:56:03,701 - WARNING - NaN/inf in loss_objectness (batch 1430) - using fallback: 0.0101 (count: 68)
2025-10-05 17:56:03,702 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1430) - using fallback: 0.0126 (count: 68)
2025-10-05 17:56:03,702 - ERROR - Error processing batch 1430: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:04,488 - WARNING - NaN/inf in loss_classifier (batch 1431) - using fallback: 0.0302 (count: 69)
2025-10-05 17:56:04,489 - WARNING - NaN/inf in loss_box_reg (batch 1431) - using fallback: 0.0318 (count: 69)
2025-10-05 17:56:04,490 - WARNING - NaN/inf in loss_objectness (batch 1431) - using fallback: 0.0101 (count: 69)
2025-10-05 17:56:04,490 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1431) - using fallback: 0.0126 (count: 69)
2025-10-05 17:56:04,491 - ERROR - Error processing batch 1431: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:05,307 - WARNING - NaN/inf in loss_classifier (batch 1432) - using fallback: 0.0302 (count: 70)
2025-10-05 17:56:05,308 - WARNING - NaN/inf in loss_box_reg (batch 1432) - using fallback: 0.0318 (count: 70)
2025-10-05 17:56:05,308 - WARNING - NaN/inf in loss_objectness (batch 1432) - using fallback: 0.0101 (count: 70)
2025-10-05 17:56:05,309 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1432) - using fallback: 0.0126 (count: 70)
2025-10-05 17:56:05,310 - ERROR - Error processing batch 1432: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:06,204 - WARNING - NaN/inf in loss_classifier (batch 1433) - using fallback: 0.0302 (count: 71)
2025-10-05 17:56:06,205 - WARNING - NaN/inf in loss_box_reg (batch 1433) - using fallback: 0.0318 (count: 71)
2025-10-05 17:56:06,205 - WARNING - NaN/inf in loss_objectness (batch 1433) - using fallback: 0.0101 (count: 71)
2025-10-05 17:56:06,206 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1433) - using fallback: 0.0126 (count: 71)
2025-10-05 17:56:06,207 - ERROR - Error processing batch 1433: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:07,319 - WARNING - NaN/inf in loss_classifier (batch 1434) - using fallback: 0.0302 (count: 72)
2025-10-05 17:56:07,319 - WARNING - NaN/inf in loss_box_reg (batch 1434) - using fallback: 0.0318 (count: 72)
2025-10-05 17:56:07,320 - WARNING - NaN/inf in loss_objectness (batch 1434) - using fallback: 0.0101 (count: 72)
2025-10-05 17:56:07,321 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1434) - using fallback: 0.0126 (count: 72)
2025-10-05 17:56:07,321 - ERROR - Error processing batch 1434: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:08,002 - WARNING - NaN/inf in loss_classifier (batch 1435) - using fallback: 0.0302 (count: 73)
2025-10-05 17:56:08,002 - WARNING - NaN/inf in loss_box_reg (batch 1435) - using fallback: 0.0318 (count: 73)
2025-10-05 17:56:08,003 - WARNING - NaN/inf in loss_objectness (batch 1435) - using fallback: 0.0101 (count: 73)
2025-10-05 17:56:08,003 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1435) - using fallback: 0.0126 (count: 73)
2025-10-05 17:56:08,004 - ERROR - Error processing batch 1435: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:08,594 - WARNING - NaN/inf in loss_classifier (batch 1436) - using fallback: 0.0302 (count: 74)
2025-10-05 17:56:08,595 - WARNING - NaN/inf in loss_box_reg (batch 1436) - using fallback: 0.0318 (count: 74)
2025-10-05 17:56:08,595 - WARNING - NaN/inf in loss_objectness (batch 1436) - using fallback: 0.0101 (count: 74)
2025-10-05 17:56:08,596 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1436) - using fallback: 0.0126 (count: 74)
2025-10-05 17:56:08,597 - ERROR - Error processing batch 1436: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:09,287 - WARNING - NaN/inf in loss_classifier (batch 1437) - using fallback: 0.0302 (count: 75)
2025-10-05 17:56:09,288 - WARNING - NaN/inf in loss_box_reg (batch 1437) - using fallback: 0.0318 (count: 75)
2025-10-05 17:56:09,289 - WARNING - NaN/inf in loss_objectness (batch 1437) - using fallback: 0.0101 (count: 75)
2025-10-05 17:56:09,289 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1437) - using fallback: 0.0126 (count: 75)
2025-10-05 17:56:09,290 - ERROR - Error processing batch 1437: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:10,094 - WARNING - NaN/inf in loss_classifier (batch 1438) - using fallback: 0.0302 (count: 76)
2025-10-05 17:56:10,095 - WARNING - NaN/inf in loss_box_reg (batch 1438) - using fallback: 0.0318 (count: 76)
2025-10-05 17:56:10,096 - WARNING - NaN/inf in loss_objectness (batch 1438) - using fallback: 0.0101 (count: 76)
2025-10-05 17:56:10,096 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1438) - using fallback: 0.0126 (count: 76)
2025-10-05 17:56:10,097 - ERROR - Error processing batch 1438: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:10,770 - WARNING - NaN/inf in loss_classifier (batch 1439) - using fallback: 0.0302 (count: 77)
2025-10-05 17:56:10,770 - WARNING - NaN/inf in loss_box_reg (batch 1439) - using fallback: 0.0318 (count: 77)
2025-10-05 17:56:10,771 - WARNING - NaN/inf in loss_objectness (batch 1439) - using fallback: 0.0101 (count: 77)
2025-10-05 17:56:10,771 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1439) - using fallback: 0.0126 (count: 77)
2025-10-05 17:56:10,772 - ERROR - Error processing batch 1439: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:11,680 - WARNING - NaN/inf in loss_classifier (batch 1440) - using fallback: 0.0302 (count: 78)
2025-10-05 17:56:11,681 - WARNING - NaN/inf in loss_box_reg (batch 1440) - using fallback: 0.0318 (count: 78)
2025-10-05 17:56:11,682 - WARNING - NaN/inf in loss_objectness (batch 1440) - using fallback: 0.0101 (count: 78)
2025-10-05 17:56:11,682 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1440) - using fallback: 0.0126 (count: 78)
2025-10-05 17:56:11,683 - ERROR - Error processing batch 1440: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:12,618 - WARNING - NaN/inf in loss_classifier (batch 1441) - using fallback: 0.0302 (count: 79)
2025-10-05 17:56:12,618 - WARNING - NaN/inf in loss_box_reg (batch 1441) - using fallback: 0.0318 (count: 79)
2025-10-05 17:56:12,619 - WARNING - NaN/inf in loss_objectness (batch 1441) - using fallback: 0.0101 (count: 79)
2025-10-05 17:56:12,619 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1441) - using fallback: 0.0126 (count: 79)
2025-10-05 17:56:12,620 - ERROR - Error processing batch 1441: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:13,211 - WARNING - NaN/inf in loss_classifier (batch 1442) - using fallback: 0.0302 (count: 80)
2025-10-05 17:56:13,212 - WARNING - NaN/inf in loss_box_reg (batch 1442) - using fallback: 0.0318 (count: 80)
2025-10-05 17:56:13,213 - WARNING - NaN/inf in loss_objectness (batch 1442) - using fallback: 0.0101 (count: 80)
2025-10-05 17:56:13,213 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1442) - using fallback: 0.0126 (count: 80)
2025-10-05 17:56:13,214 - ERROR - Error processing batch 1442: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:13,941 - WARNING - NaN/inf in loss_classifier (batch 1443) - using fallback: 0.0302 (count: 81)
2025-10-05 17:56:13,941 - WARNING - NaN/inf in loss_box_reg (batch 1443) - using fallback: 0.0318 (count: 81)
2025-10-05 17:56:13,942 - WARNING - NaN/inf in loss_objectness (batch 1443) - using fallback: 0.0101 (count: 81)
2025-10-05 17:56:13,942 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1443) - using fallback: 0.0126 (count: 81)
2025-10-05 17:56:13,943 - ERROR - Error processing batch 1443: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:14,674 - WARNING - NaN/inf in loss_classifier (batch 1444) - using fallback: 0.0302 (count: 82)
2025-10-05 17:56:14,674 - WARNING - NaN/inf in loss_box_reg (batch 1444) - using fallback: 0.0318 (count: 82)
2025-10-05 17:56:14,675 - WARNING - NaN/inf in loss_objectness (batch 1444) - using fallback: 0.0101 (count: 82)
2025-10-05 17:56:14,676 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1444) - using fallback: 0.0126 (count: 82)
2025-10-05 17:56:14,676 - ERROR - Error processing batch 1444: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:15,549 - WARNING - NaN/inf in loss_classifier (batch 1445) - using fallback: 0.0302 (count: 83)
2025-10-05 17:56:15,549 - WARNING - NaN/inf in loss_box_reg (batch 1445) - using fallback: 0.0318 (count: 83)
2025-10-05 17:56:15,550 - WARNING - NaN/inf in loss_objectness (batch 1445) - using fallback: 0.0101 (count: 83)
2025-10-05 17:56:15,550 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1445) - using fallback: 0.0126 (count: 83)
2025-10-05 17:56:15,551 - ERROR - Error processing batch 1445: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:16,182 - WARNING - NaN/inf in loss_classifier (batch 1446) - using fallback: 0.0302 (count: 84)
2025-10-05 17:56:16,183 - WARNING - NaN/inf in loss_box_reg (batch 1446) - using fallback: 0.0318 (count: 84)
2025-10-05 17:56:16,183 - WARNING - NaN/inf in loss_objectness (batch 1446) - using fallback: 0.0101 (count: 84)
2025-10-05 17:56:16,183 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1446) - using fallback: 0.0126 (count: 84)
2025-10-05 17:56:16,184 - ERROR - Error processing batch 1446: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:16,789 - WARNING - NaN/inf in loss_classifier (batch 1447) - using fallback: 0.0302 (count: 85)
2025-10-05 17:56:16,790 - WARNING - NaN/inf in loss_box_reg (batch 1447) - using fallback: 0.0318 (count: 85)
2025-10-05 17:56:16,791 - WARNING - NaN/inf in loss_objectness (batch 1447) - using fallback: 0.0101 (count: 85)
2025-10-05 17:56:16,791 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1447) - using fallback: 0.0126 (count: 85)
2025-10-05 17:56:16,792 - ERROR - Error processing batch 1447: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:17,499 - WARNING - NaN/inf in loss_classifier (batch 1448) - using fallback: 0.0302 (count: 86)
2025-10-05 17:56:17,500 - WARNING - NaN/inf in loss_box_reg (batch 1448) - using fallback: 0.0318 (count: 86)
2025-10-05 17:56:17,500 - WARNING - NaN/inf in loss_objectness (batch 1448) - using fallback: 0.0101 (count: 86)
2025-10-05 17:56:17,501 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1448) - using fallback: 0.0126 (count: 86)
2025-10-05 17:56:17,502 - ERROR - Error processing batch 1448: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:18,168 - WARNING - NaN/inf in loss_classifier (batch 1449) - using fallback: 0.0302 (count: 87)
2025-10-05 17:56:18,169 - WARNING - NaN/inf in loss_box_reg (batch 1449) - using fallback: 0.0318 (count: 87)
2025-10-05 17:56:18,169 - WARNING - NaN/inf in loss_objectness (batch 1449) - using fallback: 0.0101 (count: 87)
2025-10-05 17:56:18,170 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1449) - using fallback: 0.0126 (count: 87)
2025-10-05 17:56:18,171 - ERROR - Error processing batch 1449: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:18,740 - WARNING - NaN/inf in loss_classifier (batch 1450) - using fallback: 0.0302 (count: 88)
2025-10-05 17:56:18,741 - WARNING - NaN/inf in loss_box_reg (batch 1450) - using fallback: 0.0318 (count: 88)
2025-10-05 17:56:18,741 - WARNING - NaN/inf in loss_objectness (batch 1450) - using fallback: 0.0101 (count: 88)
2025-10-05 17:56:18,742 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1450) - using fallback: 0.0126 (count: 88)
2025-10-05 17:56:18,743 - ERROR - Error processing batch 1450: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:19,386 - WARNING - NaN/inf in loss_classifier (batch 1451) - using fallback: 0.0302 (count: 89)
2025-10-05 17:56:19,387 - WARNING - NaN/inf in loss_box_reg (batch 1451) - using fallback: 0.0318 (count: 89)
2025-10-05 17:56:19,388 - WARNING - NaN/inf in loss_objectness (batch 1451) - using fallback: 0.0101 (count: 89)
2025-10-05 17:56:19,389 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1451) - using fallback: 0.0126 (count: 89)
2025-10-05 17:56:19,389 - ERROR - Error processing batch 1451: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:20,279 - WARNING - NaN/inf in loss_classifier (batch 1452) - using fallback: 0.0302 (count: 90)
2025-10-05 17:56:20,280 - WARNING - NaN/inf in loss_box_reg (batch 1452) - using fallback: 0.0318 (count: 90)
2025-10-05 17:56:20,280 - WARNING - NaN/inf in loss_objectness (batch 1452) - using fallback: 0.0101 (count: 90)
2025-10-05 17:56:20,281 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1452) - using fallback: 0.0126 (count: 90)
2025-10-05 17:56:20,281 - ERROR - Error processing batch 1452: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:21,143 - WARNING - NaN/inf in loss_classifier (batch 1453) - using fallback: 0.0302 (count: 91)
2025-10-05 17:56:21,144 - WARNING - NaN/inf in loss_box_reg (batch 1453) - using fallback: 0.0318 (count: 91)
2025-10-05 17:56:21,145 - WARNING - NaN/inf in loss_objectness (batch 1453) - using fallback: 0.0101 (count: 91)
2025-10-05 17:56:21,145 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1453) - using fallback: 0.0126 (count: 91)
2025-10-05 17:56:21,146 - ERROR - Error processing batch 1453: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:21,910 - WARNING - NaN/inf in loss_classifier (batch 1454) - using fallback: 0.0302 (count: 92)
2025-10-05 17:56:21,910 - WARNING - NaN/inf in loss_box_reg (batch 1454) - using fallback: 0.0318 (count: 92)
2025-10-05 17:56:21,911 - WARNING - NaN/inf in loss_objectness (batch 1454) - using fallback: 0.0101 (count: 92)
2025-10-05 17:56:21,911 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1454) - using fallback: 0.0126 (count: 92)
2025-10-05 17:56:21,912 - ERROR - Error processing batch 1454: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:22,932 - WARNING - NaN/inf in loss_classifier (batch 1455) - using fallback: 0.0302 (count: 93)
2025-10-05 17:56:22,932 - WARNING - NaN/inf in loss_box_reg (batch 1455) - using fallback: 0.0318 (count: 93)
2025-10-05 17:56:22,933 - WARNING - NaN/inf in loss_objectness (batch 1455) - using fallback: 0.0101 (count: 93)
2025-10-05 17:56:22,933 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1455) - using fallback: 0.0126 (count: 93)
2025-10-05 17:56:22,934 - ERROR - Error processing batch 1455: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:23,711 - WARNING - NaN/inf in loss_classifier (batch 1456) - using fallback: 0.0302 (count: 94)
2025-10-05 17:56:23,712 - WARNING - NaN/inf in loss_box_reg (batch 1456) - using fallback: 0.0318 (count: 94)
2025-10-05 17:56:23,712 - WARNING - NaN/inf in loss_objectness (batch 1456) - using fallback: 0.0101 (count: 94)
2025-10-05 17:56:23,713 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1456) - using fallback: 0.0126 (count: 94)
2025-10-05 17:56:23,714 - ERROR - Error processing batch 1456: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:24,760 - WARNING - NaN/inf in loss_classifier (batch 1457) - using fallback: 0.0302 (count: 95)
2025-10-05 17:56:24,761 - WARNING - NaN/inf in loss_box_reg (batch 1457) - using fallback: 0.0318 (count: 95)
2025-10-05 17:56:24,761 - WARNING - NaN/inf in loss_objectness (batch 1457) - using fallback: 0.0101 (count: 95)
2025-10-05 17:56:24,762 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1457) - using fallback: 0.0126 (count: 95)
2025-10-05 17:56:24,762 - ERROR - Error processing batch 1457: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:25,345 - WARNING - NaN/inf in loss_classifier (batch 1458) - using fallback: 0.0302 (count: 96)
2025-10-05 17:56:25,346 - WARNING - NaN/inf in loss_box_reg (batch 1458) - using fallback: 0.0318 (count: 96)
2025-10-05 17:56:25,347 - WARNING - NaN/inf in loss_objectness (batch 1458) - using fallback: 0.0101 (count: 96)
2025-10-05 17:56:25,347 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1458) - using fallback: 0.0126 (count: 96)
2025-10-05 17:56:25,348 - ERROR - Error processing batch 1458: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:26,031 - WARNING - NaN/inf in loss_classifier (batch 1459) - using fallback: 0.0302 (count: 97)
2025-10-05 17:56:26,032 - WARNING - NaN/inf in loss_box_reg (batch 1459) - using fallback: 0.0318 (count: 97)
2025-10-05 17:56:26,033 - WARNING - NaN/inf in loss_objectness (batch 1459) - using fallback: 0.0101 (count: 97)
2025-10-05 17:56:26,034 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1459) - using fallback: 0.0126 (count: 97)
2025-10-05 17:56:26,034 - ERROR - Error processing batch 1459: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:26,768 - WARNING - NaN/inf in loss_classifier (batch 1460) - using fallback: 0.0302 (count: 98)
2025-10-05 17:56:26,769 - WARNING - NaN/inf in loss_box_reg (batch 1460) - using fallback: 0.0318 (count: 98)
2025-10-05 17:56:26,770 - WARNING - NaN/inf in loss_objectness (batch 1460) - using fallback: 0.0101 (count: 98)
2025-10-05 17:56:26,770 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1460) - using fallback: 0.0126 (count: 98)
2025-10-05 17:56:26,771 - ERROR - Error processing batch 1460: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:27,804 - WARNING - NaN/inf in loss_classifier (batch 1461) - using fallback: 0.0302 (count: 99)
2025-10-05 17:56:27,805 - WARNING - NaN/inf in loss_box_reg (batch 1461) - using fallback: 0.0318 (count: 99)
2025-10-05 17:56:27,805 - WARNING - NaN/inf in loss_objectness (batch 1461) - using fallback: 0.0101 (count: 99)
2025-10-05 17:56:27,806 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1461) - using fallback: 0.0126 (count: 99)
2025-10-05 17:56:27,806 - ERROR - Error processing batch 1461: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:28,712 - WARNING - NaN/inf in loss_classifier (batch 1462) - using fallback: 0.0302 (count: 100)
2025-10-05 17:56:28,713 - WARNING - NaN/inf in loss_box_reg (batch 1462) - using fallback: 0.0318 (count: 100)
2025-10-05 17:56:28,715 - WARNING - NaN/inf in loss_objectness (batch 1462) - using fallback: 0.0101 (count: 100)
2025-10-05 17:56:28,716 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1462) - using fallback: 0.0126 (count: 100)
2025-10-05 17:56:28,717 - ERROR - Error processing batch 1462: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:29,985 - WARNING - NaN/inf in loss_classifier (batch 1463) - using fallback: 0.0302 (count: 101)
2025-10-05 17:56:29,986 - WARNING - NaN/inf in loss_box_reg (batch 1463) - using fallback: 0.0318 (count: 101)
2025-10-05 17:56:29,987 - WARNING - NaN/inf in loss_objectness (batch 1463) - using fallback: 0.0101 (count: 101)
2025-10-05 17:56:29,987 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1463) - using fallback: 0.0126 (count: 101)
2025-10-05 17:56:29,988 - ERROR - Error processing batch 1463: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:30,652 - WARNING - NaN/inf in loss_classifier (batch 1464) - using fallback: 0.0302 (count: 102)
2025-10-05 17:56:30,653 - WARNING - NaN/inf in loss_box_reg (batch 1464) - using fallback: 0.0318 (count: 102)
2025-10-05 17:56:30,653 - WARNING - NaN/inf in loss_objectness (batch 1464) - using fallback: 0.0101 (count: 102)
2025-10-05 17:56:30,654 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1464) - using fallback: 0.0126 (count: 102)
2025-10-05 17:56:30,655 - ERROR - Error processing batch 1464: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:31,889 - WARNING - NaN/inf in loss_classifier (batch 1465) - using fallback: 0.0302 (count: 103)
2025-10-05 17:56:31,889 - WARNING - NaN/inf in loss_box_reg (batch 1465) - using fallback: 0.0318 (count: 103)
2025-10-05 17:56:31,890 - WARNING - NaN/inf in loss_objectness (batch 1465) - using fallback: 0.0101 (count: 103)
2025-10-05 17:56:31,890 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1465) - using fallback: 0.0126 (count: 103)
2025-10-05 17:56:31,891 - ERROR - Error processing batch 1465: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:32,605 - WARNING - NaN/inf in loss_classifier (batch 1466) - using fallback: 0.0302 (count: 104)
2025-10-05 17:56:32,606 - WARNING - NaN/inf in loss_box_reg (batch 1466) - using fallback: 0.0318 (count: 104)
2025-10-05 17:56:32,607 - WARNING - NaN/inf in loss_objectness (batch 1466) - using fallback: 0.0101 (count: 104)
2025-10-05 17:56:32,607 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1466) - using fallback: 0.0126 (count: 104)
2025-10-05 17:56:32,608 - ERROR - Error processing batch 1466: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:33,756 - WARNING - NaN/inf in loss_classifier (batch 1467) - using fallback: 0.0302 (count: 105)
2025-10-05 17:56:33,757 - WARNING - NaN/inf in loss_box_reg (batch 1467) - using fallback: 0.0318 (count: 105)
2025-10-05 17:56:33,758 - WARNING - NaN/inf in loss_objectness (batch 1467) - using fallback: 0.0101 (count: 105)
2025-10-05 17:56:33,758 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1467) - using fallback: 0.0126 (count: 105)
2025-10-05 17:56:33,759 - ERROR - Error processing batch 1467: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:34,443 - WARNING - NaN/inf in loss_classifier (batch 1468) - using fallback: 0.0302 (count: 106)
2025-10-05 17:56:34,444 - WARNING - NaN/inf in loss_box_reg (batch 1468) - using fallback: 0.0318 (count: 106)
2025-10-05 17:56:34,444 - WARNING - NaN/inf in loss_objectness (batch 1468) - using fallback: 0.0101 (count: 106)
2025-10-05 17:56:34,445 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1468) - using fallback: 0.0126 (count: 106)
2025-10-05 17:56:34,446 - ERROR - Error processing batch 1468: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:35,214 - WARNING - NaN/inf in loss_classifier (batch 1469) - using fallback: 0.0302 (count: 107)
2025-10-05 17:56:35,215 - WARNING - NaN/inf in loss_box_reg (batch 1469) - using fallback: 0.0318 (count: 107)
2025-10-05 17:56:35,216 - WARNING - NaN/inf in loss_objectness (batch 1469) - using fallback: 0.0101 (count: 107)
2025-10-05 17:56:35,217 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1469) - using fallback: 0.0126 (count: 107)
2025-10-05 17:56:35,217 - ERROR - Error processing batch 1469: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:35,908 - WARNING - NaN/inf in loss_classifier (batch 1470) - using fallback: 0.0302 (count: 108)
2025-10-05 17:56:35,909 - WARNING - NaN/inf in loss_box_reg (batch 1470) - using fallback: 0.0318 (count: 108)
2025-10-05 17:56:35,909 - WARNING - NaN/inf in loss_objectness (batch 1470) - using fallback: 0.0101 (count: 108)
2025-10-05 17:56:35,910 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1470) - using fallback: 0.0126 (count: 108)
2025-10-05 17:56:35,910 - ERROR - Error processing batch 1470: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:36,780 - WARNING - NaN/inf in loss_classifier (batch 1471) - using fallback: 0.0302 (count: 109)
2025-10-05 17:56:36,781 - WARNING - NaN/inf in loss_box_reg (batch 1471) - using fallback: 0.0318 (count: 109)
2025-10-05 17:56:36,781 - WARNING - NaN/inf in loss_objectness (batch 1471) - using fallback: 0.0101 (count: 109)
2025-10-05 17:56:36,782 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1471) - using fallback: 0.0126 (count: 109)
2025-10-05 17:56:36,783 - ERROR - Error processing batch 1471: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:37,660 - WARNING - NaN/inf in loss_classifier (batch 1472) - using fallback: 0.0302 (count: 110)
2025-10-05 17:56:37,661 - WARNING - NaN/inf in loss_box_reg (batch 1472) - using fallback: 0.0318 (count: 110)
2025-10-05 17:56:37,661 - WARNING - NaN/inf in loss_objectness (batch 1472) - using fallback: 0.0101 (count: 110)
2025-10-05 17:56:37,662 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1472) - using fallback: 0.0126 (count: 110)
2025-10-05 17:56:37,662 - ERROR - Error processing batch 1472: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:38,640 - WARNING - NaN/inf in loss_classifier (batch 1473) - using fallback: 0.0302 (count: 111)
2025-10-05 17:56:38,641 - WARNING - NaN/inf in loss_box_reg (batch 1473) - using fallback: 0.0318 (count: 111)
2025-10-05 17:56:38,641 - WARNING - NaN/inf in loss_objectness (batch 1473) - using fallback: 0.0101 (count: 111)
2025-10-05 17:56:38,642 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1473) - using fallback: 0.0126 (count: 111)
2025-10-05 17:56:38,642 - ERROR - Error processing batch 1473: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:39,506 - WARNING - NaN/inf in loss_classifier (batch 1474) - using fallback: 0.0302 (count: 112)
2025-10-05 17:56:39,507 - WARNING - NaN/inf in loss_box_reg (batch 1474) - using fallback: 0.0318 (count: 112)
2025-10-05 17:56:39,507 - WARNING - NaN/inf in loss_objectness (batch 1474) - using fallback: 0.0101 (count: 112)
2025-10-05 17:56:39,508 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1474) - using fallback: 0.0126 (count: 112)
2025-10-05 17:56:39,509 - ERROR - Error processing batch 1474: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:40,320 - WARNING - NaN/inf in loss_classifier (batch 1475) - using fallback: 0.0302 (count: 113)
2025-10-05 17:56:40,321 - WARNING - NaN/inf in loss_box_reg (batch 1475) - using fallback: 0.0318 (count: 113)
2025-10-05 17:56:40,322 - WARNING - NaN/inf in loss_objectness (batch 1475) - using fallback: 0.0101 (count: 113)
2025-10-05 17:56:40,322 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1475) - using fallback: 0.0126 (count: 113)
2025-10-05 17:56:40,323 - ERROR - Error processing batch 1475: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:41,238 - WARNING - NaN/inf in loss_classifier (batch 1476) - using fallback: 0.0302 (count: 114)
2025-10-05 17:56:41,239 - WARNING - NaN/inf in loss_box_reg (batch 1476) - using fallback: 0.0318 (count: 114)
2025-10-05 17:56:41,239 - WARNING - NaN/inf in loss_objectness (batch 1476) - using fallback: 0.0101 (count: 114)
2025-10-05 17:56:41,240 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1476) - using fallback: 0.0126 (count: 114)
2025-10-05 17:56:41,240 - ERROR - Error processing batch 1476: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:42,138 - WARNING - NaN/inf in loss_classifier (batch 1477) - using fallback: 0.0302 (count: 115)
2025-10-05 17:56:42,138 - WARNING - NaN/inf in loss_box_reg (batch 1477) - using fallback: 0.0318 (count: 115)
2025-10-05 17:56:42,139 - WARNING - NaN/inf in loss_objectness (batch 1477) - using fallback: 0.0101 (count: 115)
2025-10-05 17:56:42,139 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1477) - using fallback: 0.0126 (count: 115)
2025-10-05 17:56:42,140 - ERROR - Error processing batch 1477: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:43,048 - WARNING - NaN/inf in loss_classifier (batch 1478) - using fallback: 0.0302 (count: 116)
2025-10-05 17:56:43,049 - WARNING - NaN/inf in loss_box_reg (batch 1478) - using fallback: 0.0318 (count: 116)
2025-10-05 17:56:43,049 - WARNING - NaN/inf in loss_objectness (batch 1478) - using fallback: 0.0101 (count: 116)
2025-10-05 17:56:43,050 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1478) - using fallback: 0.0126 (count: 116)
2025-10-05 17:56:43,050 - ERROR - Error processing batch 1478: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:43,965 - WARNING - NaN/inf in loss_classifier (batch 1479) - using fallback: 0.0302 (count: 117)
2025-10-05 17:56:43,966 - WARNING - NaN/inf in loss_box_reg (batch 1479) - using fallback: 0.0318 (count: 117)
2025-10-05 17:56:43,967 - WARNING - NaN/inf in loss_objectness (batch 1479) - using fallback: 0.0101 (count: 117)
2025-10-05 17:56:43,967 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1479) - using fallback: 0.0126 (count: 117)
2025-10-05 17:56:43,968 - ERROR - Error processing batch 1479: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:44,931 - WARNING - NaN/inf in loss_classifier (batch 1480) - using fallback: 0.0302 (count: 118)
2025-10-05 17:56:44,932 - WARNING - NaN/inf in loss_box_reg (batch 1480) - using fallback: 0.0318 (count: 118)
2025-10-05 17:56:44,933 - WARNING - NaN/inf in loss_objectness (batch 1480) - using fallback: 0.0101 (count: 118)
2025-10-05 17:56:44,933 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1480) - using fallback: 0.0126 (count: 118)
2025-10-05 17:56:44,934 - ERROR - Error processing batch 1480: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:45,706 - WARNING - NaN/inf in loss_classifier (batch 1481) - using fallback: 0.0302 (count: 119)
2025-10-05 17:56:45,707 - WARNING - NaN/inf in loss_box_reg (batch 1481) - using fallback: 0.0318 (count: 119)
2025-10-05 17:56:45,708 - WARNING - NaN/inf in loss_objectness (batch 1481) - using fallback: 0.0101 (count: 119)
2025-10-05 17:56:45,708 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1481) - using fallback: 0.0126 (count: 119)
2025-10-05 17:56:45,709 - ERROR - Error processing batch 1481: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:46,656 - WARNING - NaN/inf in loss_classifier (batch 1482) - using fallback: 0.0302 (count: 120)
2025-10-05 17:56:46,657 - WARNING - NaN/inf in loss_box_reg (batch 1482) - using fallback: 0.0318 (count: 120)
2025-10-05 17:56:46,657 - WARNING - NaN/inf in loss_objectness (batch 1482) - using fallback: 0.0101 (count: 120)
2025-10-05 17:56:46,658 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1482) - using fallback: 0.0126 (count: 120)
2025-10-05 17:56:46,659 - ERROR - Error processing batch 1482: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:47,575 - WARNING - NaN/inf in loss_classifier (batch 1483) - using fallback: 0.0302 (count: 121)
2025-10-05 17:56:47,576 - WARNING - NaN/inf in loss_box_reg (batch 1483) - using fallback: 0.0318 (count: 121)
2025-10-05 17:56:47,576 - WARNING - NaN/inf in loss_objectness (batch 1483) - using fallback: 0.0101 (count: 121)
2025-10-05 17:56:47,577 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1483) - using fallback: 0.0126 (count: 121)
2025-10-05 17:56:47,578 - ERROR - Error processing batch 1483: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:48,448 - WARNING - NaN/inf in loss_classifier (batch 1484) - using fallback: 0.0302 (count: 122)
2025-10-05 17:56:48,449 - WARNING - NaN/inf in loss_box_reg (batch 1484) - using fallback: 0.0318 (count: 122)
2025-10-05 17:56:48,450 - WARNING - NaN/inf in loss_objectness (batch 1484) - using fallback: 0.0101 (count: 122)
2025-10-05 17:56:48,450 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1484) - using fallback: 0.0126 (count: 122)
2025-10-05 17:56:48,451 - ERROR - Error processing batch 1484: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:49,093 - WARNING - NaN/inf in loss_classifier (batch 1485) - using fallback: 0.0302 (count: 123)
2025-10-05 17:56:49,094 - WARNING - NaN/inf in loss_box_reg (batch 1485) - using fallback: 0.0318 (count: 123)
2025-10-05 17:56:49,094 - WARNING - NaN/inf in loss_objectness (batch 1485) - using fallback: 0.0101 (count: 123)
2025-10-05 17:56:49,095 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1485) - using fallback: 0.0126 (count: 123)
2025-10-05 17:56:49,096 - ERROR - Error processing batch 1485: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:49,836 - WARNING - NaN/inf in loss_classifier (batch 1486) - using fallback: 0.0302 (count: 124)
2025-10-05 17:56:49,837 - WARNING - NaN/inf in loss_box_reg (batch 1486) - using fallback: 0.0318 (count: 124)
2025-10-05 17:56:49,838 - WARNING - NaN/inf in loss_objectness (batch 1486) - using fallback: 0.0101 (count: 124)
2025-10-05 17:56:49,839 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1486) - using fallback: 0.0126 (count: 124)
2025-10-05 17:56:49,840 - ERROR - Error processing batch 1486: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:50,579 - WARNING - NaN/inf in loss_classifier (batch 1487) - using fallback: 0.0302 (count: 125)
2025-10-05 17:56:50,580 - WARNING - NaN/inf in loss_box_reg (batch 1487) - using fallback: 0.0318 (count: 125)
2025-10-05 17:56:50,580 - WARNING - NaN/inf in loss_objectness (batch 1487) - using fallback: 0.0101 (count: 125)
2025-10-05 17:56:50,580 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1487) - using fallback: 0.0126 (count: 125)
2025-10-05 17:56:50,581 - ERROR - Error processing batch 1487: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:51,734 - WARNING - NaN/inf in loss_classifier (batch 1488) - using fallback: 0.0302 (count: 126)
2025-10-05 17:56:51,735 - WARNING - NaN/inf in loss_box_reg (batch 1488) - using fallback: 0.0318 (count: 126)
2025-10-05 17:56:51,735 - WARNING - NaN/inf in loss_objectness (batch 1488) - using fallback: 0.0101 (count: 126)
2025-10-05 17:56:51,736 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1488) - using fallback: 0.0126 (count: 126)
2025-10-05 17:56:51,736 - ERROR - Error processing batch 1488: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:52,548 - WARNING - NaN/inf in loss_classifier (batch 1489) - using fallback: 0.0302 (count: 127)
2025-10-05 17:56:52,549 - WARNING - NaN/inf in loss_box_reg (batch 1489) - using fallback: 0.0318 (count: 127)
2025-10-05 17:56:52,549 - WARNING - NaN/inf in loss_objectness (batch 1489) - using fallback: 0.0101 (count: 127)
2025-10-05 17:56:52,550 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1489) - using fallback: 0.0126 (count: 127)
2025-10-05 17:56:52,550 - ERROR - Error processing batch 1489: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:53,770 - WARNING - NaN/inf in loss_classifier (batch 1490) - using fallback: 0.0302 (count: 128)
2025-10-05 17:56:53,770 - WARNING - NaN/inf in loss_box_reg (batch 1490) - using fallback: 0.0318 (count: 128)
2025-10-05 17:56:53,771 - WARNING - NaN/inf in loss_objectness (batch 1490) - using fallback: 0.0101 (count: 128)
2025-10-05 17:56:53,771 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1490) - using fallback: 0.0126 (count: 128)
2025-10-05 17:56:53,772 - ERROR - Error processing batch 1490: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:54,635 - WARNING - NaN/inf in loss_classifier (batch 1491) - using fallback: 0.0302 (count: 129)
2025-10-05 17:56:54,636 - WARNING - NaN/inf in loss_box_reg (batch 1491) - using fallback: 0.0318 (count: 129)
2025-10-05 17:56:54,637 - WARNING - NaN/inf in loss_objectness (batch 1491) - using fallback: 0.0101 (count: 129)
2025-10-05 17:56:54,637 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1491) - using fallback: 0.0126 (count: 129)
2025-10-05 17:56:54,638 - ERROR - Error processing batch 1491: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:55,683 - WARNING - NaN/inf in loss_classifier (batch 1492) - using fallback: 0.0302 (count: 130)
2025-10-05 17:56:55,684 - WARNING - NaN/inf in loss_box_reg (batch 1492) - using fallback: 0.0318 (count: 130)
2025-10-05 17:56:55,684 - WARNING - NaN/inf in loss_objectness (batch 1492) - using fallback: 0.0101 (count: 130)
2025-10-05 17:56:55,685 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1492) - using fallback: 0.0126 (count: 130)
2025-10-05 17:56:55,685 - ERROR - Error processing batch 1492: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:56,461 - WARNING - NaN/inf in loss_classifier (batch 1493) - using fallback: 0.0302 (count: 131)
2025-10-05 17:56:56,461 - WARNING - NaN/inf in loss_box_reg (batch 1493) - using fallback: 0.0318 (count: 131)
2025-10-05 17:56:56,462 - WARNING - NaN/inf in loss_objectness (batch 1493) - using fallback: 0.0101 (count: 131)
2025-10-05 17:56:56,462 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1493) - using fallback: 0.0126 (count: 131)
2025-10-05 17:56:56,463 - ERROR - Error processing batch 1493: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:57,387 - WARNING - NaN/inf in loss_classifier (batch 1494) - using fallback: 0.0302 (count: 132)
2025-10-05 17:56:57,387 - WARNING - NaN/inf in loss_box_reg (batch 1494) - using fallback: 0.0318 (count: 132)
2025-10-05 17:56:57,388 - WARNING - NaN/inf in loss_objectness (batch 1494) - using fallback: 0.0101 (count: 132)
2025-10-05 17:56:57,388 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1494) - using fallback: 0.0126 (count: 132)
2025-10-05 17:56:57,389 - ERROR - Error processing batch 1494: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:58,248 - WARNING - NaN/inf in loss_classifier (batch 1495) - using fallback: 0.0302 (count: 133)
2025-10-05 17:56:58,249 - WARNING - NaN/inf in loss_box_reg (batch 1495) - using fallback: 0.0318 (count: 133)
2025-10-05 17:56:58,249 - WARNING - NaN/inf in loss_objectness (batch 1495) - using fallback: 0.0101 (count: 133)
2025-10-05 17:56:58,250 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1495) - using fallback: 0.0126 (count: 133)
2025-10-05 17:56:58,251 - ERROR - Error processing batch 1495: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:56:59,323 - WARNING - NaN/inf in loss_classifier (batch 1496) - using fallback: 0.0302 (count: 134)
2025-10-05 17:56:59,324 - WARNING - NaN/inf in loss_box_reg (batch 1496) - using fallback: 0.0318 (count: 134)
2025-10-05 17:56:59,325 - WARNING - NaN/inf in loss_objectness (batch 1496) - using fallback: 0.0101 (count: 134)
2025-10-05 17:56:59,325 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1496) - using fallback: 0.0126 (count: 134)
2025-10-05 17:56:59,326 - ERROR - Error processing batch 1496: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:00,192 - WARNING - NaN/inf in loss_classifier (batch 1497) - using fallback: 0.0302 (count: 135)
2025-10-05 17:57:00,193 - WARNING - NaN/inf in loss_box_reg (batch 1497) - using fallback: 0.0318 (count: 135)
2025-10-05 17:57:00,194 - WARNING - NaN/inf in loss_objectness (batch 1497) - using fallback: 0.0101 (count: 135)
2025-10-05 17:57:00,194 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1497) - using fallback: 0.0126 (count: 135)
2025-10-05 17:57:00,195 - ERROR - Error processing batch 1497: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:01,238 - WARNING - NaN/inf in loss_classifier (batch 1498) - using fallback: 0.0302 (count: 136)
2025-10-05 17:57:01,239 - WARNING - NaN/inf in loss_box_reg (batch 1498) - using fallback: 0.0318 (count: 136)
2025-10-05 17:57:01,239 - WARNING - NaN/inf in loss_objectness (batch 1498) - using fallback: 0.0101 (count: 136)
2025-10-05 17:57:01,240 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1498) - using fallback: 0.0126 (count: 136)
2025-10-05 17:57:01,241 - ERROR - Error processing batch 1498: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:02,153 - WARNING - NaN/inf in loss_classifier (batch 1499) - using fallback: 0.0302 (count: 137)
2025-10-05 17:57:02,154 - WARNING - NaN/inf in loss_box_reg (batch 1499) - using fallback: 0.0318 (count: 137)
2025-10-05 17:57:02,155 - WARNING - NaN/inf in loss_objectness (batch 1499) - using fallback: 0.0101 (count: 137)
2025-10-05 17:57:02,155 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1499) - using fallback: 0.0126 (count: 137)
2025-10-05 17:57:02,156 - ERROR - Error processing batch 1499: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:03,186 - WARNING - NaN/inf in loss_classifier (batch 1500) - using fallback: 0.0302 (count: 138)
2025-10-05 17:57:03,187 - WARNING - NaN/inf in loss_box_reg (batch 1500) - using fallback: 0.0318 (count: 138)
2025-10-05 17:57:03,188 - WARNING - NaN/inf in loss_objectness (batch 1500) - using fallback: 0.0101 (count: 138)
2025-10-05 17:57:03,188 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1500) - using fallback: 0.0126 (count: 138)
2025-10-05 17:57:03,189 - ERROR - Error processing batch 1500: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:04,056 - WARNING - NaN/inf in loss_classifier (batch 1501) - using fallback: 0.0302 (count: 139)
2025-10-05 17:57:04,057 - WARNING - NaN/inf in loss_box_reg (batch 1501) - using fallback: 0.0318 (count: 139)
2025-10-05 17:57:04,057 - WARNING - NaN/inf in loss_objectness (batch 1501) - using fallback: 0.0101 (count: 139)
2025-10-05 17:57:04,058 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1501) - using fallback: 0.0126 (count: 139)
2025-10-05 17:57:04,058 - ERROR - Error processing batch 1501: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:04,960 - WARNING - NaN/inf in loss_classifier (batch 1502) - using fallback: 0.0302 (count: 140)
2025-10-05 17:57:04,961 - WARNING - NaN/inf in loss_box_reg (batch 1502) - using fallback: 0.0318 (count: 140)
2025-10-05 17:57:04,961 - WARNING - NaN/inf in loss_objectness (batch 1502) - using fallback: 0.0101 (count: 140)
2025-10-05 17:57:04,962 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1502) - using fallback: 0.0126 (count: 140)
2025-10-05 17:57:04,963 - ERROR - Error processing batch 1502: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:05,778 - WARNING - NaN/inf in loss_classifier (batch 1503) - using fallback: 0.0302 (count: 141)
2025-10-05 17:57:05,779 - WARNING - NaN/inf in loss_box_reg (batch 1503) - using fallback: 0.0318 (count: 141)
2025-10-05 17:57:05,779 - WARNING - NaN/inf in loss_objectness (batch 1503) - using fallback: 0.0101 (count: 141)
2025-10-05 17:57:05,780 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1503) - using fallback: 0.0126 (count: 141)
2025-10-05 17:57:05,781 - ERROR - Error processing batch 1503: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:06,823 - WARNING - NaN/inf in loss_classifier (batch 1504) - using fallback: 0.0302 (count: 142)
2025-10-05 17:57:06,824 - WARNING - NaN/inf in loss_box_reg (batch 1504) - using fallback: 0.0318 (count: 142)
2025-10-05 17:57:06,824 - WARNING - NaN/inf in loss_objectness (batch 1504) - using fallback: 0.0101 (count: 142)
2025-10-05 17:57:06,825 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1504) - using fallback: 0.0126 (count: 142)
2025-10-05 17:57:06,826 - ERROR - Error processing batch 1504: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:07,655 - WARNING - NaN/inf in loss_classifier (batch 1505) - using fallback: 0.0302 (count: 143)
2025-10-05 17:57:07,656 - WARNING - NaN/inf in loss_box_reg (batch 1505) - using fallback: 0.0318 (count: 143)
2025-10-05 17:57:07,657 - WARNING - NaN/inf in loss_objectness (batch 1505) - using fallback: 0.0101 (count: 143)
2025-10-05 17:57:07,657 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1505) - using fallback: 0.0126 (count: 143)
2025-10-05 17:57:07,658 - ERROR - Error processing batch 1505: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:08,417 - WARNING - NaN/inf in loss_classifier (batch 1506) - using fallback: 0.0302 (count: 144)
2025-10-05 17:57:08,418 - WARNING - NaN/inf in loss_box_reg (batch 1506) - using fallback: 0.0318 (count: 144)
2025-10-05 17:57:08,419 - WARNING - NaN/inf in loss_objectness (batch 1506) - using fallback: 0.0101 (count: 144)
2025-10-05 17:57:08,419 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1506) - using fallback: 0.0126 (count: 144)
2025-10-05 17:57:08,420 - ERROR - Error processing batch 1506: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:09,316 - WARNING - NaN/inf in loss_classifier (batch 1507) - using fallback: 0.0302 (count: 145)
2025-10-05 17:57:09,317 - WARNING - NaN/inf in loss_box_reg (batch 1507) - using fallback: 0.0318 (count: 145)
2025-10-05 17:57:09,318 - WARNING - NaN/inf in loss_objectness (batch 1507) - using fallback: 0.0101 (count: 145)
2025-10-05 17:57:09,318 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1507) - using fallback: 0.0126 (count: 145)
2025-10-05 17:57:09,319 - ERROR - Error processing batch 1507: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:10,211 - WARNING - NaN/inf in loss_classifier (batch 1508) - using fallback: 0.0302 (count: 146)
2025-10-05 17:57:10,211 - WARNING - NaN/inf in loss_box_reg (batch 1508) - using fallback: 0.0318 (count: 146)
2025-10-05 17:57:10,212 - WARNING - NaN/inf in loss_objectness (batch 1508) - using fallback: 0.0101 (count: 146)
2025-10-05 17:57:10,212 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1508) - using fallback: 0.0126 (count: 146)
2025-10-05 17:57:10,213 - ERROR - Error processing batch 1508: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:10,821 - WARNING - NaN/inf in loss_classifier (batch 1509) - using fallback: 0.0302 (count: 147)
2025-10-05 17:57:10,822 - WARNING - NaN/inf in loss_box_reg (batch 1509) - using fallback: 0.0318 (count: 147)
2025-10-05 17:57:10,822 - WARNING - NaN/inf in loss_objectness (batch 1509) - using fallback: 0.0101 (count: 147)
2025-10-05 17:57:10,822 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1509) - using fallback: 0.0126 (count: 147)
2025-10-05 17:57:10,823 - ERROR - Error processing batch 1509: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:11,565 - WARNING - NaN/inf in loss_classifier (batch 1510) - using fallback: 0.0302 (count: 148)
2025-10-05 17:57:11,566 - WARNING - NaN/inf in loss_box_reg (batch 1510) - using fallback: 0.0318 (count: 148)
2025-10-05 17:57:11,567 - WARNING - NaN/inf in loss_objectness (batch 1510) - using fallback: 0.0101 (count: 148)
2025-10-05 17:57:11,567 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1510) - using fallback: 0.0126 (count: 148)
2025-10-05 17:57:11,568 - ERROR - Error processing batch 1510: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:12,195 - WARNING - NaN/inf in loss_classifier (batch 1511) - using fallback: 0.0302 (count: 149)
2025-10-05 17:57:12,195 - WARNING - NaN/inf in loss_box_reg (batch 1511) - using fallback: 0.0318 (count: 149)
2025-10-05 17:57:12,196 - WARNING - NaN/inf in loss_objectness (batch 1511) - using fallback: 0.0101 (count: 149)
2025-10-05 17:57:12,196 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1511) - using fallback: 0.0126 (count: 149)
2025-10-05 17:57:12,197 - ERROR - Error processing batch 1511: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:12,909 - WARNING - NaN/inf in loss_classifier (batch 1512) - using fallback: 0.0302 (count: 150)
2025-10-05 17:57:12,910 - WARNING - NaN/inf in loss_box_reg (batch 1512) - using fallback: 0.0318 (count: 150)
2025-10-05 17:57:12,910 - WARNING - NaN/inf in loss_objectness (batch 1512) - using fallback: 0.0101 (count: 150)
2025-10-05 17:57:12,911 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1512) - using fallback: 0.0126 (count: 150)
2025-10-05 17:57:12,912 - ERROR - Error processing batch 1512: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:13,561 - WARNING - NaN/inf in loss_classifier (batch 1513) - using fallback: 0.0302 (count: 151)
2025-10-05 17:57:13,562 - WARNING - NaN/inf in loss_box_reg (batch 1513) - using fallback: 0.0318 (count: 151)
2025-10-05 17:57:13,562 - WARNING - NaN/inf in loss_objectness (batch 1513) - using fallback: 0.0101 (count: 151)
2025-10-05 17:57:13,563 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1513) - using fallback: 0.0126 (count: 151)
2025-10-05 17:57:13,563 - ERROR - Error processing batch 1513: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:14,281 - WARNING - NaN/inf in loss_classifier (batch 1514) - using fallback: 0.0302 (count: 152)
2025-10-05 17:57:14,282 - WARNING - NaN/inf in loss_box_reg (batch 1514) - using fallback: 0.0318 (count: 152)
2025-10-05 17:57:14,282 - WARNING - NaN/inf in loss_objectness (batch 1514) - using fallback: 0.0101 (count: 152)
2025-10-05 17:57:14,283 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1514) - using fallback: 0.0126 (count: 152)
2025-10-05 17:57:14,284 - ERROR - Error processing batch 1514: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:14,940 - WARNING - NaN/inf in loss_classifier (batch 1515) - using fallback: 0.0302 (count: 153)
2025-10-05 17:57:14,941 - WARNING - NaN/inf in loss_box_reg (batch 1515) - using fallback: 0.0318 (count: 153)
2025-10-05 17:57:14,942 - WARNING - NaN/inf in loss_objectness (batch 1515) - using fallback: 0.0101 (count: 153)
2025-10-05 17:57:14,942 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1515) - using fallback: 0.0126 (count: 153)
2025-10-05 17:57:14,943 - ERROR - Error processing batch 1515: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:16,166 - WARNING - NaN/inf in loss_classifier (batch 1516) - using fallback: 0.0302 (count: 154)
2025-10-05 17:57:16,167 - WARNING - NaN/inf in loss_box_reg (batch 1516) - using fallback: 0.0318 (count: 154)
2025-10-05 17:57:16,168 - WARNING - NaN/inf in loss_objectness (batch 1516) - using fallback: 0.0101 (count: 154)
2025-10-05 17:57:16,168 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1516) - using fallback: 0.0126 (count: 154)
2025-10-05 17:57:16,169 - ERROR - Error processing batch 1516: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:17,057 - WARNING - NaN/inf in loss_classifier (batch 1517) - using fallback: 0.0302 (count: 155)
2025-10-05 17:57:17,058 - WARNING - NaN/inf in loss_box_reg (batch 1517) - using fallback: 0.0318 (count: 155)
2025-10-05 17:57:17,058 - WARNING - NaN/inf in loss_objectness (batch 1517) - using fallback: 0.0101 (count: 155)
2025-10-05 17:57:17,059 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1517) - using fallback: 0.0126 (count: 155)
2025-10-05 17:57:17,060 - ERROR - Error processing batch 1517: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:17,920 - WARNING - NaN/inf in loss_classifier (batch 1518) - using fallback: 0.0302 (count: 156)
2025-10-05 17:57:17,921 - WARNING - NaN/inf in loss_box_reg (batch 1518) - using fallback: 0.0318 (count: 156)
2025-10-05 17:57:17,921 - WARNING - NaN/inf in loss_objectness (batch 1518) - using fallback: 0.0101 (count: 156)
2025-10-05 17:57:17,922 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1518) - using fallback: 0.0126 (count: 156)
2025-10-05 17:57:17,923 - ERROR - Error processing batch 1518: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:18,677 - WARNING - NaN/inf in loss_classifier (batch 1519) - using fallback: 0.0302 (count: 157)
2025-10-05 17:57:18,678 - WARNING - NaN/inf in loss_box_reg (batch 1519) - using fallback: 0.0318 (count: 157)
2025-10-05 17:57:18,679 - WARNING - NaN/inf in loss_objectness (batch 1519) - using fallback: 0.0101 (count: 157)
2025-10-05 17:57:18,680 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1519) - using fallback: 0.0126 (count: 157)
2025-10-05 17:57:18,680 - ERROR - Error processing batch 1519: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:19,652 - WARNING - NaN/inf in loss_classifier (batch 1520) - using fallback: 0.0302 (count: 158)
2025-10-05 17:57:19,653 - WARNING - NaN/inf in loss_box_reg (batch 1520) - using fallback: 0.0318 (count: 158)
2025-10-05 17:57:19,653 - WARNING - NaN/inf in loss_objectness (batch 1520) - using fallback: 0.0101 (count: 158)
2025-10-05 17:57:19,654 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1520) - using fallback: 0.0126 (count: 158)
2025-10-05 17:57:19,655 - ERROR - Error processing batch 1520: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:20,335 - WARNING - NaN/inf in loss_classifier (batch 1521) - using fallback: 0.0302 (count: 159)
2025-10-05 17:57:20,336 - WARNING - NaN/inf in loss_box_reg (batch 1521) - using fallback: 0.0318 (count: 159)
2025-10-05 17:57:20,337 - WARNING - NaN/inf in loss_objectness (batch 1521) - using fallback: 0.0101 (count: 159)
2025-10-05 17:57:20,337 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1521) - using fallback: 0.0126 (count: 159)
2025-10-05 17:57:20,338 - ERROR - Error processing batch 1521: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:21,500 - WARNING - NaN/inf in loss_classifier (batch 1522) - using fallback: 0.0302 (count: 160)
2025-10-05 17:57:21,500 - WARNING - NaN/inf in loss_box_reg (batch 1522) - using fallback: 0.0318 (count: 160)
2025-10-05 17:57:21,501 - WARNING - NaN/inf in loss_objectness (batch 1522) - using fallback: 0.0101 (count: 160)
2025-10-05 17:57:21,502 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1522) - using fallback: 0.0126 (count: 160)
2025-10-05 17:57:21,502 - ERROR - Error processing batch 1522: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:22,178 - WARNING - NaN/inf in loss_classifier (batch 1523) - using fallback: 0.0302 (count: 161)
2025-10-05 17:57:22,178 - WARNING - NaN/inf in loss_box_reg (batch 1523) - using fallback: 0.0318 (count: 161)
2025-10-05 17:57:22,179 - WARNING - NaN/inf in loss_objectness (batch 1523) - using fallback: 0.0101 (count: 161)
2025-10-05 17:57:22,180 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1523) - using fallback: 0.0126 (count: 161)
2025-10-05 17:57:22,180 - ERROR - Error processing batch 1523: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:23,092 - WARNING - NaN/inf in loss_classifier (batch 1524) - using fallback: 0.0302 (count: 162)
2025-10-05 17:57:23,093 - WARNING - NaN/inf in loss_box_reg (batch 1524) - using fallback: 0.0318 (count: 162)
2025-10-05 17:57:23,094 - WARNING - NaN/inf in loss_objectness (batch 1524) - using fallback: 0.0101 (count: 162)
2025-10-05 17:57:23,094 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1524) - using fallback: 0.0126 (count: 162)
2025-10-05 17:57:23,095 - ERROR - Error processing batch 1524: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:23,726 - WARNING - NaN/inf in loss_classifier (batch 1525) - using fallback: 0.0302 (count: 163)
2025-10-05 17:57:23,727 - WARNING - NaN/inf in loss_box_reg (batch 1525) - using fallback: 0.0318 (count: 163)
2025-10-05 17:57:23,727 - WARNING - NaN/inf in loss_objectness (batch 1525) - using fallback: 0.0101 (count: 163)
2025-10-05 17:57:23,728 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1525) - using fallback: 0.0126 (count: 163)
2025-10-05 17:57:23,729 - ERROR - Error processing batch 1525: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:24,377 - WARNING - NaN/inf in loss_classifier (batch 1526) - using fallback: 0.0302 (count: 164)
2025-10-05 17:57:24,377 - WARNING - NaN/inf in loss_box_reg (batch 1526) - using fallback: 0.0318 (count: 164)
2025-10-05 17:57:24,378 - WARNING - NaN/inf in loss_objectness (batch 1526) - using fallback: 0.0101 (count: 164)
2025-10-05 17:57:24,378 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1526) - using fallback: 0.0126 (count: 164)
2025-10-05 17:57:24,379 - ERROR - Error processing batch 1526: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:24,962 - WARNING - NaN/inf in loss_classifier (batch 1527) - using fallback: 0.0302 (count: 165)
2025-10-05 17:57:24,962 - WARNING - NaN/inf in loss_box_reg (batch 1527) - using fallback: 0.0318 (count: 165)
2025-10-05 17:57:24,963 - WARNING - NaN/inf in loss_objectness (batch 1527) - using fallback: 0.0101 (count: 165)
2025-10-05 17:57:24,963 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1527) - using fallback: 0.0126 (count: 165)
2025-10-05 17:57:24,964 - ERROR - Error processing batch 1527: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:25,834 - WARNING - NaN/inf in loss_classifier (batch 1528) - using fallback: 0.0302 (count: 166)
2025-10-05 17:57:25,835 - WARNING - NaN/inf in loss_box_reg (batch 1528) - using fallback: 0.0318 (count: 166)
2025-10-05 17:57:25,836 - WARNING - NaN/inf in loss_objectness (batch 1528) - using fallback: 0.0101 (count: 166)
2025-10-05 17:57:25,836 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1528) - using fallback: 0.0126 (count: 166)
2025-10-05 17:57:25,837 - ERROR - Error processing batch 1528: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:26,961 - WARNING - NaN/inf in loss_classifier (batch 1529) - using fallback: 0.0302 (count: 167)
2025-10-05 17:57:26,962 - WARNING - NaN/inf in loss_box_reg (batch 1529) - using fallback: 0.0318 (count: 167)
2025-10-05 17:57:26,962 - WARNING - NaN/inf in loss_objectness (batch 1529) - using fallback: 0.0101 (count: 167)
2025-10-05 17:57:26,963 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1529) - using fallback: 0.0126 (count: 167)
2025-10-05 17:57:26,964 - ERROR - Error processing batch 1529: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:28,158 - WARNING - NaN/inf in loss_classifier (batch 1530) - using fallback: 0.0302 (count: 168)
2025-10-05 17:57:28,159 - WARNING - NaN/inf in loss_box_reg (batch 1530) - using fallback: 0.0318 (count: 168)
2025-10-05 17:57:28,160 - WARNING - NaN/inf in loss_objectness (batch 1530) - using fallback: 0.0101 (count: 168)
2025-10-05 17:57:28,160 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1530) - using fallback: 0.0126 (count: 168)
2025-10-05 17:57:28,161 - ERROR - Error processing batch 1530: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:28,951 - WARNING - NaN/inf in loss_classifier (batch 1531) - using fallback: 0.0302 (count: 169)
2025-10-05 17:57:28,952 - WARNING - NaN/inf in loss_box_reg (batch 1531) - using fallback: 0.0318 (count: 169)
2025-10-05 17:57:28,953 - WARNING - NaN/inf in loss_objectness (batch 1531) - using fallback: 0.0101 (count: 169)
2025-10-05 17:57:28,953 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1531) - using fallback: 0.0126 (count: 169)
2025-10-05 17:57:28,954 - ERROR - Error processing batch 1531: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:30,333 - WARNING - NaN/inf in loss_classifier (batch 1532) - using fallback: 0.0302 (count: 170)
2025-10-05 17:57:30,334 - WARNING - NaN/inf in loss_box_reg (batch 1532) - using fallback: 0.0318 (count: 170)
2025-10-05 17:57:30,334 - WARNING - NaN/inf in loss_objectness (batch 1532) - using fallback: 0.0101 (count: 170)
2025-10-05 17:57:30,335 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1532) - using fallback: 0.0126 (count: 170)
2025-10-05 17:57:30,335 - ERROR - Error processing batch 1532: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:31,036 - WARNING - NaN/inf in loss_classifier (batch 1533) - using fallback: 0.0302 (count: 171)
2025-10-05 17:57:31,037 - WARNING - NaN/inf in loss_box_reg (batch 1533) - using fallback: 0.0318 (count: 171)
2025-10-05 17:57:31,038 - WARNING - NaN/inf in loss_objectness (batch 1533) - using fallback: 0.0101 (count: 171)
2025-10-05 17:57:31,038 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1533) - using fallback: 0.0126 (count: 171)
2025-10-05 17:57:31,039 - ERROR - Error processing batch 1533: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:32,141 - WARNING - NaN/inf in loss_classifier (batch 1534) - using fallback: 0.0302 (count: 172)
2025-10-05 17:57:32,141 - WARNING - NaN/inf in loss_box_reg (batch 1534) - using fallback: 0.0318 (count: 172)
2025-10-05 17:57:32,142 - WARNING - NaN/inf in loss_objectness (batch 1534) - using fallback: 0.0101 (count: 172)
2025-10-05 17:57:32,143 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1534) - using fallback: 0.0126 (count: 172)
2025-10-05 17:57:32,143 - ERROR - Error processing batch 1534: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:32,709 - WARNING - NaN/inf in loss_classifier (batch 1535) - using fallback: 0.0302 (count: 173)
2025-10-05 17:57:32,710 - WARNING - NaN/inf in loss_box_reg (batch 1535) - using fallback: 0.0318 (count: 173)
2025-10-05 17:57:32,710 - WARNING - NaN/inf in loss_objectness (batch 1535) - using fallback: 0.0101 (count: 173)
2025-10-05 17:57:32,711 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1535) - using fallback: 0.0126 (count: 173)
2025-10-05 17:57:32,711 - ERROR - Error processing batch 1535: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:33,888 - WARNING - NaN/inf in loss_classifier (batch 1536) - using fallback: 0.0302 (count: 174)
2025-10-05 17:57:33,889 - WARNING - NaN/inf in loss_box_reg (batch 1536) - using fallback: 0.0318 (count: 174)
2025-10-05 17:57:33,889 - WARNING - NaN/inf in loss_objectness (batch 1536) - using fallback: 0.0101 (count: 174)
2025-10-05 17:57:33,890 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1536) - using fallback: 0.0126 (count: 174)
2025-10-05 17:57:33,890 - ERROR - Error processing batch 1536: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:34,594 - WARNING - NaN/inf in loss_classifier (batch 1537) - using fallback: 0.0302 (count: 175)
2025-10-05 17:57:34,595 - WARNING - NaN/inf in loss_box_reg (batch 1537) - using fallback: 0.0318 (count: 175)
2025-10-05 17:57:34,595 - WARNING - NaN/inf in loss_objectness (batch 1537) - using fallback: 0.0101 (count: 175)
2025-10-05 17:57:34,596 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1537) - using fallback: 0.0126 (count: 175)
2025-10-05 17:57:34,597 - ERROR - Error processing batch 1537: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:35,316 - WARNING - NaN/inf in loss_classifier (batch 1538) - using fallback: 0.0302 (count: 176)
2025-10-05 17:57:35,316 - WARNING - NaN/inf in loss_box_reg (batch 1538) - using fallback: 0.0318 (count: 176)
2025-10-05 17:57:35,317 - WARNING - NaN/inf in loss_objectness (batch 1538) - using fallback: 0.0101 (count: 176)
2025-10-05 17:57:35,318 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1538) - using fallback: 0.0126 (count: 176)
2025-10-05 17:57:35,318 - ERROR - Error processing batch 1538: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:36,246 - WARNING - NaN/inf in loss_classifier (batch 1539) - using fallback: 0.0302 (count: 177)
2025-10-05 17:57:36,247 - WARNING - NaN/inf in loss_box_reg (batch 1539) - using fallback: 0.0318 (count: 177)
2025-10-05 17:57:36,248 - WARNING - NaN/inf in loss_objectness (batch 1539) - using fallback: 0.0101 (count: 177)
2025-10-05 17:57:36,248 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1539) - using fallback: 0.0126 (count: 177)
2025-10-05 17:57:36,249 - ERROR - Error processing batch 1539: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:37,331 - WARNING - NaN/inf in loss_classifier (batch 1540) - using fallback: 0.0302 (count: 178)
2025-10-05 17:57:37,332 - WARNING - NaN/inf in loss_box_reg (batch 1540) - using fallback: 0.0318 (count: 178)
2025-10-05 17:57:37,332 - WARNING - NaN/inf in loss_objectness (batch 1540) - using fallback: 0.0101 (count: 178)
2025-10-05 17:57:37,333 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1540) - using fallback: 0.0126 (count: 178)
2025-10-05 17:57:37,334 - ERROR - Error processing batch 1540: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:38,309 - WARNING - NaN/inf in loss_classifier (batch 1541) - using fallback: 0.0302 (count: 179)
2025-10-05 17:57:38,310 - WARNING - NaN/inf in loss_box_reg (batch 1541) - using fallback: 0.0318 (count: 179)
2025-10-05 17:57:38,310 - WARNING - NaN/inf in loss_objectness (batch 1541) - using fallback: 0.0101 (count: 179)
2025-10-05 17:57:38,311 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1541) - using fallback: 0.0126 (count: 179)
2025-10-05 17:57:38,312 - ERROR - Error processing batch 1541: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:39,231 - WARNING - NaN/inf in loss_classifier (batch 1542) - using fallback: 0.0302 (count: 180)
2025-10-05 17:57:39,232 - WARNING - NaN/inf in loss_box_reg (batch 1542) - using fallback: 0.0318 (count: 180)
2025-10-05 17:57:39,232 - WARNING - NaN/inf in loss_objectness (batch 1542) - using fallback: 0.0101 (count: 180)
2025-10-05 17:57:39,233 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1542) - using fallback: 0.0126 (count: 180)
2025-10-05 17:57:39,233 - ERROR - Error processing batch 1542: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:40,301 - WARNING - NaN/inf in loss_classifier (batch 1543) - using fallback: 0.0302 (count: 181)
2025-10-05 17:57:40,302 - WARNING - NaN/inf in loss_box_reg (batch 1543) - using fallback: 0.0318 (count: 181)
2025-10-05 17:57:40,302 - WARNING - NaN/inf in loss_objectness (batch 1543) - using fallback: 0.0101 (count: 181)
2025-10-05 17:57:40,303 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1543) - using fallback: 0.0126 (count: 181)
2025-10-05 17:57:40,303 - ERROR - Error processing batch 1543: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:41,307 - WARNING - NaN/inf in loss_classifier (batch 1544) - using fallback: 0.0302 (count: 182)
2025-10-05 17:57:41,308 - WARNING - NaN/inf in loss_box_reg (batch 1544) - using fallback: 0.0318 (count: 182)
2025-10-05 17:57:41,309 - WARNING - NaN/inf in loss_objectness (batch 1544) - using fallback: 0.0101 (count: 182)
2025-10-05 17:57:41,309 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1544) - using fallback: 0.0126 (count: 182)
2025-10-05 17:57:41,310 - ERROR - Error processing batch 1544: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:42,528 - WARNING - NaN/inf in loss_classifier (batch 1545) - using fallback: 0.0302 (count: 183)
2025-10-05 17:57:42,529 - WARNING - NaN/inf in loss_box_reg (batch 1545) - using fallback: 0.0318 (count: 183)
2025-10-05 17:57:42,530 - WARNING - NaN/inf in loss_objectness (batch 1545) - using fallback: 0.0101 (count: 183)
2025-10-05 17:57:42,530 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1545) - using fallback: 0.0126 (count: 183)
2025-10-05 17:57:42,531 - ERROR - Error processing batch 1545: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:43,494 - WARNING - NaN/inf in loss_classifier (batch 1546) - using fallback: 0.0302 (count: 184)
2025-10-05 17:57:43,494 - WARNING - NaN/inf in loss_box_reg (batch 1546) - using fallback: 0.0318 (count: 184)
2025-10-05 17:57:43,495 - WARNING - NaN/inf in loss_objectness (batch 1546) - using fallback: 0.0101 (count: 184)
2025-10-05 17:57:43,495 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1546) - using fallback: 0.0126 (count: 184)
2025-10-05 17:57:43,497 - ERROR - Error processing batch 1546: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:44,523 - WARNING - NaN/inf in loss_classifier (batch 1547) - using fallback: 0.0302 (count: 185)
2025-10-05 17:57:44,523 - WARNING - NaN/inf in loss_box_reg (batch 1547) - using fallback: 0.0318 (count: 185)
2025-10-05 17:57:44,524 - WARNING - NaN/inf in loss_objectness (batch 1547) - using fallback: 0.0101 (count: 185)
2025-10-05 17:57:44,525 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1547) - using fallback: 0.0126 (count: 185)
2025-10-05 17:57:44,526 - ERROR - Error processing batch 1547: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:45,319 - WARNING - NaN/inf in loss_classifier (batch 1548) - using fallback: 0.0302 (count: 186)
2025-10-05 17:57:45,319 - WARNING - NaN/inf in loss_box_reg (batch 1548) - using fallback: 0.0318 (count: 186)
2025-10-05 17:57:45,320 - WARNING - NaN/inf in loss_objectness (batch 1548) - using fallback: 0.0101 (count: 186)
2025-10-05 17:57:45,320 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1548) - using fallback: 0.0126 (count: 186)
2025-10-05 17:57:45,321 - ERROR - Error processing batch 1548: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:46,192 - WARNING - NaN/inf in loss_classifier (batch 1549) - using fallback: 0.0302 (count: 187)
2025-10-05 17:57:46,193 - WARNING - NaN/inf in loss_box_reg (batch 1549) - using fallback: 0.0318 (count: 187)
2025-10-05 17:57:46,193 - WARNING - NaN/inf in loss_objectness (batch 1549) - using fallback: 0.0101 (count: 187)
2025-10-05 17:57:46,194 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1549) - using fallback: 0.0126 (count: 187)
2025-10-05 17:57:46,194 - ERROR - Error processing batch 1549: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:47,016 - WARNING - NaN/inf in loss_classifier (batch 1550) - using fallback: 0.0302 (count: 188)
2025-10-05 17:57:47,017 - WARNING - NaN/inf in loss_box_reg (batch 1550) - using fallback: 0.0318 (count: 188)
2025-10-05 17:57:47,018 - WARNING - NaN/inf in loss_objectness (batch 1550) - using fallback: 0.0101 (count: 188)
2025-10-05 17:57:47,019 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1550) - using fallback: 0.0126 (count: 188)
2025-10-05 17:57:47,020 - ERROR - Error processing batch 1550: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:47,920 - WARNING - NaN/inf in loss_classifier (batch 1551) - using fallback: 0.0302 (count: 189)
2025-10-05 17:57:47,921 - WARNING - NaN/inf in loss_box_reg (batch 1551) - using fallback: 0.0318 (count: 189)
2025-10-05 17:57:47,921 - WARNING - NaN/inf in loss_objectness (batch 1551) - using fallback: 0.0101 (count: 189)
2025-10-05 17:57:47,922 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1551) - using fallback: 0.0126 (count: 189)
2025-10-05 17:57:47,923 - ERROR - Error processing batch 1551: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:49,111 - WARNING - NaN/inf in loss_classifier (batch 1552) - using fallback: 0.0302 (count: 190)
2025-10-05 17:57:49,111 - WARNING - NaN/inf in loss_box_reg (batch 1552) - using fallback: 0.0318 (count: 190)
2025-10-05 17:57:49,112 - WARNING - NaN/inf in loss_objectness (batch 1552) - using fallback: 0.0101 (count: 190)
2025-10-05 17:57:49,112 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1552) - using fallback: 0.0126 (count: 190)
2025-10-05 17:57:49,113 - ERROR - Error processing batch 1552: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:50,160 - WARNING - NaN/inf in loss_classifier (batch 1553) - using fallback: 0.0302 (count: 191)
2025-10-05 17:57:50,160 - WARNING - NaN/inf in loss_box_reg (batch 1553) - using fallback: 0.0318 (count: 191)
2025-10-05 17:57:50,161 - WARNING - NaN/inf in loss_objectness (batch 1553) - using fallback: 0.0101 (count: 191)
2025-10-05 17:57:50,161 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1553) - using fallback: 0.0126 (count: 191)
2025-10-05 17:57:50,162 - ERROR - Error processing batch 1553: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:51,193 - WARNING - NaN/inf in loss_classifier (batch 1554) - using fallback: 0.0302 (count: 192)
2025-10-05 17:57:51,194 - WARNING - NaN/inf in loss_box_reg (batch 1554) - using fallback: 0.0318 (count: 192)
2025-10-05 17:57:51,195 - WARNING - NaN/inf in loss_objectness (batch 1554) - using fallback: 0.0101 (count: 192)
2025-10-05 17:57:51,195 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1554) - using fallback: 0.0126 (count: 192)
2025-10-05 17:57:51,196 - ERROR - Error processing batch 1554: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:52,411 - WARNING - NaN/inf in loss_classifier (batch 1555) - using fallback: 0.0302 (count: 193)
2025-10-05 17:57:52,411 - WARNING - NaN/inf in loss_box_reg (batch 1555) - using fallback: 0.0318 (count: 193)
2025-10-05 17:57:52,412 - WARNING - NaN/inf in loss_objectness (batch 1555) - using fallback: 0.0101 (count: 193)
2025-10-05 17:57:52,412 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1555) - using fallback: 0.0126 (count: 193)
2025-10-05 17:57:52,413 - ERROR - Error processing batch 1555: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:53,564 - WARNING - NaN/inf in loss_classifier (batch 1556) - using fallback: 0.0302 (count: 194)
2025-10-05 17:57:53,565 - WARNING - NaN/inf in loss_box_reg (batch 1556) - using fallback: 0.0318 (count: 194)
2025-10-05 17:57:53,565 - WARNING - NaN/inf in loss_objectness (batch 1556) - using fallback: 0.0101 (count: 194)
2025-10-05 17:57:53,566 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1556) - using fallback: 0.0126 (count: 194)
2025-10-05 17:57:53,567 - ERROR - Error processing batch 1556: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:54,770 - WARNING - NaN/inf in loss_classifier (batch 1557) - using fallback: 0.0302 (count: 195)
2025-10-05 17:57:54,770 - WARNING - NaN/inf in loss_box_reg (batch 1557) - using fallback: 0.0318 (count: 195)
2025-10-05 17:57:54,771 - WARNING - NaN/inf in loss_objectness (batch 1557) - using fallback: 0.0101 (count: 195)
2025-10-05 17:57:54,771 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1557) - using fallback: 0.0126 (count: 195)
2025-10-05 17:57:54,772 - ERROR - Error processing batch 1557: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:55,646 - WARNING - NaN/inf in loss_classifier (batch 1558) - using fallback: 0.0302 (count: 196)
2025-10-05 17:57:55,647 - WARNING - NaN/inf in loss_box_reg (batch 1558) - using fallback: 0.0318 (count: 196)
2025-10-05 17:57:55,647 - WARNING - NaN/inf in loss_objectness (batch 1558) - using fallback: 0.0101 (count: 196)
2025-10-05 17:57:55,648 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1558) - using fallback: 0.0126 (count: 196)
2025-10-05 17:57:55,649 - ERROR - Error processing batch 1558: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:56,901 - WARNING - NaN/inf in loss_classifier (batch 1559) - using fallback: 0.0302 (count: 197)
2025-10-05 17:57:56,902 - WARNING - NaN/inf in loss_box_reg (batch 1559) - using fallback: 0.0318 (count: 197)
2025-10-05 17:57:56,903 - WARNING - NaN/inf in loss_objectness (batch 1559) - using fallback: 0.0101 (count: 197)
2025-10-05 17:57:56,904 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1559) - using fallback: 0.0126 (count: 197)
2025-10-05 17:57:56,906 - ERROR - Error processing batch 1559: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:58,154 - WARNING - NaN/inf in loss_classifier (batch 1560) - using fallback: 0.0302 (count: 198)
2025-10-05 17:57:58,154 - WARNING - NaN/inf in loss_box_reg (batch 1560) - using fallback: 0.0318 (count: 198)
2025-10-05 17:57:58,155 - WARNING - NaN/inf in loss_objectness (batch 1560) - using fallback: 0.0101 (count: 198)
2025-10-05 17:57:58,155 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1560) - using fallback: 0.0126 (count: 198)
2025-10-05 17:57:58,156 - ERROR - Error processing batch 1560: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:57:59,209 - WARNING - NaN/inf in loss_classifier (batch 1561) - using fallback: 0.0302 (count: 199)
2025-10-05 17:57:59,210 - WARNING - NaN/inf in loss_box_reg (batch 1561) - using fallback: 0.0318 (count: 199)
2025-10-05 17:57:59,210 - WARNING - NaN/inf in loss_objectness (batch 1561) - using fallback: 0.0101 (count: 199)
2025-10-05 17:57:59,211 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1561) - using fallback: 0.0126 (count: 199)
2025-10-05 17:57:59,212 - ERROR - Error processing batch 1561: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:00,184 - WARNING - NaN/inf in loss_classifier (batch 1562) - using fallback: 0.0302 (count: 200)
2025-10-05 17:58:00,184 - WARNING - NaN/inf in loss_box_reg (batch 1562) - using fallback: 0.0318 (count: 200)
2025-10-05 17:58:00,185 - WARNING - NaN/inf in loss_objectness (batch 1562) - using fallback: 0.0101 (count: 200)
2025-10-05 17:58:00,186 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1562) - using fallback: 0.0126 (count: 200)
2025-10-05 17:58:00,186 - ERROR - Error processing batch 1562: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:01,074 - WARNING - NaN/inf in loss_classifier (batch 1563) - using fallback: 0.0302 (count: 201)
2025-10-05 17:58:01,075 - WARNING - NaN/inf in loss_box_reg (batch 1563) - using fallback: 0.0318 (count: 201)
2025-10-05 17:58:01,075 - WARNING - NaN/inf in loss_objectness (batch 1563) - using fallback: 0.0101 (count: 201)
2025-10-05 17:58:01,076 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1563) - using fallback: 0.0126 (count: 201)
2025-10-05 17:58:01,076 - ERROR - Error processing batch 1563: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:02,024 - WARNING - NaN/inf in loss_classifier (batch 1564) - using fallback: 0.0302 (count: 202)
2025-10-05 17:58:02,024 - WARNING - NaN/inf in loss_box_reg (batch 1564) - using fallback: 0.0318 (count: 202)
2025-10-05 17:58:02,025 - WARNING - NaN/inf in loss_objectness (batch 1564) - using fallback: 0.0101 (count: 202)
2025-10-05 17:58:02,026 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1564) - using fallback: 0.0126 (count: 202)
2025-10-05 17:58:02,026 - ERROR - Error processing batch 1564: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:02,932 - WARNING - NaN/inf in loss_classifier (batch 1565) - using fallback: 0.0302 (count: 203)
2025-10-05 17:58:02,932 - WARNING - NaN/inf in loss_box_reg (batch 1565) - using fallback: 0.0318 (count: 203)
2025-10-05 17:58:02,933 - WARNING - NaN/inf in loss_objectness (batch 1565) - using fallback: 0.0101 (count: 203)
2025-10-05 17:58:02,933 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1565) - using fallback: 0.0126 (count: 203)
2025-10-05 17:58:02,934 - ERROR - Error processing batch 1565: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:03,875 - WARNING - NaN/inf in loss_classifier (batch 1566) - using fallback: 0.0302 (count: 204)
2025-10-05 17:58:03,875 - WARNING - NaN/inf in loss_box_reg (batch 1566) - using fallback: 0.0318 (count: 204)
2025-10-05 17:58:03,876 - WARNING - NaN/inf in loss_objectness (batch 1566) - using fallback: 0.0101 (count: 204)
2025-10-05 17:58:03,876 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1566) - using fallback: 0.0126 (count: 204)
2025-10-05 17:58:03,877 - ERROR - Error processing batch 1566: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:04,546 - WARNING - NaN/inf in loss_classifier (batch 1567) - using fallback: 0.0302 (count: 205)
2025-10-05 17:58:04,547 - WARNING - NaN/inf in loss_box_reg (batch 1567) - using fallback: 0.0318 (count: 205)
2025-10-05 17:58:04,547 - WARNING - NaN/inf in loss_objectness (batch 1567) - using fallback: 0.0101 (count: 205)
2025-10-05 17:58:04,548 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1567) - using fallback: 0.0126 (count: 205)
2025-10-05 17:58:04,548 - ERROR - Error processing batch 1567: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:05,405 - WARNING - NaN/inf in loss_classifier (batch 1568) - using fallback: 0.0302 (count: 206)
2025-10-05 17:58:05,406 - WARNING - NaN/inf in loss_box_reg (batch 1568) - using fallback: 0.0318 (count: 206)
2025-10-05 17:58:05,407 - WARNING - NaN/inf in loss_objectness (batch 1568) - using fallback: 0.0101 (count: 206)
2025-10-05 17:58:05,408 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1568) - using fallback: 0.0126 (count: 206)
2025-10-05 17:58:05,408 - ERROR - Error processing batch 1568: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:06,192 - WARNING - NaN/inf in loss_classifier (batch 1569) - using fallback: 0.0302 (count: 207)
2025-10-05 17:58:06,193 - WARNING - NaN/inf in loss_box_reg (batch 1569) - using fallback: 0.0318 (count: 207)
2025-10-05 17:58:06,193 - WARNING - NaN/inf in loss_objectness (batch 1569) - using fallback: 0.0101 (count: 207)
2025-10-05 17:58:06,194 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1569) - using fallback: 0.0126 (count: 207)
2025-10-05 17:58:06,195 - ERROR - Error processing batch 1569: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:06,932 - WARNING - NaN/inf in loss_classifier (batch 1570) - using fallback: 0.0302 (count: 208)
2025-10-05 17:58:06,933 - WARNING - NaN/inf in loss_box_reg (batch 1570) - using fallback: 0.0318 (count: 208)
2025-10-05 17:58:06,934 - WARNING - NaN/inf in loss_objectness (batch 1570) - using fallback: 0.0101 (count: 208)
2025-10-05 17:58:06,935 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1570) - using fallback: 0.0126 (count: 208)
2025-10-05 17:58:06,935 - ERROR - Error processing batch 1570: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:07,570 - WARNING - NaN/inf in loss_classifier (batch 1571) - using fallback: 0.0302 (count: 209)
2025-10-05 17:58:07,570 - WARNING - NaN/inf in loss_box_reg (batch 1571) - using fallback: 0.0318 (count: 209)
2025-10-05 17:58:07,571 - WARNING - NaN/inf in loss_objectness (batch 1571) - using fallback: 0.0101 (count: 209)
2025-10-05 17:58:07,571 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1571) - using fallback: 0.0126 (count: 209)
2025-10-05 17:58:07,572 - ERROR - Error processing batch 1571: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:08,621 - WARNING - NaN/inf in loss_classifier (batch 1572) - using fallback: 0.0302 (count: 210)
2025-10-05 17:58:08,622 - WARNING - NaN/inf in loss_box_reg (batch 1572) - using fallback: 0.0318 (count: 210)
2025-10-05 17:58:08,622 - WARNING - NaN/inf in loss_objectness (batch 1572) - using fallback: 0.0101 (count: 210)
2025-10-05 17:58:08,623 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1572) - using fallback: 0.0126 (count: 210)
2025-10-05 17:58:08,623 - ERROR - Error processing batch 1572: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:09,324 - WARNING - NaN/inf in loss_classifier (batch 1573) - using fallback: 0.0302 (count: 211)
2025-10-05 17:58:09,324 - WARNING - NaN/inf in loss_box_reg (batch 1573) - using fallback: 0.0318 (count: 211)
2025-10-05 17:58:09,325 - WARNING - NaN/inf in loss_objectness (batch 1573) - using fallback: 0.0101 (count: 211)
2025-10-05 17:58:09,325 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1573) - using fallback: 0.0126 (count: 211)
2025-10-05 17:58:09,326 - ERROR - Error processing batch 1573: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:10,325 - WARNING - NaN/inf in loss_classifier (batch 1574) - using fallback: 0.0302 (count: 212)
2025-10-05 17:58:10,325 - WARNING - NaN/inf in loss_box_reg (batch 1574) - using fallback: 0.0318 (count: 212)
2025-10-05 17:58:10,326 - WARNING - NaN/inf in loss_objectness (batch 1574) - using fallback: 0.0101 (count: 212)
2025-10-05 17:58:10,327 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1574) - using fallback: 0.0126 (count: 212)
2025-10-05 17:58:10,328 - ERROR - Error processing batch 1574: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:11,038 - WARNING - NaN/inf in loss_classifier (batch 1575) - using fallback: 0.0302 (count: 213)
2025-10-05 17:58:11,039 - WARNING - NaN/inf in loss_box_reg (batch 1575) - using fallback: 0.0318 (count: 213)
2025-10-05 17:58:11,039 - WARNING - NaN/inf in loss_objectness (batch 1575) - using fallback: 0.0101 (count: 213)
2025-10-05 17:58:11,040 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1575) - using fallback: 0.0126 (count: 213)
2025-10-05 17:58:11,040 - ERROR - Error processing batch 1575: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:11,866 - WARNING - NaN/inf in loss_classifier (batch 1576) - using fallback: 0.0302 (count: 214)
2025-10-05 17:58:11,867 - WARNING - NaN/inf in loss_box_reg (batch 1576) - using fallback: 0.0318 (count: 214)
2025-10-05 17:58:11,867 - WARNING - NaN/inf in loss_objectness (batch 1576) - using fallback: 0.0101 (count: 214)
2025-10-05 17:58:11,868 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1576) - using fallback: 0.0126 (count: 214)
2025-10-05 17:58:11,869 - ERROR - Error processing batch 1576: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:12,486 - WARNING - NaN/inf in loss_classifier (batch 1577) - using fallback: 0.0302 (count: 215)
2025-10-05 17:58:12,486 - WARNING - NaN/inf in loss_box_reg (batch 1577) - using fallback: 0.0318 (count: 215)
2025-10-05 17:58:12,487 - WARNING - NaN/inf in loss_objectness (batch 1577) - using fallback: 0.0101 (count: 215)
2025-10-05 17:58:12,487 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1577) - using fallback: 0.0126 (count: 215)
2025-10-05 17:58:12,488 - ERROR - Error processing batch 1577: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:13,265 - WARNING - NaN/inf in loss_classifier (batch 1578) - using fallback: 0.0302 (count: 216)
2025-10-05 17:58:13,266 - WARNING - NaN/inf in loss_box_reg (batch 1578) - using fallback: 0.0318 (count: 216)
2025-10-05 17:58:13,267 - WARNING - NaN/inf in loss_objectness (batch 1578) - using fallback: 0.0101 (count: 216)
2025-10-05 17:58:13,267 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1578) - using fallback: 0.0126 (count: 216)
2025-10-05 17:58:13,268 - ERROR - Error processing batch 1578: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:14,044 - WARNING - NaN/inf in loss_classifier (batch 1579) - using fallback: 0.0302 (count: 217)
2025-10-05 17:58:14,045 - WARNING - NaN/inf in loss_box_reg (batch 1579) - using fallback: 0.0318 (count: 217)
2025-10-05 17:58:14,046 - WARNING - NaN/inf in loss_objectness (batch 1579) - using fallback: 0.0101 (count: 217)
2025-10-05 17:58:14,046 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1579) - using fallback: 0.0126 (count: 217)
2025-10-05 17:58:14,047 - ERROR - Error processing batch 1579: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:14,869 - WARNING - NaN/inf in loss_classifier (batch 1580) - using fallback: 0.0302 (count: 218)
2025-10-05 17:58:14,870 - WARNING - NaN/inf in loss_box_reg (batch 1580) - using fallback: 0.0318 (count: 218)
2025-10-05 17:58:14,870 - WARNING - NaN/inf in loss_objectness (batch 1580) - using fallback: 0.0101 (count: 218)
2025-10-05 17:58:14,871 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1580) - using fallback: 0.0126 (count: 218)
2025-10-05 17:58:14,872 - ERROR - Error processing batch 1580: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:15,880 - WARNING - NaN/inf in loss_classifier (batch 1581) - using fallback: 0.0302 (count: 219)
2025-10-05 17:58:15,881 - WARNING - NaN/inf in loss_box_reg (batch 1581) - using fallback: 0.0318 (count: 219)
2025-10-05 17:58:15,881 - WARNING - NaN/inf in loss_objectness (batch 1581) - using fallback: 0.0101 (count: 219)
2025-10-05 17:58:15,882 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1581) - using fallback: 0.0126 (count: 219)
2025-10-05 17:58:15,882 - ERROR - Error processing batch 1581: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:16,803 - WARNING - NaN/inf in loss_classifier (batch 1582) - using fallback: 0.0302 (count: 220)
2025-10-05 17:58:16,804 - WARNING - NaN/inf in loss_box_reg (batch 1582) - using fallback: 0.0318 (count: 220)
2025-10-05 17:58:16,804 - WARNING - NaN/inf in loss_objectness (batch 1582) - using fallback: 0.0101 (count: 220)
2025-10-05 17:58:16,805 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1582) - using fallback: 0.0126 (count: 220)
2025-10-05 17:58:16,806 - ERROR - Error processing batch 1582: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:17,702 - WARNING - NaN/inf in loss_classifier (batch 1583) - using fallback: 0.0302 (count: 221)
2025-10-05 17:58:17,703 - WARNING - NaN/inf in loss_box_reg (batch 1583) - using fallback: 0.0318 (count: 221)
2025-10-05 17:58:17,704 - WARNING - NaN/inf in loss_objectness (batch 1583) - using fallback: 0.0101 (count: 221)
2025-10-05 17:58:17,704 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1583) - using fallback: 0.0126 (count: 221)
2025-10-05 17:58:17,705 - ERROR - Error processing batch 1583: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:18,622 - WARNING - NaN/inf in loss_classifier (batch 1584) - using fallback: 0.0302 (count: 222)
2025-10-05 17:58:18,623 - WARNING - NaN/inf in loss_box_reg (batch 1584) - using fallback: 0.0318 (count: 222)
2025-10-05 17:58:18,623 - WARNING - NaN/inf in loss_objectness (batch 1584) - using fallback: 0.0101 (count: 222)
2025-10-05 17:58:18,624 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1584) - using fallback: 0.0126 (count: 222)
2025-10-05 17:58:18,624 - ERROR - Error processing batch 1584: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:19,342 - WARNING - NaN/inf in loss_classifier (batch 1585) - using fallback: 0.0302 (count: 223)
2025-10-05 17:58:19,343 - WARNING - NaN/inf in loss_box_reg (batch 1585) - using fallback: 0.0318 (count: 223)
2025-10-05 17:58:19,344 - WARNING - NaN/inf in loss_objectness (batch 1585) - using fallback: 0.0101 (count: 223)
2025-10-05 17:58:19,344 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1585) - using fallback: 0.0126 (count: 223)
2025-10-05 17:58:19,345 - ERROR - Error processing batch 1585: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:20,650 - WARNING - NaN/inf in loss_classifier (batch 1586) - using fallback: 0.0302 (count: 224)
2025-10-05 17:58:20,651 - WARNING - NaN/inf in loss_box_reg (batch 1586) - using fallback: 0.0318 (count: 224)
2025-10-05 17:58:20,651 - WARNING - NaN/inf in loss_objectness (batch 1586) - using fallback: 0.0101 (count: 224)
2025-10-05 17:58:20,652 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1586) - using fallback: 0.0126 (count: 224)
2025-10-05 17:58:20,653 - ERROR - Error processing batch 1586: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:21,437 - WARNING - NaN/inf in loss_classifier (batch 1587) - using fallback: 0.0302 (count: 225)
2025-10-05 17:58:21,438 - WARNING - NaN/inf in loss_box_reg (batch 1587) - using fallback: 0.0318 (count: 225)
2025-10-05 17:58:21,438 - WARNING - NaN/inf in loss_objectness (batch 1587) - using fallback: 0.0101 (count: 225)
2025-10-05 17:58:21,439 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1587) - using fallback: 0.0126 (count: 225)
2025-10-05 17:58:21,440 - ERROR - Error processing batch 1587: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:22,318 - WARNING - NaN/inf in loss_classifier (batch 1588) - using fallback: 0.0302 (count: 226)
2025-10-05 17:58:22,318 - WARNING - NaN/inf in loss_box_reg (batch 1588) - using fallback: 0.0318 (count: 226)
2025-10-05 17:58:22,319 - WARNING - NaN/inf in loss_objectness (batch 1588) - using fallback: 0.0101 (count: 226)
2025-10-05 17:58:22,319 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1588) - using fallback: 0.0126 (count: 226)
2025-10-05 17:58:22,320 - ERROR - Error processing batch 1588: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:22,974 - WARNING - NaN/inf in loss_classifier (batch 1589) - using fallback: 0.0302 (count: 227)
2025-10-05 17:58:22,974 - WARNING - NaN/inf in loss_box_reg (batch 1589) - using fallback: 0.0318 (count: 227)
2025-10-05 17:58:22,975 - WARNING - NaN/inf in loss_objectness (batch 1589) - using fallback: 0.0101 (count: 227)
2025-10-05 17:58:22,976 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1589) - using fallback: 0.0126 (count: 227)
2025-10-05 17:58:22,976 - ERROR - Error processing batch 1589: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:23,981 - WARNING - NaN/inf in loss_classifier (batch 1590) - using fallback: 0.0302 (count: 228)
2025-10-05 17:58:23,982 - WARNING - NaN/inf in loss_box_reg (batch 1590) - using fallback: 0.0318 (count: 228)
2025-10-05 17:58:23,982 - WARNING - NaN/inf in loss_objectness (batch 1590) - using fallback: 0.0101 (count: 228)
2025-10-05 17:58:23,983 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1590) - using fallback: 0.0126 (count: 228)
2025-10-05 17:58:23,983 - ERROR - Error processing batch 1590: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:24,698 - WARNING - NaN/inf in loss_classifier (batch 1591) - using fallback: 0.0302 (count: 229)
2025-10-05 17:58:24,698 - WARNING - NaN/inf in loss_box_reg (batch 1591) - using fallback: 0.0318 (count: 229)
2025-10-05 17:58:24,699 - WARNING - NaN/inf in loss_objectness (batch 1591) - using fallback: 0.0101 (count: 229)
2025-10-05 17:58:24,700 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1591) - using fallback: 0.0126 (count: 229)
2025-10-05 17:58:24,701 - ERROR - Error processing batch 1591: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:25,491 - WARNING - NaN/inf in loss_classifier (batch 1592) - using fallback: 0.0302 (count: 230)
2025-10-05 17:58:25,492 - WARNING - NaN/inf in loss_box_reg (batch 1592) - using fallback: 0.0318 (count: 230)
2025-10-05 17:58:25,493 - WARNING - NaN/inf in loss_objectness (batch 1592) - using fallback: 0.0101 (count: 230)
2025-10-05 17:58:25,494 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1592) - using fallback: 0.0126 (count: 230)
2025-10-05 17:58:25,494 - ERROR - Error processing batch 1592: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:26,153 - WARNING - NaN/inf in loss_classifier (batch 1593) - using fallback: 0.0302 (count: 231)
2025-10-05 17:58:26,154 - WARNING - NaN/inf in loss_box_reg (batch 1593) - using fallback: 0.0318 (count: 231)
2025-10-05 17:58:26,154 - WARNING - NaN/inf in loss_objectness (batch 1593) - using fallback: 0.0101 (count: 231)
2025-10-05 17:58:26,155 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1593) - using fallback: 0.0126 (count: 231)
2025-10-05 17:58:26,156 - ERROR - Error processing batch 1593: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:27,230 - WARNING - NaN/inf in loss_classifier (batch 1594) - using fallback: 0.0302 (count: 232)
2025-10-05 17:58:27,231 - WARNING - NaN/inf in loss_box_reg (batch 1594) - using fallback: 0.0318 (count: 232)
2025-10-05 17:58:27,231 - WARNING - NaN/inf in loss_objectness (batch 1594) - using fallback: 0.0101 (count: 232)
2025-10-05 17:58:27,232 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1594) - using fallback: 0.0126 (count: 232)
2025-10-05 17:58:27,233 - ERROR - Error processing batch 1594: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:27,910 - WARNING - NaN/inf in loss_classifier (batch 1595) - using fallback: 0.0302 (count: 233)
2025-10-05 17:58:27,911 - WARNING - NaN/inf in loss_box_reg (batch 1595) - using fallback: 0.0318 (count: 233)
2025-10-05 17:58:27,911 - WARNING - NaN/inf in loss_objectness (batch 1595) - using fallback: 0.0101 (count: 233)
2025-10-05 17:58:27,912 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1595) - using fallback: 0.0126 (count: 233)
2025-10-05 17:58:27,913 - ERROR - Error processing batch 1595: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:28,701 - WARNING - NaN/inf in loss_classifier (batch 1596) - using fallback: 0.0302 (count: 234)
2025-10-05 17:58:28,701 - WARNING - NaN/inf in loss_box_reg (batch 1596) - using fallback: 0.0318 (count: 234)
2025-10-05 17:58:28,702 - WARNING - NaN/inf in loss_objectness (batch 1596) - using fallback: 0.0101 (count: 234)
2025-10-05 17:58:28,703 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1596) - using fallback: 0.0126 (count: 234)
2025-10-05 17:58:28,703 - ERROR - Error processing batch 1596: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:29,332 - WARNING - NaN/inf in loss_classifier (batch 1597) - using fallback: 0.0302 (count: 235)
2025-10-05 17:58:29,333 - WARNING - NaN/inf in loss_box_reg (batch 1597) - using fallback: 0.0318 (count: 235)
2025-10-05 17:58:29,334 - WARNING - NaN/inf in loss_objectness (batch 1597) - using fallback: 0.0101 (count: 235)
2025-10-05 17:58:29,334 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1597) - using fallback: 0.0126 (count: 235)
2025-10-05 17:58:29,335 - ERROR - Error processing batch 1597: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:29,890 - WARNING - NaN/inf in loss_classifier (batch 1598) - using fallback: 0.0302 (count: 236)
2025-10-05 17:58:29,891 - WARNING - NaN/inf in loss_box_reg (batch 1598) - using fallback: 0.0318 (count: 236)
2025-10-05 17:58:29,892 - WARNING - NaN/inf in loss_objectness (batch 1598) - using fallback: 0.0101 (count: 236)
2025-10-05 17:58:29,892 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1598) - using fallback: 0.0126 (count: 236)
2025-10-05 17:58:29,893 - ERROR - Error processing batch 1598: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:30,491 - WARNING - NaN/inf in loss_classifier (batch 1599) - using fallback: 0.0302 (count: 237)
2025-10-05 17:58:30,491 - WARNING - NaN/inf in loss_box_reg (batch 1599) - using fallback: 0.0318 (count: 237)
2025-10-05 17:58:30,492 - WARNING - NaN/inf in loss_objectness (batch 1599) - using fallback: 0.0101 (count: 237)
2025-10-05 17:58:30,492 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1599) - using fallback: 0.0126 (count: 237)
2025-10-05 17:58:30,493 - ERROR - Error processing batch 1599: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:31,138 - WARNING - NaN/inf in loss_classifier (batch 1600) - using fallback: 0.0302 (count: 238)
2025-10-05 17:58:31,139 - WARNING - NaN/inf in loss_box_reg (batch 1600) - using fallback: 0.0318 (count: 238)
2025-10-05 17:58:31,140 - WARNING - NaN/inf in loss_objectness (batch 1600) - using fallback: 0.0101 (count: 238)
2025-10-05 17:58:31,141 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1600) - using fallback: 0.0126 (count: 238)
2025-10-05 17:58:31,142 - ERROR - Error processing batch 1600: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:31,791 - WARNING - NaN/inf in loss_classifier (batch 1601) - using fallback: 0.0302 (count: 239)
2025-10-05 17:58:31,792 - WARNING - NaN/inf in loss_box_reg (batch 1601) - using fallback: 0.0318 (count: 239)
2025-10-05 17:58:31,792 - WARNING - NaN/inf in loss_objectness (batch 1601) - using fallback: 0.0101 (count: 239)
2025-10-05 17:58:31,792 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1601) - using fallback: 0.0126 (count: 239)
2025-10-05 17:58:31,793 - ERROR - Error processing batch 1601: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:32,427 - WARNING - NaN/inf in loss_classifier (batch 1602) - using fallback: 0.0302 (count: 240)
2025-10-05 17:58:32,427 - WARNING - NaN/inf in loss_box_reg (batch 1602) - using fallback: 0.0318 (count: 240)
2025-10-05 17:58:32,428 - WARNING - NaN/inf in loss_objectness (batch 1602) - using fallback: 0.0101 (count: 240)
2025-10-05 17:58:32,429 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1602) - using fallback: 0.0126 (count: 240)
2025-10-05 17:58:32,430 - ERROR - Error processing batch 1602: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:33,172 - WARNING - NaN/inf in loss_classifier (batch 1603) - using fallback: 0.0302 (count: 241)
2025-10-05 17:58:33,173 - WARNING - NaN/inf in loss_box_reg (batch 1603) - using fallback: 0.0318 (count: 241)
2025-10-05 17:58:33,174 - WARNING - NaN/inf in loss_objectness (batch 1603) - using fallback: 0.0101 (count: 241)
2025-10-05 17:58:33,175 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1603) - using fallback: 0.0126 (count: 241)
2025-10-05 17:58:33,176 - ERROR - Error processing batch 1603: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:33,801 - WARNING - NaN/inf in loss_classifier (batch 1604) - using fallback: 0.0302 (count: 242)
2025-10-05 17:58:33,802 - WARNING - NaN/inf in loss_box_reg (batch 1604) - using fallback: 0.0318 (count: 242)
2025-10-05 17:58:33,803 - WARNING - NaN/inf in loss_objectness (batch 1604) - using fallback: 0.0101 (count: 242)
2025-10-05 17:58:33,803 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1604) - using fallback: 0.0126 (count: 242)
2025-10-05 17:58:33,804 - ERROR - Error processing batch 1604: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:34,484 - WARNING - NaN/inf in loss_classifier (batch 1605) - using fallback: 0.0302 (count: 243)
2025-10-05 17:58:34,484 - WARNING - NaN/inf in loss_box_reg (batch 1605) - using fallback: 0.0318 (count: 243)
2025-10-05 17:58:34,485 - WARNING - NaN/inf in loss_objectness (batch 1605) - using fallback: 0.0101 (count: 243)
2025-10-05 17:58:34,485 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1605) - using fallback: 0.0126 (count: 243)
2025-10-05 17:58:34,486 - ERROR - Error processing batch 1605: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:35,079 - WARNING - NaN/inf in loss_classifier (batch 1606) - using fallback: 0.0302 (count: 244)
2025-10-05 17:58:35,080 - WARNING - NaN/inf in loss_box_reg (batch 1606) - using fallback: 0.0318 (count: 244)
2025-10-05 17:58:35,080 - WARNING - NaN/inf in loss_objectness (batch 1606) - using fallback: 0.0101 (count: 244)
2025-10-05 17:58:35,081 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1606) - using fallback: 0.0126 (count: 244)
2025-10-05 17:58:35,081 - ERROR - Error processing batch 1606: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:35,763 - WARNING - NaN/inf in loss_classifier (batch 1607) - using fallback: 0.0302 (count: 245)
2025-10-05 17:58:35,764 - WARNING - NaN/inf in loss_box_reg (batch 1607) - using fallback: 0.0318 (count: 245)
2025-10-05 17:58:35,764 - WARNING - NaN/inf in loss_objectness (batch 1607) - using fallback: 0.0101 (count: 245)
2025-10-05 17:58:35,765 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1607) - using fallback: 0.0126 (count: 245)
2025-10-05 17:58:35,765 - ERROR - Error processing batch 1607: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:36,340 - WARNING - NaN/inf in loss_classifier (batch 1608) - using fallback: 0.0302 (count: 246)
2025-10-05 17:58:36,341 - WARNING - NaN/inf in loss_box_reg (batch 1608) - using fallback: 0.0318 (count: 246)
2025-10-05 17:58:36,341 - WARNING - NaN/inf in loss_objectness (batch 1608) - using fallback: 0.0101 (count: 246)
2025-10-05 17:58:36,342 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1608) - using fallback: 0.0126 (count: 246)
2025-10-05 17:58:36,342 - ERROR - Error processing batch 1608: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:36,929 - WARNING - NaN/inf in loss_classifier (batch 1609) - using fallback: 0.0302 (count: 247)
2025-10-05 17:58:36,930 - WARNING - NaN/inf in loss_box_reg (batch 1609) - using fallback: 0.0318 (count: 247)
2025-10-05 17:58:36,930 - WARNING - NaN/inf in loss_objectness (batch 1609) - using fallback: 0.0101 (count: 247)
2025-10-05 17:58:36,931 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1609) - using fallback: 0.0126 (count: 247)
2025-10-05 17:58:36,931 - ERROR - Error processing batch 1609: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:37,548 - WARNING - NaN/inf in loss_classifier (batch 1610) - using fallback: 0.0302 (count: 248)
2025-10-05 17:58:37,549 - WARNING - NaN/inf in loss_box_reg (batch 1610) - using fallback: 0.0318 (count: 248)
2025-10-05 17:58:37,549 - WARNING - NaN/inf in loss_objectness (batch 1610) - using fallback: 0.0101 (count: 248)
2025-10-05 17:58:37,550 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1610) - using fallback: 0.0126 (count: 248)
2025-10-05 17:58:37,551 - ERROR - Error processing batch 1610: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:38,174 - WARNING - NaN/inf in loss_classifier (batch 1611) - using fallback: 0.0302 (count: 249)
2025-10-05 17:58:38,175 - WARNING - NaN/inf in loss_box_reg (batch 1611) - using fallback: 0.0318 (count: 249)
2025-10-05 17:58:38,175 - WARNING - NaN/inf in loss_objectness (batch 1611) - using fallback: 0.0101 (count: 249)
2025-10-05 17:58:38,176 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1611) - using fallback: 0.0126 (count: 249)
2025-10-05 17:58:38,177 - ERROR - Error processing batch 1611: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:38,788 - WARNING - NaN/inf in loss_classifier (batch 1612) - using fallback: 0.0302 (count: 250)
2025-10-05 17:58:38,789 - WARNING - NaN/inf in loss_box_reg (batch 1612) - using fallback: 0.0318 (count: 250)
2025-10-05 17:58:38,789 - WARNING - NaN/inf in loss_objectness (batch 1612) - using fallback: 0.0101 (count: 250)
2025-10-05 17:58:38,790 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1612) - using fallback: 0.0126 (count: 250)
2025-10-05 17:58:38,791 - ERROR - Error processing batch 1612: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:39,622 - WARNING - NaN/inf in loss_classifier (batch 1613) - using fallback: 0.0302 (count: 251)
2025-10-05 17:58:39,623 - WARNING - NaN/inf in loss_box_reg (batch 1613) - using fallback: 0.0318 (count: 251)
2025-10-05 17:58:39,624 - WARNING - NaN/inf in loss_objectness (batch 1613) - using fallback: 0.0101 (count: 251)
2025-10-05 17:58:39,624 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1613) - using fallback: 0.0126 (count: 251)
2025-10-05 17:58:39,625 - ERROR - Error processing batch 1613: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:40,288 - WARNING - NaN/inf in loss_classifier (batch 1614) - using fallback: 0.0302 (count: 252)
2025-10-05 17:58:40,289 - WARNING - NaN/inf in loss_box_reg (batch 1614) - using fallback: 0.0318 (count: 252)
2025-10-05 17:58:40,290 - WARNING - NaN/inf in loss_objectness (batch 1614) - using fallback: 0.0101 (count: 252)
2025-10-05 17:58:40,290 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1614) - using fallback: 0.0126 (count: 252)
2025-10-05 17:58:40,291 - ERROR - Error processing batch 1614: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:41,302 - WARNING - NaN/inf in loss_classifier (batch 1615) - using fallback: 0.0302 (count: 253)
2025-10-05 17:58:41,302 - WARNING - NaN/inf in loss_box_reg (batch 1615) - using fallback: 0.0318 (count: 253)
2025-10-05 17:58:41,303 - WARNING - NaN/inf in loss_objectness (batch 1615) - using fallback: 0.0101 (count: 253)
2025-10-05 17:58:41,303 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1615) - using fallback: 0.0126 (count: 253)
2025-10-05 17:58:41,304 - ERROR - Error processing batch 1615: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:42,218 - WARNING - NaN/inf in loss_classifier (batch 1616) - using fallback: 0.0302 (count: 254)
2025-10-05 17:58:42,219 - WARNING - NaN/inf in loss_box_reg (batch 1616) - using fallback: 0.0318 (count: 254)
2025-10-05 17:58:42,219 - WARNING - NaN/inf in loss_objectness (batch 1616) - using fallback: 0.0101 (count: 254)
2025-10-05 17:58:42,220 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1616) - using fallback: 0.0126 (count: 254)
2025-10-05 17:58:42,221 - ERROR - Error processing batch 1616: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:42,755 - WARNING - NaN/inf in loss_classifier (batch 1617) - using fallback: 0.0302 (count: 255)
2025-10-05 17:58:42,756 - WARNING - NaN/inf in loss_box_reg (batch 1617) - using fallback: 0.0318 (count: 255)
2025-10-05 17:58:42,757 - WARNING - NaN/inf in loss_objectness (batch 1617) - using fallback: 0.0101 (count: 255)
2025-10-05 17:58:42,757 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1617) - using fallback: 0.0126 (count: 255)
2025-10-05 17:58:42,758 - ERROR - Error processing batch 1617: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:43,524 - WARNING - NaN/inf in loss_classifier (batch 1618) - using fallback: 0.0302 (count: 256)
2025-10-05 17:58:43,524 - WARNING - NaN/inf in loss_box_reg (batch 1618) - using fallback: 0.0318 (count: 256)
2025-10-05 17:58:43,525 - WARNING - NaN/inf in loss_objectness (batch 1618) - using fallback: 0.0101 (count: 256)
2025-10-05 17:58:43,525 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1618) - using fallback: 0.0126 (count: 256)
2025-10-05 17:58:43,525 - ERROR - Error processing batch 1618: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:44,215 - WARNING - NaN/inf in loss_classifier (batch 1619) - using fallback: 0.0302 (count: 257)
2025-10-05 17:58:44,216 - WARNING - NaN/inf in loss_box_reg (batch 1619) - using fallback: 0.0318 (count: 257)
2025-10-05 17:58:44,216 - WARNING - NaN/inf in loss_objectness (batch 1619) - using fallback: 0.0101 (count: 257)
2025-10-05 17:58:44,216 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1619) - using fallback: 0.0126 (count: 257)
2025-10-05 17:58:44,217 - ERROR - Error processing batch 1619: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:44,893 - WARNING - NaN/inf in loss_classifier (batch 1620) - using fallback: 0.0302 (count: 258)
2025-10-05 17:58:44,894 - WARNING - NaN/inf in loss_box_reg (batch 1620) - using fallback: 0.0318 (count: 258)
2025-10-05 17:58:44,895 - WARNING - NaN/inf in loss_objectness (batch 1620) - using fallback: 0.0101 (count: 258)
2025-10-05 17:58:44,896 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1620) - using fallback: 0.0126 (count: 258)
2025-10-05 17:58:44,897 - ERROR - Error processing batch 1620: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:45,689 - WARNING - NaN/inf in loss_classifier (batch 1621) - using fallback: 0.0302 (count: 259)
2025-10-05 17:58:45,689 - WARNING - NaN/inf in loss_box_reg (batch 1621) - using fallback: 0.0318 (count: 259)
2025-10-05 17:58:45,690 - WARNING - NaN/inf in loss_objectness (batch 1621) - using fallback: 0.0101 (count: 259)
2025-10-05 17:58:45,690 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1621) - using fallback: 0.0126 (count: 259)
2025-10-05 17:58:45,691 - ERROR - Error processing batch 1621: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:46,296 - WARNING - NaN/inf in loss_classifier (batch 1622) - using fallback: 0.0302 (count: 260)
2025-10-05 17:58:46,296 - WARNING - NaN/inf in loss_box_reg (batch 1622) - using fallback: 0.0318 (count: 260)
2025-10-05 17:58:46,297 - WARNING - NaN/inf in loss_objectness (batch 1622) - using fallback: 0.0101 (count: 260)
2025-10-05 17:58:46,298 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1622) - using fallback: 0.0126 (count: 260)
2025-10-05 17:58:46,298 - ERROR - Error processing batch 1622: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:46,849 - WARNING - NaN/inf in loss_classifier (batch 1623) - using fallback: 0.0302 (count: 261)
2025-10-05 17:58:46,850 - WARNING - NaN/inf in loss_box_reg (batch 1623) - using fallback: 0.0318 (count: 261)
2025-10-05 17:58:46,851 - WARNING - NaN/inf in loss_objectness (batch 1623) - using fallback: 0.0101 (count: 261)
2025-10-05 17:58:46,851 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1623) - using fallback: 0.0126 (count: 261)
2025-10-05 17:58:46,852 - ERROR - Error processing batch 1623: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:47,664 - WARNING - NaN/inf in loss_classifier (batch 1624) - using fallback: 0.0302 (count: 262)
2025-10-05 17:58:47,665 - WARNING - NaN/inf in loss_box_reg (batch 1624) - using fallback: 0.0318 (count: 262)
2025-10-05 17:58:47,666 - WARNING - NaN/inf in loss_objectness (batch 1624) - using fallback: 0.0101 (count: 262)
2025-10-05 17:58:47,666 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1624) - using fallback: 0.0126 (count: 262)
2025-10-05 17:58:47,667 - ERROR - Error processing batch 1624: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:48,212 - WARNING - NaN/inf in loss_classifier (batch 1625) - using fallback: 0.0302 (count: 263)
2025-10-05 17:58:48,213 - WARNING - NaN/inf in loss_box_reg (batch 1625) - using fallback: 0.0318 (count: 263)
2025-10-05 17:58:48,213 - WARNING - NaN/inf in loss_objectness (batch 1625) - using fallback: 0.0101 (count: 263)
2025-10-05 17:58:48,214 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1625) - using fallback: 0.0126 (count: 263)
2025-10-05 17:58:48,215 - ERROR - Error processing batch 1625: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:49,040 - WARNING - NaN/inf in loss_classifier (batch 1626) - using fallback: 0.0302 (count: 264)
2025-10-05 17:58:49,041 - WARNING - NaN/inf in loss_box_reg (batch 1626) - using fallback: 0.0318 (count: 264)
2025-10-05 17:58:49,041 - WARNING - NaN/inf in loss_objectness (batch 1626) - using fallback: 0.0101 (count: 264)
2025-10-05 17:58:49,042 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1626) - using fallback: 0.0126 (count: 264)
2025-10-05 17:58:49,043 - ERROR - Error processing batch 1626: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:49,588 - WARNING - NaN/inf in loss_classifier (batch 1627) - using fallback: 0.0302 (count: 265)
2025-10-05 17:58:49,589 - WARNING - NaN/inf in loss_box_reg (batch 1627) - using fallback: 0.0318 (count: 265)
2025-10-05 17:58:49,590 - WARNING - NaN/inf in loss_objectness (batch 1627) - using fallback: 0.0101 (count: 265)
2025-10-05 17:58:49,590 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1627) - using fallback: 0.0126 (count: 265)
2025-10-05 17:58:49,591 - ERROR - Error processing batch 1627: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:50,474 - WARNING - NaN/inf in loss_classifier (batch 1628) - using fallback: 0.0302 (count: 266)
2025-10-05 17:58:50,475 - WARNING - NaN/inf in loss_box_reg (batch 1628) - using fallback: 0.0318 (count: 266)
2025-10-05 17:58:50,476 - WARNING - NaN/inf in loss_objectness (batch 1628) - using fallback: 0.0101 (count: 266)
2025-10-05 17:58:50,476 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1628) - using fallback: 0.0126 (count: 266)
2025-10-05 17:58:50,477 - ERROR - Error processing batch 1628: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:51,063 - WARNING - NaN/inf in loss_classifier (batch 1629) - using fallback: 0.0302 (count: 267)
2025-10-05 17:58:51,063 - WARNING - NaN/inf in loss_box_reg (batch 1629) - using fallback: 0.0318 (count: 267)
2025-10-05 17:58:51,064 - WARNING - NaN/inf in loss_objectness (batch 1629) - using fallback: 0.0101 (count: 267)
2025-10-05 17:58:51,064 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1629) - using fallback: 0.0126 (count: 267)
2025-10-05 17:58:51,065 - ERROR - Error processing batch 1629: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:51,945 - WARNING - NaN/inf in loss_classifier (batch 1630) - using fallback: 0.0302 (count: 268)
2025-10-05 17:58:51,945 - WARNING - NaN/inf in loss_box_reg (batch 1630) - using fallback: 0.0318 (count: 268)
2025-10-05 17:58:51,946 - WARNING - NaN/inf in loss_objectness (batch 1630) - using fallback: 0.0101 (count: 268)
2025-10-05 17:58:51,947 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1630) - using fallback: 0.0126 (count: 268)
2025-10-05 17:58:51,948 - ERROR - Error processing batch 1630: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:52,490 - WARNING - NaN/inf in loss_classifier (batch 1631) - using fallback: 0.0302 (count: 269)
2025-10-05 17:58:52,491 - WARNING - NaN/inf in loss_box_reg (batch 1631) - using fallback: 0.0318 (count: 269)
2025-10-05 17:58:52,492 - WARNING - NaN/inf in loss_objectness (batch 1631) - using fallback: 0.0101 (count: 269)
2025-10-05 17:58:52,492 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1631) - using fallback: 0.0126 (count: 269)
2025-10-05 17:58:52,493 - ERROR - Error processing batch 1631: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:53,115 - WARNING - NaN/inf in loss_classifier (batch 1632) - using fallback: 0.0302 (count: 270)
2025-10-05 17:58:53,116 - WARNING - NaN/inf in loss_box_reg (batch 1632) - using fallback: 0.0318 (count: 270)
2025-10-05 17:58:53,116 - WARNING - NaN/inf in loss_objectness (batch 1632) - using fallback: 0.0101 (count: 270)
2025-10-05 17:58:53,117 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1632) - using fallback: 0.0126 (count: 270)
2025-10-05 17:58:53,117 - ERROR - Error processing batch 1632: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:53,708 - WARNING - NaN/inf in loss_classifier (batch 1633) - using fallback: 0.0302 (count: 271)
2025-10-05 17:58:53,709 - WARNING - NaN/inf in loss_box_reg (batch 1633) - using fallback: 0.0318 (count: 271)
2025-10-05 17:58:53,709 - WARNING - NaN/inf in loss_objectness (batch 1633) - using fallback: 0.0101 (count: 271)
2025-10-05 17:58:53,710 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1633) - using fallback: 0.0126 (count: 271)
2025-10-05 17:58:53,710 - ERROR - Error processing batch 1633: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:54,312 - WARNING - NaN/inf in loss_classifier (batch 1634) - using fallback: 0.0302 (count: 272)
2025-10-05 17:58:54,313 - WARNING - NaN/inf in loss_box_reg (batch 1634) - using fallback: 0.0318 (count: 272)
2025-10-05 17:58:54,313 - WARNING - NaN/inf in loss_objectness (batch 1634) - using fallback: 0.0101 (count: 272)
2025-10-05 17:58:54,314 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1634) - using fallback: 0.0126 (count: 272)
2025-10-05 17:58:54,315 - ERROR - Error processing batch 1634: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:54,825 - WARNING - NaN/inf in loss_classifier (batch 1635) - using fallback: 0.0302 (count: 273)
2025-10-05 17:58:54,826 - WARNING - NaN/inf in loss_box_reg (batch 1635) - using fallback: 0.0318 (count: 273)
2025-10-05 17:58:54,826 - WARNING - NaN/inf in loss_objectness (batch 1635) - using fallback: 0.0101 (count: 273)
2025-10-05 17:58:54,827 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1635) - using fallback: 0.0126 (count: 273)
2025-10-05 17:58:54,828 - ERROR - Error processing batch 1635: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:55,431 - WARNING - NaN/inf in loss_classifier (batch 1636) - using fallback: 0.0302 (count: 274)
2025-10-05 17:58:55,432 - WARNING - NaN/inf in loss_box_reg (batch 1636) - using fallback: 0.0318 (count: 274)
2025-10-05 17:58:55,433 - WARNING - NaN/inf in loss_objectness (batch 1636) - using fallback: 0.0101 (count: 274)
2025-10-05 17:58:55,433 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1636) - using fallback: 0.0126 (count: 274)
2025-10-05 17:58:55,434 - ERROR - Error processing batch 1636: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:56,005 - WARNING - NaN/inf in loss_classifier (batch 1637) - using fallback: 0.0302 (count: 275)
2025-10-05 17:58:56,006 - WARNING - NaN/inf in loss_box_reg (batch 1637) - using fallback: 0.0318 (count: 275)
2025-10-05 17:58:56,007 - WARNING - NaN/inf in loss_objectness (batch 1637) - using fallback: 0.0101 (count: 275)
2025-10-05 17:58:56,007 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1637) - using fallback: 0.0126 (count: 275)
2025-10-05 17:58:56,008 - ERROR - Error processing batch 1637: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:56,664 - WARNING - NaN/inf in loss_classifier (batch 1638) - using fallback: 0.0302 (count: 276)
2025-10-05 17:58:56,665 - WARNING - NaN/inf in loss_box_reg (batch 1638) - using fallback: 0.0318 (count: 276)
2025-10-05 17:58:56,665 - WARNING - NaN/inf in loss_objectness (batch 1638) - using fallback: 0.0101 (count: 276)
2025-10-05 17:58:56,666 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1638) - using fallback: 0.0126 (count: 276)
2025-10-05 17:58:56,666 - ERROR - Error processing batch 1638: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:57,163 - WARNING - NaN/inf in loss_classifier (batch 1639) - using fallback: 0.0302 (count: 277)
2025-10-05 17:58:57,164 - WARNING - NaN/inf in loss_box_reg (batch 1639) - using fallback: 0.0318 (count: 277)
2025-10-05 17:58:57,165 - WARNING - NaN/inf in loss_objectness (batch 1639) - using fallback: 0.0101 (count: 277)
2025-10-05 17:58:57,166 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1639) - using fallback: 0.0126 (count: 277)
2025-10-05 17:58:57,166 - ERROR - Error processing batch 1639: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:57,831 - WARNING - NaN/inf in loss_classifier (batch 1640) - using fallback: 0.0302 (count: 278)
2025-10-05 17:58:57,831 - WARNING - NaN/inf in loss_box_reg (batch 1640) - using fallback: 0.0318 (count: 278)
2025-10-05 17:58:57,832 - WARNING - NaN/inf in loss_objectness (batch 1640) - using fallback: 0.0101 (count: 278)
2025-10-05 17:58:57,833 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1640) - using fallback: 0.0126 (count: 278)
2025-10-05 17:58:57,833 - ERROR - Error processing batch 1640: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:58,400 - WARNING - NaN/inf in loss_classifier (batch 1641) - using fallback: 0.0302 (count: 279)
2025-10-05 17:58:58,401 - WARNING - NaN/inf in loss_box_reg (batch 1641) - using fallback: 0.0318 (count: 279)
2025-10-05 17:58:58,401 - WARNING - NaN/inf in loss_objectness (batch 1641) - using fallback: 0.0101 (count: 279)
2025-10-05 17:58:58,402 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1641) - using fallback: 0.0126 (count: 279)
2025-10-05 17:58:58,402 - ERROR - Error processing batch 1641: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:59,057 - WARNING - NaN/inf in loss_classifier (batch 1642) - using fallback: 0.0302 (count: 280)
2025-10-05 17:58:59,058 - WARNING - NaN/inf in loss_box_reg (batch 1642) - using fallback: 0.0318 (count: 280)
2025-10-05 17:58:59,059 - WARNING - NaN/inf in loss_objectness (batch 1642) - using fallback: 0.0101 (count: 280)
2025-10-05 17:58:59,060 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1642) - using fallback: 0.0126 (count: 280)
2025-10-05 17:58:59,061 - ERROR - Error processing batch 1642: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:58:59,582 - WARNING - NaN/inf in loss_classifier (batch 1643) - using fallback: 0.0302 (count: 281)
2025-10-05 17:58:59,583 - WARNING - NaN/inf in loss_box_reg (batch 1643) - using fallback: 0.0318 (count: 281)
2025-10-05 17:58:59,583 - WARNING - NaN/inf in loss_objectness (batch 1643) - using fallback: 0.0101 (count: 281)
2025-10-05 17:58:59,584 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1643) - using fallback: 0.0126 (count: 281)
2025-10-05 17:58:59,585 - ERROR - Error processing batch 1643: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:00,410 - WARNING - NaN/inf in loss_classifier (batch 1644) - using fallback: 0.0302 (count: 282)
2025-10-05 17:59:00,411 - WARNING - NaN/inf in loss_box_reg (batch 1644) - using fallback: 0.0318 (count: 282)
2025-10-05 17:59:00,412 - WARNING - NaN/inf in loss_objectness (batch 1644) - using fallback: 0.0101 (count: 282)
2025-10-05 17:59:00,413 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1644) - using fallback: 0.0126 (count: 282)
2025-10-05 17:59:00,414 - ERROR - Error processing batch 1644: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:00,984 - WARNING - NaN/inf in loss_classifier (batch 1645) - using fallback: 0.0302 (count: 283)
2025-10-05 17:59:00,985 - WARNING - NaN/inf in loss_box_reg (batch 1645) - using fallback: 0.0318 (count: 283)
2025-10-05 17:59:00,985 - WARNING - NaN/inf in loss_objectness (batch 1645) - using fallback: 0.0101 (count: 283)
2025-10-05 17:59:00,986 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1645) - using fallback: 0.0126 (count: 283)
2025-10-05 17:59:00,986 - ERROR - Error processing batch 1645: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:01,637 - WARNING - NaN/inf in loss_classifier (batch 1646) - using fallback: 0.0302 (count: 284)
2025-10-05 17:59:01,638 - WARNING - NaN/inf in loss_box_reg (batch 1646) - using fallback: 0.0318 (count: 284)
2025-10-05 17:59:01,639 - WARNING - NaN/inf in loss_objectness (batch 1646) - using fallback: 0.0101 (count: 284)
2025-10-05 17:59:01,639 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1646) - using fallback: 0.0126 (count: 284)
2025-10-05 17:59:01,640 - ERROR - Error processing batch 1646: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:02,219 - WARNING - NaN/inf in loss_classifier (batch 1647) - using fallback: 0.0302 (count: 285)
2025-10-05 17:59:02,220 - WARNING - NaN/inf in loss_box_reg (batch 1647) - using fallback: 0.0318 (count: 285)
2025-10-05 17:59:02,220 - WARNING - NaN/inf in loss_objectness (batch 1647) - using fallback: 0.0101 (count: 285)
2025-10-05 17:59:02,221 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1647) - using fallback: 0.0126 (count: 285)
2025-10-05 17:59:02,222 - ERROR - Error processing batch 1647: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:03,114 - WARNING - NaN/inf in loss_classifier (batch 1648) - using fallback: 0.0302 (count: 286)
2025-10-05 17:59:03,115 - WARNING - NaN/inf in loss_box_reg (batch 1648) - using fallback: 0.0318 (count: 286)
2025-10-05 17:59:03,116 - WARNING - NaN/inf in loss_objectness (batch 1648) - using fallback: 0.0101 (count: 286)
2025-10-05 17:59:03,117 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1648) - using fallback: 0.0126 (count: 286)
2025-10-05 17:59:03,118 - ERROR - Error processing batch 1648: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:03,726 - WARNING - NaN/inf in loss_classifier (batch 1649) - using fallback: 0.0302 (count: 287)
2025-10-05 17:59:03,727 - WARNING - NaN/inf in loss_box_reg (batch 1649) - using fallback: 0.0318 (count: 287)
2025-10-05 17:59:03,728 - WARNING - NaN/inf in loss_objectness (batch 1649) - using fallback: 0.0101 (count: 287)
2025-10-05 17:59:03,729 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1649) - using fallback: 0.0126 (count: 287)
2025-10-05 17:59:03,729 - ERROR - Error processing batch 1649: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:04,583 - WARNING - NaN/inf in loss_classifier (batch 1650) - using fallback: 0.0302 (count: 288)
2025-10-05 17:59:04,584 - WARNING - NaN/inf in loss_box_reg (batch 1650) - using fallback: 0.0318 (count: 288)
2025-10-05 17:59:04,584 - WARNING - NaN/inf in loss_objectness (batch 1650) - using fallback: 0.0101 (count: 288)
2025-10-05 17:59:04,585 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1650) - using fallback: 0.0126 (count: 288)
2025-10-05 17:59:04,585 - ERROR - Error processing batch 1650: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:05,148 - WARNING - NaN/inf in loss_classifier (batch 1651) - using fallback: 0.0302 (count: 289)
2025-10-05 17:59:05,149 - WARNING - NaN/inf in loss_box_reg (batch 1651) - using fallback: 0.0318 (count: 289)
2025-10-05 17:59:05,150 - WARNING - NaN/inf in loss_objectness (batch 1651) - using fallback: 0.0101 (count: 289)
2025-10-05 17:59:05,150 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1651) - using fallback: 0.0126 (count: 289)
2025-10-05 17:59:05,151 - ERROR - Error processing batch 1651: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:05,925 - WARNING - NaN/inf in loss_classifier (batch 1652) - using fallback: 0.0302 (count: 290)
2025-10-05 17:59:05,926 - WARNING - NaN/inf in loss_box_reg (batch 1652) - using fallback: 0.0318 (count: 290)
2025-10-05 17:59:05,927 - WARNING - NaN/inf in loss_objectness (batch 1652) - using fallback: 0.0101 (count: 290)
2025-10-05 17:59:05,927 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1652) - using fallback: 0.0126 (count: 290)
2025-10-05 17:59:05,928 - ERROR - Error processing batch 1652: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:06,556 - WARNING - NaN/inf in loss_classifier (batch 1653) - using fallback: 0.0302 (count: 291)
2025-10-05 17:59:06,556 - WARNING - NaN/inf in loss_box_reg (batch 1653) - using fallback: 0.0318 (count: 291)
2025-10-05 17:59:06,557 - WARNING - NaN/inf in loss_objectness (batch 1653) - using fallback: 0.0101 (count: 291)
2025-10-05 17:59:06,557 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1653) - using fallback: 0.0126 (count: 291)
2025-10-05 17:59:06,558 - ERROR - Error processing batch 1653: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:07,328 - WARNING - NaN/inf in loss_classifier (batch 1654) - using fallback: 0.0302 (count: 292)
2025-10-05 17:59:07,328 - WARNING - NaN/inf in loss_box_reg (batch 1654) - using fallback: 0.0318 (count: 292)
2025-10-05 17:59:07,329 - WARNING - NaN/inf in loss_objectness (batch 1654) - using fallback: 0.0101 (count: 292)
2025-10-05 17:59:07,330 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1654) - using fallback: 0.0126 (count: 292)
2025-10-05 17:59:07,331 - ERROR - Error processing batch 1654: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:08,042 - WARNING - NaN/inf in loss_classifier (batch 1655) - using fallback: 0.0302 (count: 293)
2025-10-05 17:59:08,043 - WARNING - NaN/inf in loss_box_reg (batch 1655) - using fallback: 0.0318 (count: 293)
2025-10-05 17:59:08,043 - WARNING - NaN/inf in loss_objectness (batch 1655) - using fallback: 0.0101 (count: 293)
2025-10-05 17:59:08,044 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1655) - using fallback: 0.0126 (count: 293)
2025-10-05 17:59:08,044 - ERROR - Error processing batch 1655: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:08,799 - WARNING - NaN/inf in loss_classifier (batch 1656) - using fallback: 0.0302 (count: 294)
2025-10-05 17:59:08,800 - WARNING - NaN/inf in loss_box_reg (batch 1656) - using fallback: 0.0318 (count: 294)
2025-10-05 17:59:08,801 - WARNING - NaN/inf in loss_objectness (batch 1656) - using fallback: 0.0101 (count: 294)
2025-10-05 17:59:08,801 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1656) - using fallback: 0.0126 (count: 294)
2025-10-05 17:59:08,802 - ERROR - Error processing batch 1656: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:09,682 - WARNING - NaN/inf in loss_classifier (batch 1657) - using fallback: 0.0302 (count: 295)
2025-10-05 17:59:09,683 - WARNING - NaN/inf in loss_box_reg (batch 1657) - using fallback: 0.0318 (count: 295)
2025-10-05 17:59:09,683 - WARNING - NaN/inf in loss_objectness (batch 1657) - using fallback: 0.0101 (count: 295)
2025-10-05 17:59:09,683 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1657) - using fallback: 0.0126 (count: 295)
2025-10-05 17:59:09,684 - ERROR - Error processing batch 1657: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:10,539 - WARNING - NaN/inf in loss_classifier (batch 1658) - using fallback: 0.0302 (count: 296)
2025-10-05 17:59:10,540 - WARNING - NaN/inf in loss_box_reg (batch 1658) - using fallback: 0.0318 (count: 296)
2025-10-05 17:59:10,540 - WARNING - NaN/inf in loss_objectness (batch 1658) - using fallback: 0.0101 (count: 296)
2025-10-05 17:59:10,541 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1658) - using fallback: 0.0126 (count: 296)
2025-10-05 17:59:10,542 - ERROR - Error processing batch 1658: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:11,338 - WARNING - NaN/inf in loss_classifier (batch 1659) - using fallback: 0.0302 (count: 297)
2025-10-05 17:59:11,339 - WARNING - NaN/inf in loss_box_reg (batch 1659) - using fallback: 0.0318 (count: 297)
2025-10-05 17:59:11,340 - WARNING - NaN/inf in loss_objectness (batch 1659) - using fallback: 0.0101 (count: 297)
2025-10-05 17:59:11,340 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1659) - using fallback: 0.0126 (count: 297)
2025-10-05 17:59:11,341 - ERROR - Error processing batch 1659: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:12,148 - WARNING - NaN/inf in loss_classifier (batch 1660) - using fallback: 0.0302 (count: 298)
2025-10-05 17:59:12,149 - WARNING - NaN/inf in loss_box_reg (batch 1660) - using fallback: 0.0318 (count: 298)
2025-10-05 17:59:12,149 - WARNING - NaN/inf in loss_objectness (batch 1660) - using fallback: 0.0101 (count: 298)
2025-10-05 17:59:12,150 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1660) - using fallback: 0.0126 (count: 298)
2025-10-05 17:59:12,151 - ERROR - Error processing batch 1660: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:12,995 - WARNING - NaN/inf in loss_classifier (batch 1661) - using fallback: 0.0302 (count: 299)
2025-10-05 17:59:12,996 - WARNING - NaN/inf in loss_box_reg (batch 1661) - using fallback: 0.0318 (count: 299)
2025-10-05 17:59:12,996 - WARNING - NaN/inf in loss_objectness (batch 1661) - using fallback: 0.0101 (count: 299)
2025-10-05 17:59:12,997 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1661) - using fallback: 0.0126 (count: 299)
2025-10-05 17:59:12,998 - ERROR - Error processing batch 1661: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:13,984 - WARNING - NaN/inf in loss_classifier (batch 1662) - using fallback: 0.0302 (count: 300)
2025-10-05 17:59:13,985 - WARNING - NaN/inf in loss_box_reg (batch 1662) - using fallback: 0.0318 (count: 300)
2025-10-05 17:59:13,986 - WARNING - NaN/inf in loss_objectness (batch 1662) - using fallback: 0.0101 (count: 300)
2025-10-05 17:59:13,986 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1662) - using fallback: 0.0126 (count: 300)
2025-10-05 17:59:13,987 - ERROR - Error processing batch 1662: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:14,614 - WARNING - NaN/inf in loss_classifier (batch 1663) - using fallback: 0.0302 (count: 301)
2025-10-05 17:59:14,614 - WARNING - NaN/inf in loss_box_reg (batch 1663) - using fallback: 0.0318 (count: 301)
2025-10-05 17:59:14,615 - WARNING - NaN/inf in loss_objectness (batch 1663) - using fallback: 0.0101 (count: 301)
2025-10-05 17:59:14,616 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1663) - using fallback: 0.0126 (count: 301)
2025-10-05 17:59:14,616 - ERROR - Error processing batch 1663: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:15,466 - WARNING - NaN/inf in loss_classifier (batch 1664) - using fallback: 0.0302 (count: 302)
2025-10-05 17:59:15,467 - WARNING - NaN/inf in loss_box_reg (batch 1664) - using fallback: 0.0318 (count: 302)
2025-10-05 17:59:15,468 - WARNING - NaN/inf in loss_objectness (batch 1664) - using fallback: 0.0101 (count: 302)
2025-10-05 17:59:15,468 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1664) - using fallback: 0.0126 (count: 302)
2025-10-05 17:59:15,469 - ERROR - Error processing batch 1664: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:16,110 - WARNING - NaN/inf in loss_classifier (batch 1665) - using fallback: 0.0302 (count: 303)
2025-10-05 17:59:16,110 - WARNING - NaN/inf in loss_box_reg (batch 1665) - using fallback: 0.0318 (count: 303)
2025-10-05 17:59:16,111 - WARNING - NaN/inf in loss_objectness (batch 1665) - using fallback: 0.0101 (count: 303)
2025-10-05 17:59:16,111 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1665) - using fallback: 0.0126 (count: 303)
2025-10-05 17:59:16,112 - ERROR - Error processing batch 1665: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:16,898 - WARNING - NaN/inf in loss_classifier (batch 1666) - using fallback: 0.0302 (count: 304)
2025-10-05 17:59:16,898 - WARNING - NaN/inf in loss_box_reg (batch 1666) - using fallback: 0.0318 (count: 304)
2025-10-05 17:59:16,899 - WARNING - NaN/inf in loss_objectness (batch 1666) - using fallback: 0.0101 (count: 304)
2025-10-05 17:59:16,900 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1666) - using fallback: 0.0126 (count: 304)
2025-10-05 17:59:16,900 - ERROR - Error processing batch 1666: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:17,513 - WARNING - NaN/inf in loss_classifier (batch 1667) - using fallback: 0.0302 (count: 305)
2025-10-05 17:59:17,513 - WARNING - NaN/inf in loss_box_reg (batch 1667) - using fallback: 0.0318 (count: 305)
2025-10-05 17:59:17,514 - WARNING - NaN/inf in loss_objectness (batch 1667) - using fallback: 0.0101 (count: 305)
2025-10-05 17:59:17,515 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1667) - using fallback: 0.0126 (count: 305)
2025-10-05 17:59:17,516 - ERROR - Error processing batch 1667: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:18,517 - WARNING - NaN/inf in loss_classifier (batch 1668) - using fallback: 0.0302 (count: 306)
2025-10-05 17:59:18,517 - WARNING - NaN/inf in loss_box_reg (batch 1668) - using fallback: 0.0318 (count: 306)
2025-10-05 17:59:18,518 - WARNING - NaN/inf in loss_objectness (batch 1668) - using fallback: 0.0101 (count: 306)
2025-10-05 17:59:18,518 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1668) - using fallback: 0.0126 (count: 306)
2025-10-05 17:59:18,519 - ERROR - Error processing batch 1668: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:19,069 - WARNING - NaN/inf in loss_classifier (batch 1669) - using fallback: 0.0302 (count: 307)
2025-10-05 17:59:19,069 - WARNING - NaN/inf in loss_box_reg (batch 1669) - using fallback: 0.0318 (count: 307)
2025-10-05 17:59:19,070 - WARNING - NaN/inf in loss_objectness (batch 1669) - using fallback: 0.0101 (count: 307)
2025-10-05 17:59:19,070 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1669) - using fallback: 0.0126 (count: 307)
2025-10-05 17:59:19,071 - ERROR - Error processing batch 1669: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:19,962 - WARNING - NaN/inf in loss_classifier (batch 1670) - using fallback: 0.0302 (count: 308)
2025-10-05 17:59:19,963 - WARNING - NaN/inf in loss_box_reg (batch 1670) - using fallback: 0.0318 (count: 308)
2025-10-05 17:59:19,963 - WARNING - NaN/inf in loss_objectness (batch 1670) - using fallback: 0.0101 (count: 308)
2025-10-05 17:59:19,964 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1670) - using fallback: 0.0126 (count: 308)
2025-10-05 17:59:19,965 - ERROR - Error processing batch 1670: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:20,507 - WARNING - NaN/inf in loss_classifier (batch 1671) - using fallback: 0.0302 (count: 309)
2025-10-05 17:59:20,508 - WARNING - NaN/inf in loss_box_reg (batch 1671) - using fallback: 0.0318 (count: 309)
2025-10-05 17:59:20,509 - WARNING - NaN/inf in loss_objectness (batch 1671) - using fallback: 0.0101 (count: 309)
2025-10-05 17:59:20,509 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1671) - using fallback: 0.0126 (count: 309)
2025-10-05 17:59:20,510 - ERROR - Error processing batch 1671: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:21,527 - WARNING - NaN/inf in loss_classifier (batch 1672) - using fallback: 0.0302 (count: 310)
2025-10-05 17:59:21,528 - WARNING - NaN/inf in loss_box_reg (batch 1672) - using fallback: 0.0318 (count: 310)
2025-10-05 17:59:21,529 - WARNING - NaN/inf in loss_objectness (batch 1672) - using fallback: 0.0101 (count: 310)
2025-10-05 17:59:21,530 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1672) - using fallback: 0.0126 (count: 310)
2025-10-05 17:59:21,530 - ERROR - Error processing batch 1672: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:22,205 - WARNING - NaN/inf in loss_classifier (batch 1673) - using fallback: 0.0302 (count: 311)
2025-10-05 17:59:22,206 - WARNING - NaN/inf in loss_box_reg (batch 1673) - using fallback: 0.0318 (count: 311)
2025-10-05 17:59:22,206 - WARNING - NaN/inf in loss_objectness (batch 1673) - using fallback: 0.0101 (count: 311)
2025-10-05 17:59:22,207 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1673) - using fallback: 0.0126 (count: 311)
2025-10-05 17:59:22,207 - ERROR - Error processing batch 1673: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:23,107 - WARNING - NaN/inf in loss_classifier (batch 1674) - using fallback: 0.0302 (count: 312)
2025-10-05 17:59:23,108 - WARNING - NaN/inf in loss_box_reg (batch 1674) - using fallback: 0.0318 (count: 312)
2025-10-05 17:59:23,109 - WARNING - NaN/inf in loss_objectness (batch 1674) - using fallback: 0.0101 (count: 312)
2025-10-05 17:59:23,109 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1674) - using fallback: 0.0126 (count: 312)
2025-10-05 17:59:23,110 - ERROR - Error processing batch 1674: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:23,972 - WARNING - NaN/inf in loss_classifier (batch 1675) - using fallback: 0.0302 (count: 313)
2025-10-05 17:59:23,972 - WARNING - NaN/inf in loss_box_reg (batch 1675) - using fallback: 0.0318 (count: 313)
2025-10-05 17:59:23,973 - WARNING - NaN/inf in loss_objectness (batch 1675) - using fallback: 0.0101 (count: 313)
2025-10-05 17:59:23,974 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1675) - using fallback: 0.0126 (count: 313)
2025-10-05 17:59:23,974 - ERROR - Error processing batch 1675: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:24,972 - WARNING - NaN/inf in loss_classifier (batch 1676) - using fallback: 0.0302 (count: 314)
2025-10-05 17:59:24,972 - WARNING - NaN/inf in loss_box_reg (batch 1676) - using fallback: 0.0318 (count: 314)
2025-10-05 17:59:24,973 - WARNING - NaN/inf in loss_objectness (batch 1676) - using fallback: 0.0101 (count: 314)
2025-10-05 17:59:24,974 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1676) - using fallback: 0.0126 (count: 314)
2025-10-05 17:59:24,974 - ERROR - Error processing batch 1676: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:25,794 - WARNING - NaN/inf in loss_classifier (batch 1677) - using fallback: 0.0302 (count: 315)
2025-10-05 17:59:25,794 - WARNING - NaN/inf in loss_box_reg (batch 1677) - using fallback: 0.0318 (count: 315)
2025-10-05 17:59:25,795 - WARNING - NaN/inf in loss_objectness (batch 1677) - using fallback: 0.0101 (count: 315)
2025-10-05 17:59:25,795 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1677) - using fallback: 0.0126 (count: 315)
2025-10-05 17:59:25,796 - ERROR - Error processing batch 1677: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:26,589 - WARNING - NaN/inf in loss_classifier (batch 1678) - using fallback: 0.0302 (count: 316)
2025-10-05 17:59:26,589 - WARNING - NaN/inf in loss_box_reg (batch 1678) - using fallback: 0.0318 (count: 316)
2025-10-05 17:59:26,590 - WARNING - NaN/inf in loss_objectness (batch 1678) - using fallback: 0.0101 (count: 316)
2025-10-05 17:59:26,590 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1678) - using fallback: 0.0126 (count: 316)
2025-10-05 17:59:26,591 - ERROR - Error processing batch 1678: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:27,175 - WARNING - NaN/inf in loss_classifier (batch 1679) - using fallback: 0.0302 (count: 317)
2025-10-05 17:59:27,175 - WARNING - NaN/inf in loss_box_reg (batch 1679) - using fallback: 0.0318 (count: 317)
2025-10-05 17:59:27,176 - WARNING - NaN/inf in loss_objectness (batch 1679) - using fallback: 0.0101 (count: 317)
2025-10-05 17:59:27,176 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1679) - using fallback: 0.0126 (count: 317)
2025-10-05 17:59:27,177 - ERROR - Error processing batch 1679: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:28,024 - WARNING - NaN/inf in loss_classifier (batch 1680) - using fallback: 0.0302 (count: 318)
2025-10-05 17:59:28,037 - WARNING - NaN/inf in loss_box_reg (batch 1680) - using fallback: 0.0318 (count: 318)
2025-10-05 17:59:28,038 - WARNING - NaN/inf in loss_objectness (batch 1680) - using fallback: 0.0101 (count: 318)
2025-10-05 17:59:28,039 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1680) - using fallback: 0.0126 (count: 318)
2025-10-05 17:59:28,040 - ERROR - Error processing batch 1680: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:28,616 - WARNING - NaN/inf in loss_classifier (batch 1681) - using fallback: 0.0302 (count: 319)
2025-10-05 17:59:28,617 - WARNING - NaN/inf in loss_box_reg (batch 1681) - using fallback: 0.0318 (count: 319)
2025-10-05 17:59:28,618 - WARNING - NaN/inf in loss_objectness (batch 1681) - using fallback: 0.0101 (count: 319)
2025-10-05 17:59:28,619 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1681) - using fallback: 0.0126 (count: 319)
2025-10-05 17:59:28,619 - ERROR - Error processing batch 1681: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:29,247 - WARNING - NaN/inf in loss_classifier (batch 1682) - using fallback: 0.0302 (count: 320)
2025-10-05 17:59:29,247 - WARNING - NaN/inf in loss_box_reg (batch 1682) - using fallback: 0.0318 (count: 320)
2025-10-05 17:59:29,248 - WARNING - NaN/inf in loss_objectness (batch 1682) - using fallback: 0.0101 (count: 320)
2025-10-05 17:59:29,249 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1682) - using fallback: 0.0126 (count: 320)
2025-10-05 17:59:29,249 - ERROR - Error processing batch 1682: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:29,814 - WARNING - NaN/inf in loss_classifier (batch 1683) - using fallback: 0.0302 (count: 321)
2025-10-05 17:59:29,815 - WARNING - NaN/inf in loss_box_reg (batch 1683) - using fallback: 0.0318 (count: 321)
2025-10-05 17:59:29,816 - WARNING - NaN/inf in loss_objectness (batch 1683) - using fallback: 0.0101 (count: 321)
2025-10-05 17:59:29,817 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1683) - using fallback: 0.0126 (count: 321)
2025-10-05 17:59:29,818 - ERROR - Error processing batch 1683: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:30,664 - WARNING - NaN/inf in loss_classifier (batch 1684) - using fallback: 0.0302 (count: 322)
2025-10-05 17:59:30,665 - WARNING - NaN/inf in loss_box_reg (batch 1684) - using fallback: 0.0318 (count: 322)
2025-10-05 17:59:30,665 - WARNING - NaN/inf in loss_objectness (batch 1684) - using fallback: 0.0101 (count: 322)
2025-10-05 17:59:30,666 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1684) - using fallback: 0.0126 (count: 322)
2025-10-05 17:59:30,666 - ERROR - Error processing batch 1684: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:31,254 - WARNING - NaN/inf in loss_classifier (batch 1685) - using fallback: 0.0302 (count: 323)
2025-10-05 17:59:31,254 - WARNING - NaN/inf in loss_box_reg (batch 1685) - using fallback: 0.0318 (count: 323)
2025-10-05 17:59:31,255 - WARNING - NaN/inf in loss_objectness (batch 1685) - using fallback: 0.0101 (count: 323)
2025-10-05 17:59:31,255 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1685) - using fallback: 0.0126 (count: 323)
2025-10-05 17:59:31,256 - ERROR - Error processing batch 1685: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:31,847 - WARNING - NaN/inf in loss_classifier (batch 1686) - using fallback: 0.0302 (count: 324)
2025-10-05 17:59:31,847 - WARNING - NaN/inf in loss_box_reg (batch 1686) - using fallback: 0.0318 (count: 324)
2025-10-05 17:59:31,848 - WARNING - NaN/inf in loss_objectness (batch 1686) - using fallback: 0.0101 (count: 324)
2025-10-05 17:59:31,848 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1686) - using fallback: 0.0126 (count: 324)
2025-10-05 17:59:31,849 - ERROR - Error processing batch 1686: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:32,444 - WARNING - NaN/inf in loss_classifier (batch 1687) - using fallback: 0.0302 (count: 325)
2025-10-05 17:59:32,445 - WARNING - NaN/inf in loss_box_reg (batch 1687) - using fallback: 0.0318 (count: 325)
2025-10-05 17:59:32,446 - WARNING - NaN/inf in loss_objectness (batch 1687) - using fallback: 0.0101 (count: 325)
2025-10-05 17:59:32,447 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1687) - using fallback: 0.0126 (count: 325)
2025-10-05 17:59:32,447 - ERROR - Error processing batch 1687: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:33,009 - WARNING - NaN/inf in loss_classifier (batch 1688) - using fallback: 0.0302 (count: 326)
2025-10-05 17:59:33,010 - WARNING - NaN/inf in loss_box_reg (batch 1688) - using fallback: 0.0318 (count: 326)
2025-10-05 17:59:33,010 - WARNING - NaN/inf in loss_objectness (batch 1688) - using fallback: 0.0101 (count: 326)
2025-10-05 17:59:33,011 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1688) - using fallback: 0.0126 (count: 326)
2025-10-05 17:59:33,012 - ERROR - Error processing batch 1688: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:33,576 - WARNING - NaN/inf in loss_classifier (batch 1689) - using fallback: 0.0302 (count: 327)
2025-10-05 17:59:33,577 - WARNING - NaN/inf in loss_box_reg (batch 1689) - using fallback: 0.0318 (count: 327)
2025-10-05 17:59:33,577 - WARNING - NaN/inf in loss_objectness (batch 1689) - using fallback: 0.0101 (count: 327)
2025-10-05 17:59:33,578 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1689) - using fallback: 0.0126 (count: 327)
2025-10-05 17:59:33,578 - ERROR - Error processing batch 1689: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:34,123 - WARNING - NaN/inf in loss_classifier (batch 1690) - using fallback: 0.0302 (count: 328)
2025-10-05 17:59:34,123 - WARNING - NaN/inf in loss_box_reg (batch 1690) - using fallback: 0.0318 (count: 328)
2025-10-05 17:59:34,124 - WARNING - NaN/inf in loss_objectness (batch 1690) - using fallback: 0.0101 (count: 328)
2025-10-05 17:59:34,124 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1690) - using fallback: 0.0126 (count: 328)
2025-10-05 17:59:34,125 - ERROR - Error processing batch 1690: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:34,750 - WARNING - NaN/inf in loss_classifier (batch 1691) - using fallback: 0.0302 (count: 329)
2025-10-05 17:59:34,751 - WARNING - NaN/inf in loss_box_reg (batch 1691) - using fallback: 0.0318 (count: 329)
2025-10-05 17:59:34,752 - WARNING - NaN/inf in loss_objectness (batch 1691) - using fallback: 0.0101 (count: 329)
2025-10-05 17:59:34,752 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1691) - using fallback: 0.0126 (count: 329)
2025-10-05 17:59:34,753 - ERROR - Error processing batch 1691: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:35,329 - WARNING - NaN/inf in loss_classifier (batch 1692) - using fallback: 0.0302 (count: 330)
2025-10-05 17:59:35,330 - WARNING - NaN/inf in loss_box_reg (batch 1692) - using fallback: 0.0318 (count: 330)
2025-10-05 17:59:35,330 - WARNING - NaN/inf in loss_objectness (batch 1692) - using fallback: 0.0101 (count: 330)
2025-10-05 17:59:35,331 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1692) - using fallback: 0.0126 (count: 330)
2025-10-05 17:59:35,332 - ERROR - Error processing batch 1692: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:35,965 - WARNING - NaN/inf in loss_classifier (batch 1693) - using fallback: 0.0302 (count: 331)
2025-10-05 17:59:35,966 - WARNING - NaN/inf in loss_box_reg (batch 1693) - using fallback: 0.0318 (count: 331)
2025-10-05 17:59:35,966 - WARNING - NaN/inf in loss_objectness (batch 1693) - using fallback: 0.0101 (count: 331)
2025-10-05 17:59:35,967 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1693) - using fallback: 0.0126 (count: 331)
2025-10-05 17:59:35,967 - ERROR - Error processing batch 1693: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:36,567 - WARNING - NaN/inf in loss_classifier (batch 1694) - using fallback: 0.0302 (count: 332)
2025-10-05 17:59:36,567 - WARNING - NaN/inf in loss_box_reg (batch 1694) - using fallback: 0.0318 (count: 332)
2025-10-05 17:59:36,568 - WARNING - NaN/inf in loss_objectness (batch 1694) - using fallback: 0.0101 (count: 332)
2025-10-05 17:59:36,568 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1694) - using fallback: 0.0126 (count: 332)
2025-10-05 17:59:36,569 - ERROR - Error processing batch 1694: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:37,249 - WARNING - NaN/inf in loss_classifier (batch 1695) - using fallback: 0.0302 (count: 333)
2025-10-05 17:59:37,250 - WARNING - NaN/inf in loss_box_reg (batch 1695) - using fallback: 0.0318 (count: 333)
2025-10-05 17:59:37,251 - WARNING - NaN/inf in loss_objectness (batch 1695) - using fallback: 0.0101 (count: 333)
2025-10-05 17:59:37,251 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1695) - using fallback: 0.0126 (count: 333)
2025-10-05 17:59:37,252 - ERROR - Error processing batch 1695: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:37,765 - WARNING - NaN/inf in loss_classifier (batch 1696) - using fallback: 0.0302 (count: 334)
2025-10-05 17:59:37,766 - WARNING - NaN/inf in loss_box_reg (batch 1696) - using fallback: 0.0318 (count: 334)
2025-10-05 17:59:37,766 - WARNING - NaN/inf in loss_objectness (batch 1696) - using fallback: 0.0101 (count: 334)
2025-10-05 17:59:37,767 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1696) - using fallback: 0.0126 (count: 334)
2025-10-05 17:59:37,768 - ERROR - Error processing batch 1696: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:38,373 - WARNING - NaN/inf in loss_classifier (batch 1697) - using fallback: 0.0302 (count: 335)
2025-10-05 17:59:38,373 - WARNING - NaN/inf in loss_box_reg (batch 1697) - using fallback: 0.0318 (count: 335)
2025-10-05 17:59:38,374 - WARNING - NaN/inf in loss_objectness (batch 1697) - using fallback: 0.0101 (count: 335)
2025-10-05 17:59:38,375 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1697) - using fallback: 0.0126 (count: 335)
2025-10-05 17:59:38,375 - ERROR - Error processing batch 1697: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:38,892 - WARNING - NaN/inf in loss_classifier (batch 1698) - using fallback: 0.0302 (count: 336)
2025-10-05 17:59:38,893 - WARNING - NaN/inf in loss_box_reg (batch 1698) - using fallback: 0.0318 (count: 336)
2025-10-05 17:59:38,894 - WARNING - NaN/inf in loss_objectness (batch 1698) - using fallback: 0.0101 (count: 336)
2025-10-05 17:59:38,894 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1698) - using fallback: 0.0126 (count: 336)
2025-10-05 17:59:38,895 - ERROR - Error processing batch 1698: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:39,483 - WARNING - NaN/inf in loss_classifier (batch 1699) - using fallback: 0.0302 (count: 337)
2025-10-05 17:59:39,484 - WARNING - NaN/inf in loss_box_reg (batch 1699) - using fallback: 0.0318 (count: 337)
2025-10-05 17:59:39,484 - WARNING - NaN/inf in loss_objectness (batch 1699) - using fallback: 0.0101 (count: 337)
2025-10-05 17:59:39,485 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1699) - using fallback: 0.0126 (count: 337)
2025-10-05 17:59:39,486 - ERROR - Error processing batch 1699: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:40,048 - WARNING - NaN/inf in loss_classifier (batch 1700) - using fallback: 0.0302 (count: 338)
2025-10-05 17:59:40,048 - WARNING - NaN/inf in loss_box_reg (batch 1700) - using fallback: 0.0318 (count: 338)
2025-10-05 17:59:40,049 - WARNING - NaN/inf in loss_objectness (batch 1700) - using fallback: 0.0101 (count: 338)
2025-10-05 17:59:40,049 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1700) - using fallback: 0.0126 (count: 338)
2025-10-05 17:59:40,050 - ERROR - Error processing batch 1700: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:40,706 - WARNING - NaN/inf in loss_classifier (batch 1701) - using fallback: 0.0302 (count: 339)
2025-10-05 17:59:40,707 - WARNING - NaN/inf in loss_box_reg (batch 1701) - using fallback: 0.0318 (count: 339)
2025-10-05 17:59:40,707 - WARNING - NaN/inf in loss_objectness (batch 1701) - using fallback: 0.0101 (count: 339)
2025-10-05 17:59:40,708 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1701) - using fallback: 0.0126 (count: 339)
2025-10-05 17:59:40,708 - ERROR - Error processing batch 1701: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:41,530 - WARNING - NaN/inf in loss_classifier (batch 1702) - using fallback: 0.0302 (count: 340)
2025-10-05 17:59:41,531 - WARNING - NaN/inf in loss_box_reg (batch 1702) - using fallback: 0.0318 (count: 340)
2025-10-05 17:59:41,531 - WARNING - NaN/inf in loss_objectness (batch 1702) - using fallback: 0.0101 (count: 340)
2025-10-05 17:59:41,532 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1702) - using fallback: 0.0126 (count: 340)
2025-10-05 17:59:41,532 - ERROR - Error processing batch 1702: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:42,322 - WARNING - NaN/inf in loss_classifier (batch 1703) - using fallback: 0.0302 (count: 341)
2025-10-05 17:59:42,323 - WARNING - NaN/inf in loss_box_reg (batch 1703) - using fallback: 0.0318 (count: 341)
2025-10-05 17:59:42,323 - WARNING - NaN/inf in loss_objectness (batch 1703) - using fallback: 0.0101 (count: 341)
2025-10-05 17:59:42,324 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1703) - using fallback: 0.0126 (count: 341)
2025-10-05 17:59:42,324 - ERROR - Error processing batch 1703: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:42,864 - WARNING - NaN/inf in loss_classifier (batch 1704) - using fallback: 0.0302 (count: 342)
2025-10-05 17:59:42,864 - WARNING - NaN/inf in loss_box_reg (batch 1704) - using fallback: 0.0318 (count: 342)
2025-10-05 17:59:42,865 - WARNING - NaN/inf in loss_objectness (batch 1704) - using fallback: 0.0101 (count: 342)
2025-10-05 17:59:42,865 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1704) - using fallback: 0.0126 (count: 342)
2025-10-05 17:59:42,866 - ERROR - Error processing batch 1704: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:43,845 - WARNING - NaN/inf in loss_classifier (batch 1705) - using fallback: 0.0302 (count: 343)
2025-10-05 17:59:43,845 - WARNING - NaN/inf in loss_box_reg (batch 1705) - using fallback: 0.0318 (count: 343)
2025-10-05 17:59:43,846 - WARNING - NaN/inf in loss_objectness (batch 1705) - using fallback: 0.0101 (count: 343)
2025-10-05 17:59:43,847 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1705) - using fallback: 0.0126 (count: 343)
2025-10-05 17:59:43,847 - ERROR - Error processing batch 1705: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:44,764 - WARNING - NaN/inf in loss_classifier (batch 1706) - using fallback: 0.0302 (count: 344)
2025-10-05 17:59:44,765 - WARNING - NaN/inf in loss_box_reg (batch 1706) - using fallback: 0.0318 (count: 344)
2025-10-05 17:59:44,766 - WARNING - NaN/inf in loss_objectness (batch 1706) - using fallback: 0.0101 (count: 344)
2025-10-05 17:59:44,766 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1706) - using fallback: 0.0126 (count: 344)
2025-10-05 17:59:44,767 - ERROR - Error processing batch 1706: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:45,801 - WARNING - NaN/inf in loss_classifier (batch 1707) - using fallback: 0.0302 (count: 345)
2025-10-05 17:59:45,802 - WARNING - NaN/inf in loss_box_reg (batch 1707) - using fallback: 0.0318 (count: 345)
2025-10-05 17:59:45,802 - WARNING - NaN/inf in loss_objectness (batch 1707) - using fallback: 0.0101 (count: 345)
2025-10-05 17:59:45,803 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1707) - using fallback: 0.0126 (count: 345)
2025-10-05 17:59:45,804 - ERROR - Error processing batch 1707: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:46,592 - WARNING - NaN/inf in loss_classifier (batch 1708) - using fallback: 0.0302 (count: 346)
2025-10-05 17:59:46,593 - WARNING - NaN/inf in loss_box_reg (batch 1708) - using fallback: 0.0318 (count: 346)
2025-10-05 17:59:46,593 - WARNING - NaN/inf in loss_objectness (batch 1708) - using fallback: 0.0101 (count: 346)
2025-10-05 17:59:46,594 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1708) - using fallback: 0.0126 (count: 346)
2025-10-05 17:59:46,595 - ERROR - Error processing batch 1708: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:47,294 - WARNING - NaN/inf in loss_classifier (batch 1709) - using fallback: 0.0302 (count: 347)
2025-10-05 17:59:47,295 - WARNING - NaN/inf in loss_box_reg (batch 1709) - using fallback: 0.0318 (count: 347)
2025-10-05 17:59:47,295 - WARNING - NaN/inf in loss_objectness (batch 1709) - using fallback: 0.0101 (count: 347)
2025-10-05 17:59:47,296 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1709) - using fallback: 0.0126 (count: 347)
2025-10-05 17:59:47,297 - ERROR - Error processing batch 1709: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:47,902 - WARNING - NaN/inf in loss_classifier (batch 1710) - using fallback: 0.0302 (count: 348)
2025-10-05 17:59:47,903 - WARNING - NaN/inf in loss_box_reg (batch 1710) - using fallback: 0.0318 (count: 348)
2025-10-05 17:59:47,904 - WARNING - NaN/inf in loss_objectness (batch 1710) - using fallback: 0.0101 (count: 348)
2025-10-05 17:59:47,905 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1710) - using fallback: 0.0126 (count: 348)
2025-10-05 17:59:47,905 - ERROR - Error processing batch 1710: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:48,690 - WARNING - NaN/inf in loss_classifier (batch 1711) - using fallback: 0.0302 (count: 349)
2025-10-05 17:59:48,691 - WARNING - NaN/inf in loss_box_reg (batch 1711) - using fallback: 0.0318 (count: 349)
2025-10-05 17:59:48,692 - WARNING - NaN/inf in loss_objectness (batch 1711) - using fallback: 0.0101 (count: 349)
2025-10-05 17:59:48,692 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1711) - using fallback: 0.0126 (count: 349)
2025-10-05 17:59:48,693 - ERROR - Error processing batch 1711: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:49,656 - WARNING - NaN/inf in loss_classifier (batch 1712) - using fallback: 0.0302 (count: 350)
2025-10-05 17:59:49,656 - WARNING - NaN/inf in loss_box_reg (batch 1712) - using fallback: 0.0318 (count: 350)
2025-10-05 17:59:49,657 - WARNING - NaN/inf in loss_objectness (batch 1712) - using fallback: 0.0101 (count: 350)
2025-10-05 17:59:49,658 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1712) - using fallback: 0.0126 (count: 350)
2025-10-05 17:59:49,658 - ERROR - Error processing batch 1712: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:50,323 - WARNING - NaN/inf in loss_classifier (batch 1713) - using fallback: 0.0302 (count: 351)
2025-10-05 17:59:50,323 - WARNING - NaN/inf in loss_box_reg (batch 1713) - using fallback: 0.0318 (count: 351)
2025-10-05 17:59:50,324 - WARNING - NaN/inf in loss_objectness (batch 1713) - using fallback: 0.0101 (count: 351)
2025-10-05 17:59:50,324 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1713) - using fallback: 0.0126 (count: 351)
2025-10-05 17:59:50,325 - ERROR - Error processing batch 1713: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:51,294 - WARNING - NaN/inf in loss_classifier (batch 1714) - using fallback: 0.0302 (count: 352)
2025-10-05 17:59:51,294 - WARNING - NaN/inf in loss_box_reg (batch 1714) - using fallback: 0.0318 (count: 352)
2025-10-05 17:59:51,295 - WARNING - NaN/inf in loss_objectness (batch 1714) - using fallback: 0.0101 (count: 352)
2025-10-05 17:59:51,295 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1714) - using fallback: 0.0126 (count: 352)
2025-10-05 17:59:51,296 - ERROR - Error processing batch 1714: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:51,922 - WARNING - NaN/inf in loss_classifier (batch 1715) - using fallback: 0.0302 (count: 353)
2025-10-05 17:59:51,922 - WARNING - NaN/inf in loss_box_reg (batch 1715) - using fallback: 0.0318 (count: 353)
2025-10-05 17:59:51,923 - WARNING - NaN/inf in loss_objectness (batch 1715) - using fallback: 0.0101 (count: 353)
2025-10-05 17:59:51,923 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1715) - using fallback: 0.0126 (count: 353)
2025-10-05 17:59:51,924 - ERROR - Error processing batch 1715: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:52,837 - WARNING - NaN/inf in loss_classifier (batch 1716) - using fallback: 0.0302 (count: 354)
2025-10-05 17:59:52,838 - WARNING - NaN/inf in loss_box_reg (batch 1716) - using fallback: 0.0318 (count: 354)
2025-10-05 17:59:52,839 - WARNING - NaN/inf in loss_objectness (batch 1716) - using fallback: 0.0101 (count: 354)
2025-10-05 17:59:52,839 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1716) - using fallback: 0.0126 (count: 354)
2025-10-05 17:59:52,840 - ERROR - Error processing batch 1716: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:53,880 - WARNING - NaN/inf in loss_classifier (batch 1717) - using fallback: 0.0302 (count: 355)
2025-10-05 17:59:53,880 - WARNING - NaN/inf in loss_box_reg (batch 1717) - using fallback: 0.0318 (count: 355)
2025-10-05 17:59:53,881 - WARNING - NaN/inf in loss_objectness (batch 1717) - using fallback: 0.0101 (count: 355)
2025-10-05 17:59:53,882 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1717) - using fallback: 0.0126 (count: 355)
2025-10-05 17:59:53,883 - ERROR - Error processing batch 1717: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:54,667 - WARNING - NaN/inf in loss_classifier (batch 1718) - using fallback: 0.0302 (count: 356)
2025-10-05 17:59:54,668 - WARNING - NaN/inf in loss_box_reg (batch 1718) - using fallback: 0.0318 (count: 356)
2025-10-05 17:59:54,668 - WARNING - NaN/inf in loss_objectness (batch 1718) - using fallback: 0.0101 (count: 356)
2025-10-05 17:59:54,669 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1718) - using fallback: 0.0126 (count: 356)
2025-10-05 17:59:54,670 - ERROR - Error processing batch 1718: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:55,751 - WARNING - NaN/inf in loss_classifier (batch 1719) - using fallback: 0.0302 (count: 357)
2025-10-05 17:59:55,751 - WARNING - NaN/inf in loss_box_reg (batch 1719) - using fallback: 0.0318 (count: 357)
2025-10-05 17:59:55,752 - WARNING - NaN/inf in loss_objectness (batch 1719) - using fallback: 0.0101 (count: 357)
2025-10-05 17:59:55,752 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1719) - using fallback: 0.0126 (count: 357)
2025-10-05 17:59:55,753 - ERROR - Error processing batch 1719: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:56,305 - WARNING - NaN/inf in loss_classifier (batch 1720) - using fallback: 0.0302 (count: 358)
2025-10-05 17:59:56,305 - WARNING - NaN/inf in loss_box_reg (batch 1720) - using fallback: 0.0318 (count: 358)
2025-10-05 17:59:56,306 - WARNING - NaN/inf in loss_objectness (batch 1720) - using fallback: 0.0101 (count: 358)
2025-10-05 17:59:56,307 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1720) - using fallback: 0.0126 (count: 358)
2025-10-05 17:59:56,307 - ERROR - Error processing batch 1720: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:56,852 - WARNING - NaN/inf in loss_classifier (batch 1721) - using fallback: 0.0302 (count: 359)
2025-10-05 17:59:56,852 - WARNING - NaN/inf in loss_box_reg (batch 1721) - using fallback: 0.0318 (count: 359)
2025-10-05 17:59:56,853 - WARNING - NaN/inf in loss_objectness (batch 1721) - using fallback: 0.0101 (count: 359)
2025-10-05 17:59:56,853 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1721) - using fallback: 0.0126 (count: 359)
2025-10-05 17:59:56,854 - ERROR - Error processing batch 1721: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:57,535 - WARNING - NaN/inf in loss_classifier (batch 1722) - using fallback: 0.0302 (count: 360)
2025-10-05 17:59:57,536 - WARNING - NaN/inf in loss_box_reg (batch 1722) - using fallback: 0.0318 (count: 360)
2025-10-05 17:59:57,536 - WARNING - NaN/inf in loss_objectness (batch 1722) - using fallback: 0.0101 (count: 360)
2025-10-05 17:59:57,537 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1722) - using fallback: 0.0126 (count: 360)
2025-10-05 17:59:57,537 - ERROR - Error processing batch 1722: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:58,127 - WARNING - NaN/inf in loss_classifier (batch 1723) - using fallback: 0.0302 (count: 361)
2025-10-05 17:59:58,128 - WARNING - NaN/inf in loss_box_reg (batch 1723) - using fallback: 0.0318 (count: 361)
2025-10-05 17:59:58,129 - WARNING - NaN/inf in loss_objectness (batch 1723) - using fallback: 0.0101 (count: 361)
2025-10-05 17:59:58,130 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1723) - using fallback: 0.0126 (count: 361)
2025-10-05 17:59:58,130 - ERROR - Error processing batch 1723: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:58,771 - WARNING - NaN/inf in loss_classifier (batch 1724) - using fallback: 0.0302 (count: 362)
2025-10-05 17:59:58,771 - WARNING - NaN/inf in loss_box_reg (batch 1724) - using fallback: 0.0318 (count: 362)
2025-10-05 17:59:58,772 - WARNING - NaN/inf in loss_objectness (batch 1724) - using fallback: 0.0101 (count: 362)
2025-10-05 17:59:58,772 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1724) - using fallback: 0.0126 (count: 362)
2025-10-05 17:59:58,773 - ERROR - Error processing batch 1724: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 17:59:59,392 - WARNING - NaN/inf in loss_classifier (batch 1725) - using fallback: 0.0302 (count: 363)
2025-10-05 17:59:59,397 - WARNING - NaN/inf in loss_box_reg (batch 1725) - using fallback: 0.0318 (count: 363)
2025-10-05 17:59:59,398 - WARNING - NaN/inf in loss_objectness (batch 1725) - using fallback: 0.0101 (count: 363)
2025-10-05 17:59:59,399 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1725) - using fallback: 0.0126 (count: 363)
2025-10-05 17:59:59,399 - ERROR - Error processing batch 1725: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:00,048 - WARNING - NaN/inf in loss_classifier (batch 1726) - using fallback: 0.0302 (count: 364)
2025-10-05 18:00:00,048 - WARNING - NaN/inf in loss_box_reg (batch 1726) - using fallback: 0.0318 (count: 364)
2025-10-05 18:00:00,049 - WARNING - NaN/inf in loss_objectness (batch 1726) - using fallback: 0.0101 (count: 364)
2025-10-05 18:00:00,049 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1726) - using fallback: 0.0126 (count: 364)
2025-10-05 18:00:00,050 - ERROR - Error processing batch 1726: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:00,743 - WARNING - NaN/inf in loss_classifier (batch 1727) - using fallback: 0.0302 (count: 365)
2025-10-05 18:00:00,743 - WARNING - NaN/inf in loss_box_reg (batch 1727) - using fallback: 0.0318 (count: 365)
2025-10-05 18:00:00,744 - WARNING - NaN/inf in loss_objectness (batch 1727) - using fallback: 0.0101 (count: 365)
2025-10-05 18:00:00,744 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1727) - using fallback: 0.0126 (count: 365)
2025-10-05 18:00:00,745 - ERROR - Error processing batch 1727: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:01,358 - WARNING - NaN/inf in loss_classifier (batch 1728) - using fallback: 0.0302 (count: 366)
2025-10-05 18:00:01,359 - WARNING - NaN/inf in loss_box_reg (batch 1728) - using fallback: 0.0318 (count: 366)
2025-10-05 18:00:01,360 - WARNING - NaN/inf in loss_objectness (batch 1728) - using fallback: 0.0101 (count: 366)
2025-10-05 18:00:01,360 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1728) - using fallback: 0.0126 (count: 366)
2025-10-05 18:00:01,361 - ERROR - Error processing batch 1728: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:01,912 - WARNING - NaN/inf in loss_classifier (batch 1729) - using fallback: 0.0302 (count: 367)
2025-10-05 18:00:01,913 - WARNING - NaN/inf in loss_box_reg (batch 1729) - using fallback: 0.0318 (count: 367)
2025-10-05 18:00:01,913 - WARNING - NaN/inf in loss_objectness (batch 1729) - using fallback: 0.0101 (count: 367)
2025-10-05 18:00:01,914 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1729) - using fallback: 0.0126 (count: 367)
2025-10-05 18:00:01,915 - ERROR - Error processing batch 1729: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:02,598 - WARNING - NaN/inf in loss_classifier (batch 1730) - using fallback: 0.0302 (count: 368)
2025-10-05 18:00:02,599 - WARNING - NaN/inf in loss_box_reg (batch 1730) - using fallback: 0.0318 (count: 368)
2025-10-05 18:00:02,600 - WARNING - NaN/inf in loss_objectness (batch 1730) - using fallback: 0.0101 (count: 368)
2025-10-05 18:00:02,600 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1730) - using fallback: 0.0126 (count: 368)
2025-10-05 18:00:02,601 - ERROR - Error processing batch 1730: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:03,265 - WARNING - NaN/inf in loss_classifier (batch 1731) - using fallback: 0.0302 (count: 369)
2025-10-05 18:00:03,266 - WARNING - NaN/inf in loss_box_reg (batch 1731) - using fallback: 0.0318 (count: 369)
2025-10-05 18:00:03,266 - WARNING - NaN/inf in loss_objectness (batch 1731) - using fallback: 0.0101 (count: 369)
2025-10-05 18:00:03,267 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1731) - using fallback: 0.0126 (count: 369)
2025-10-05 18:00:03,267 - ERROR - Error processing batch 1731: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:03,933 - WARNING - NaN/inf in loss_classifier (batch 1732) - using fallback: 0.0302 (count: 370)
2025-10-05 18:00:03,934 - WARNING - NaN/inf in loss_box_reg (batch 1732) - using fallback: 0.0318 (count: 370)
2025-10-05 18:00:03,934 - WARNING - NaN/inf in loss_objectness (batch 1732) - using fallback: 0.0101 (count: 370)
2025-10-05 18:00:03,935 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1732) - using fallback: 0.0126 (count: 370)
2025-10-05 18:00:03,936 - ERROR - Error processing batch 1732: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:04,653 - WARNING - NaN/inf in loss_classifier (batch 1733) - using fallback: 0.0302 (count: 371)
2025-10-05 18:00:04,654 - WARNING - NaN/inf in loss_box_reg (batch 1733) - using fallback: 0.0318 (count: 371)
2025-10-05 18:00:04,655 - WARNING - NaN/inf in loss_objectness (batch 1733) - using fallback: 0.0101 (count: 371)
2025-10-05 18:00:04,655 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1733) - using fallback: 0.0126 (count: 371)
2025-10-05 18:00:04,656 - ERROR - Error processing batch 1733: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:05,208 - WARNING - NaN/inf in loss_classifier (batch 1734) - using fallback: 0.0302 (count: 372)
2025-10-05 18:00:05,209 - WARNING - NaN/inf in loss_box_reg (batch 1734) - using fallback: 0.0318 (count: 372)
2025-10-05 18:00:05,210 - WARNING - NaN/inf in loss_objectness (batch 1734) - using fallback: 0.0101 (count: 372)
2025-10-05 18:00:05,211 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1734) - using fallback: 0.0126 (count: 372)
2025-10-05 18:00:05,211 - ERROR - Error processing batch 1734: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:06,058 - WARNING - NaN/inf in loss_classifier (batch 1735) - using fallback: 0.0302 (count: 373)
2025-10-05 18:00:06,058 - WARNING - NaN/inf in loss_box_reg (batch 1735) - using fallback: 0.0318 (count: 373)
2025-10-05 18:00:06,059 - WARNING - NaN/inf in loss_objectness (batch 1735) - using fallback: 0.0101 (count: 373)
2025-10-05 18:00:06,060 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1735) - using fallback: 0.0126 (count: 373)
2025-10-05 18:00:06,061 - ERROR - Error processing batch 1735: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:06,610 - WARNING - NaN/inf in loss_classifier (batch 1736) - using fallback: 0.0302 (count: 374)
2025-10-05 18:00:06,610 - WARNING - NaN/inf in loss_box_reg (batch 1736) - using fallback: 0.0318 (count: 374)
2025-10-05 18:00:06,611 - WARNING - NaN/inf in loss_objectness (batch 1736) - using fallback: 0.0101 (count: 374)
2025-10-05 18:00:06,612 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1736) - using fallback: 0.0126 (count: 374)
2025-10-05 18:00:06,612 - ERROR - Error processing batch 1736: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:07,299 - WARNING - NaN/inf in loss_classifier (batch 1737) - using fallback: 0.0302 (count: 375)
2025-10-05 18:00:07,300 - WARNING - NaN/inf in loss_box_reg (batch 1737) - using fallback: 0.0318 (count: 375)
2025-10-05 18:00:07,301 - WARNING - NaN/inf in loss_objectness (batch 1737) - using fallback: 0.0101 (count: 375)
2025-10-05 18:00:07,301 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1737) - using fallback: 0.0126 (count: 375)
2025-10-05 18:00:07,302 - ERROR - Error processing batch 1737: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:07,810 - WARNING - NaN/inf in loss_classifier (batch 1738) - using fallback: 0.0302 (count: 376)
2025-10-05 18:00:07,811 - WARNING - NaN/inf in loss_box_reg (batch 1738) - using fallback: 0.0318 (count: 376)
2025-10-05 18:00:07,811 - WARNING - NaN/inf in loss_objectness (batch 1738) - using fallback: 0.0101 (count: 376)
2025-10-05 18:00:07,812 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1738) - using fallback: 0.0126 (count: 376)
2025-10-05 18:00:07,812 - ERROR - Error processing batch 1738: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:08,455 - WARNING - NaN/inf in loss_classifier (batch 1739) - using fallback: 0.0302 (count: 377)
2025-10-05 18:00:08,456 - WARNING - NaN/inf in loss_box_reg (batch 1739) - using fallback: 0.0318 (count: 377)
2025-10-05 18:00:08,457 - WARNING - NaN/inf in loss_objectness (batch 1739) - using fallback: 0.0101 (count: 377)
2025-10-05 18:00:08,458 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1739) - using fallback: 0.0126 (count: 377)
2025-10-05 18:00:08,458 - ERROR - Error processing batch 1739: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:08,948 - WARNING - NaN/inf in loss_classifier (batch 1740) - using fallback: 0.0302 (count: 378)
2025-10-05 18:00:08,949 - WARNING - NaN/inf in loss_box_reg (batch 1740) - using fallback: 0.0318 (count: 378)
2025-10-05 18:00:08,950 - WARNING - NaN/inf in loss_objectness (batch 1740) - using fallback: 0.0101 (count: 378)
2025-10-05 18:00:08,950 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1740) - using fallback: 0.0126 (count: 378)
2025-10-05 18:00:08,951 - ERROR - Error processing batch 1740: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:09,549 - WARNING - NaN/inf in loss_classifier (batch 1741) - using fallback: 0.0302 (count: 379)
2025-10-05 18:00:09,549 - WARNING - NaN/inf in loss_box_reg (batch 1741) - using fallback: 0.0318 (count: 379)
2025-10-05 18:00:09,550 - WARNING - NaN/inf in loss_objectness (batch 1741) - using fallback: 0.0101 (count: 379)
2025-10-05 18:00:09,550 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1741) - using fallback: 0.0126 (count: 379)
2025-10-05 18:00:09,551 - ERROR - Error processing batch 1741: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:10,070 - WARNING - NaN/inf in loss_classifier (batch 1742) - using fallback: 0.0302 (count: 380)
2025-10-05 18:00:10,070 - WARNING - NaN/inf in loss_box_reg (batch 1742) - using fallback: 0.0318 (count: 380)
2025-10-05 18:00:10,071 - WARNING - NaN/inf in loss_objectness (batch 1742) - using fallback: 0.0101 (count: 380)
2025-10-05 18:00:10,072 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1742) - using fallback: 0.0126 (count: 380)
2025-10-05 18:00:10,072 - ERROR - Error processing batch 1742: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:10,742 - WARNING - NaN/inf in loss_classifier (batch 1743) - using fallback: 0.0302 (count: 381)
2025-10-05 18:00:10,743 - WARNING - NaN/inf in loss_box_reg (batch 1743) - using fallback: 0.0318 (count: 381)
2025-10-05 18:00:10,744 - WARNING - NaN/inf in loss_objectness (batch 1743) - using fallback: 0.0101 (count: 381)
2025-10-05 18:00:10,744 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1743) - using fallback: 0.0126 (count: 381)
2025-10-05 18:00:10,745 - ERROR - Error processing batch 1743: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:11,277 - WARNING - NaN/inf in loss_classifier (batch 1744) - using fallback: 0.0302 (count: 382)
2025-10-05 18:00:11,278 - WARNING - NaN/inf in loss_box_reg (batch 1744) - using fallback: 0.0318 (count: 382)
2025-10-05 18:00:11,278 - WARNING - NaN/inf in loss_objectness (batch 1744) - using fallback: 0.0101 (count: 382)
2025-10-05 18:00:11,279 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1744) - using fallback: 0.0126 (count: 382)
2025-10-05 18:00:11,280 - ERROR - Error processing batch 1744: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:11,956 - WARNING - NaN/inf in loss_classifier (batch 1745) - using fallback: 0.0302 (count: 383)
2025-10-05 18:00:11,957 - WARNING - NaN/inf in loss_box_reg (batch 1745) - using fallback: 0.0318 (count: 383)
2025-10-05 18:00:11,958 - WARNING - NaN/inf in loss_objectness (batch 1745) - using fallback: 0.0101 (count: 383)
2025-10-05 18:00:11,958 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1745) - using fallback: 0.0126 (count: 383)
2025-10-05 18:00:11,959 - ERROR - Error processing batch 1745: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:12,482 - WARNING - NaN/inf in loss_classifier (batch 1746) - using fallback: 0.0302 (count: 384)
2025-10-05 18:00:12,483 - WARNING - NaN/inf in loss_box_reg (batch 1746) - using fallback: 0.0318 (count: 384)
2025-10-05 18:00:12,484 - WARNING - NaN/inf in loss_objectness (batch 1746) - using fallback: 0.0101 (count: 384)
2025-10-05 18:00:12,484 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1746) - using fallback: 0.0126 (count: 384)
2025-10-05 18:00:12,485 - ERROR - Error processing batch 1746: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:13,221 - WARNING - NaN/inf in loss_classifier (batch 1747) - using fallback: 0.0302 (count: 385)
2025-10-05 18:00:13,221 - WARNING - NaN/inf in loss_box_reg (batch 1747) - using fallback: 0.0318 (count: 385)
2025-10-05 18:00:13,222 - WARNING - NaN/inf in loss_objectness (batch 1747) - using fallback: 0.0101 (count: 385)
2025-10-05 18:00:13,223 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1747) - using fallback: 0.0126 (count: 385)
2025-10-05 18:00:13,223 - ERROR - Error processing batch 1747: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:13,711 - WARNING - NaN/inf in loss_classifier (batch 1748) - using fallback: 0.0302 (count: 386)
2025-10-05 18:00:13,712 - WARNING - NaN/inf in loss_box_reg (batch 1748) - using fallback: 0.0318 (count: 386)
2025-10-05 18:00:13,712 - WARNING - NaN/inf in loss_objectness (batch 1748) - using fallback: 0.0101 (count: 386)
2025-10-05 18:00:13,713 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1748) - using fallback: 0.0126 (count: 386)
2025-10-05 18:00:13,714 - ERROR - Error processing batch 1748: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:14,246 - WARNING - NaN/inf in loss_classifier (batch 1749) - using fallback: 0.0302 (count: 387)
2025-10-05 18:00:14,246 - WARNING - NaN/inf in loss_box_reg (batch 1749) - using fallback: 0.0318 (count: 387)
2025-10-05 18:00:14,247 - WARNING - NaN/inf in loss_objectness (batch 1749) - using fallback: 0.0101 (count: 387)
2025-10-05 18:00:14,247 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1749) - using fallback: 0.0126 (count: 387)
2025-10-05 18:00:14,248 - ERROR - Error processing batch 1749: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:14,750 - WARNING - NaN/inf in loss_classifier (batch 1750) - using fallback: 0.0302 (count: 388)
2025-10-05 18:00:14,751 - WARNING - NaN/inf in loss_box_reg (batch 1750) - using fallback: 0.0318 (count: 388)
2025-10-05 18:00:14,751 - WARNING - NaN/inf in loss_objectness (batch 1750) - using fallback: 0.0101 (count: 388)
2025-10-05 18:00:14,752 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1750) - using fallback: 0.0126 (count: 388)
2025-10-05 18:00:14,752 - ERROR - Error processing batch 1750: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:15,304 - WARNING - NaN/inf in loss_classifier (batch 1751) - using fallback: 0.0302 (count: 389)
2025-10-05 18:00:15,305 - WARNING - NaN/inf in loss_box_reg (batch 1751) - using fallback: 0.0318 (count: 389)
2025-10-05 18:00:15,305 - WARNING - NaN/inf in loss_objectness (batch 1751) - using fallback: 0.0101 (count: 389)
2025-10-05 18:00:15,306 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1751) - using fallback: 0.0126 (count: 389)
2025-10-05 18:00:15,307 - ERROR - Error processing batch 1751: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:15,869 - WARNING - NaN/inf in loss_classifier (batch 1752) - using fallback: 0.0302 (count: 390)
2025-10-05 18:00:15,870 - WARNING - NaN/inf in loss_box_reg (batch 1752) - using fallback: 0.0318 (count: 390)
2025-10-05 18:00:15,870 - WARNING - NaN/inf in loss_objectness (batch 1752) - using fallback: 0.0101 (count: 390)
2025-10-05 18:00:15,871 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1752) - using fallback: 0.0126 (count: 390)
2025-10-05 18:00:15,871 - ERROR - Error processing batch 1752: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:16,439 - WARNING - NaN/inf in loss_classifier (batch 1753) - using fallback: 0.0302 (count: 391)
2025-10-05 18:00:16,439 - WARNING - NaN/inf in loss_box_reg (batch 1753) - using fallback: 0.0318 (count: 391)
2025-10-05 18:00:16,440 - WARNING - NaN/inf in loss_objectness (batch 1753) - using fallback: 0.0101 (count: 391)
2025-10-05 18:00:16,440 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1753) - using fallback: 0.0126 (count: 391)
2025-10-05 18:00:16,441 - ERROR - Error processing batch 1753: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:16,959 - WARNING - NaN/inf in loss_classifier (batch 1754) - using fallback: 0.0302 (count: 392)
2025-10-05 18:00:16,960 - WARNING - NaN/inf in loss_box_reg (batch 1754) - using fallback: 0.0318 (count: 392)
2025-10-05 18:00:16,960 - WARNING - NaN/inf in loss_objectness (batch 1754) - using fallback: 0.0101 (count: 392)
2025-10-05 18:00:16,961 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1754) - using fallback: 0.0126 (count: 392)
2025-10-05 18:00:16,962 - ERROR - Error processing batch 1754: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:17,528 - WARNING - NaN/inf in loss_classifier (batch 1755) - using fallback: 0.0302 (count: 393)
2025-10-05 18:00:17,529 - WARNING - NaN/inf in loss_box_reg (batch 1755) - using fallback: 0.0318 (count: 393)
2025-10-05 18:00:17,529 - WARNING - NaN/inf in loss_objectness (batch 1755) - using fallback: 0.0101 (count: 393)
2025-10-05 18:00:17,530 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1755) - using fallback: 0.0126 (count: 393)
2025-10-05 18:00:17,530 - ERROR - Error processing batch 1755: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:18,038 - WARNING - NaN/inf in loss_classifier (batch 1756) - using fallback: 0.0302 (count: 394)
2025-10-05 18:00:18,039 - WARNING - NaN/inf in loss_box_reg (batch 1756) - using fallback: 0.0318 (count: 394)
2025-10-05 18:00:18,040 - WARNING - NaN/inf in loss_objectness (batch 1756) - using fallback: 0.0101 (count: 394)
2025-10-05 18:00:18,040 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1756) - using fallback: 0.0126 (count: 394)
2025-10-05 18:00:18,041 - ERROR - Error processing batch 1756: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:18,675 - WARNING - NaN/inf in loss_classifier (batch 1757) - using fallback: 0.0302 (count: 395)
2025-10-05 18:00:18,676 - WARNING - NaN/inf in loss_box_reg (batch 1757) - using fallback: 0.0318 (count: 395)
2025-10-05 18:00:18,676 - WARNING - NaN/inf in loss_objectness (batch 1757) - using fallback: 0.0101 (count: 395)
2025-10-05 18:00:18,677 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1757) - using fallback: 0.0126 (count: 395)
2025-10-05 18:00:18,678 - ERROR - Error processing batch 1757: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:19,134 - WARNING - NaN/inf in loss_classifier (batch 1758) - using fallback: 0.0302 (count: 396)
2025-10-05 18:00:19,135 - WARNING - NaN/inf in loss_box_reg (batch 1758) - using fallback: 0.0318 (count: 396)
2025-10-05 18:00:19,136 - WARNING - NaN/inf in loss_objectness (batch 1758) - using fallback: 0.0101 (count: 396)
2025-10-05 18:00:19,136 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1758) - using fallback: 0.0126 (count: 396)
2025-10-05 18:00:19,137 - ERROR - Error processing batch 1758: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:19,699 - WARNING - NaN/inf in loss_classifier (batch 1759) - using fallback: 0.0302 (count: 397)
2025-10-05 18:00:19,700 - WARNING - NaN/inf in loss_box_reg (batch 1759) - using fallback: 0.0318 (count: 397)
2025-10-05 18:00:19,700 - WARNING - NaN/inf in loss_objectness (batch 1759) - using fallback: 0.0101 (count: 397)
2025-10-05 18:00:19,701 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1759) - using fallback: 0.0126 (count: 397)
2025-10-05 18:00:19,701 - ERROR - Error processing batch 1759: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:20,186 - WARNING - NaN/inf in loss_classifier (batch 1760) - using fallback: 0.0302 (count: 398)
2025-10-05 18:00:20,187 - WARNING - NaN/inf in loss_box_reg (batch 1760) - using fallback: 0.0318 (count: 398)
2025-10-05 18:00:20,188 - WARNING - NaN/inf in loss_objectness (batch 1760) - using fallback: 0.0101 (count: 398)
2025-10-05 18:00:20,188 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1760) - using fallback: 0.0126 (count: 398)
2025-10-05 18:00:20,189 - ERROR - Error processing batch 1760: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:20,853 - WARNING - NaN/inf in loss_classifier (batch 1761) - using fallback: 0.0302 (count: 399)
2025-10-05 18:00:20,853 - WARNING - NaN/inf in loss_box_reg (batch 1761) - using fallback: 0.0318 (count: 399)
2025-10-05 18:00:20,854 - WARNING - NaN/inf in loss_objectness (batch 1761) - using fallback: 0.0101 (count: 399)
2025-10-05 18:00:20,855 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1761) - using fallback: 0.0126 (count: 399)
2025-10-05 18:00:20,855 - ERROR - Error processing batch 1761: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:21,379 - WARNING - NaN/inf in loss_classifier (batch 1762) - using fallback: 0.0302 (count: 400)
2025-10-05 18:00:21,380 - WARNING - NaN/inf in loss_box_reg (batch 1762) - using fallback: 0.0318 (count: 400)
2025-10-05 18:00:21,381 - WARNING - NaN/inf in loss_objectness (batch 1762) - using fallback: 0.0101 (count: 400)
2025-10-05 18:00:21,381 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1762) - using fallback: 0.0126 (count: 400)
2025-10-05 18:00:21,382 - ERROR - Error processing batch 1762: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:21,990 - WARNING - NaN/inf in loss_classifier (batch 1763) - using fallback: 0.0302 (count: 401)
2025-10-05 18:00:21,991 - WARNING - NaN/inf in loss_box_reg (batch 1763) - using fallback: 0.0318 (count: 401)
2025-10-05 18:00:21,991 - WARNING - NaN/inf in loss_objectness (batch 1763) - using fallback: 0.0101 (count: 401)
2025-10-05 18:00:21,992 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1763) - using fallback: 0.0126 (count: 401)
2025-10-05 18:00:21,992 - ERROR - Error processing batch 1763: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:22,516 - WARNING - NaN/inf in loss_classifier (batch 1764) - using fallback: 0.0302 (count: 402)
2025-10-05 18:00:22,517 - WARNING - NaN/inf in loss_box_reg (batch 1764) - using fallback: 0.0318 (count: 402)
2025-10-05 18:00:22,518 - WARNING - NaN/inf in loss_objectness (batch 1764) - using fallback: 0.0101 (count: 402)
2025-10-05 18:00:22,518 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1764) - using fallback: 0.0126 (count: 402)
2025-10-05 18:00:22,519 - ERROR - Error processing batch 1764: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:23,129 - WARNING - NaN/inf in loss_classifier (batch 1765) - using fallback: 0.0302 (count: 403)
2025-10-05 18:00:23,130 - WARNING - NaN/inf in loss_box_reg (batch 1765) - using fallback: 0.0318 (count: 403)
2025-10-05 18:00:23,131 - WARNING - NaN/inf in loss_objectness (batch 1765) - using fallback: 0.0101 (count: 403)
2025-10-05 18:00:23,131 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1765) - using fallback: 0.0126 (count: 403)
2025-10-05 18:00:23,132 - ERROR - Error processing batch 1765: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:23,651 - WARNING - NaN/inf in loss_classifier (batch 1766) - using fallback: 0.0302 (count: 404)
2025-10-05 18:00:23,652 - WARNING - NaN/inf in loss_box_reg (batch 1766) - using fallback: 0.0318 (count: 404)
2025-10-05 18:00:23,652 - WARNING - NaN/inf in loss_objectness (batch 1766) - using fallback: 0.0101 (count: 404)
2025-10-05 18:00:23,653 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1766) - using fallback: 0.0126 (count: 404)
2025-10-05 18:00:23,654 - ERROR - Error processing batch 1766: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:24,281 - WARNING - NaN/inf in loss_classifier (batch 1767) - using fallback: 0.0302 (count: 405)
2025-10-05 18:00:24,282 - WARNING - NaN/inf in loss_box_reg (batch 1767) - using fallback: 0.0318 (count: 405)
2025-10-05 18:00:24,282 - WARNING - NaN/inf in loss_objectness (batch 1767) - using fallback: 0.0101 (count: 405)
2025-10-05 18:00:24,283 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1767) - using fallback: 0.0126 (count: 405)
2025-10-05 18:00:24,284 - ERROR - Error processing batch 1767: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:24,828 - WARNING - NaN/inf in loss_classifier (batch 1768) - using fallback: 0.0302 (count: 406)
2025-10-05 18:00:24,829 - WARNING - NaN/inf in loss_box_reg (batch 1768) - using fallback: 0.0318 (count: 406)
2025-10-05 18:00:24,829 - WARNING - NaN/inf in loss_objectness (batch 1768) - using fallback: 0.0101 (count: 406)
2025-10-05 18:00:24,830 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1768) - using fallback: 0.0126 (count: 406)
2025-10-05 18:00:24,831 - ERROR - Error processing batch 1768: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:25,378 - WARNING - NaN/inf in loss_classifier (batch 1769) - using fallback: 0.0302 (count: 407)
2025-10-05 18:00:25,378 - WARNING - NaN/inf in loss_box_reg (batch 1769) - using fallback: 0.0318 (count: 407)
2025-10-05 18:00:25,379 - WARNING - NaN/inf in loss_objectness (batch 1769) - using fallback: 0.0101 (count: 407)
2025-10-05 18:00:25,379 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1769) - using fallback: 0.0126 (count: 407)
2025-10-05 18:00:25,380 - ERROR - Error processing batch 1769: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:25,952 - WARNING - NaN/inf in loss_classifier (batch 1770) - using fallback: 0.0302 (count: 408)
2025-10-05 18:00:25,953 - WARNING - NaN/inf in loss_box_reg (batch 1770) - using fallback: 0.0318 (count: 408)
2025-10-05 18:00:25,954 - WARNING - NaN/inf in loss_objectness (batch 1770) - using fallback: 0.0101 (count: 408)
2025-10-05 18:00:25,954 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1770) - using fallback: 0.0126 (count: 408)
2025-10-05 18:00:25,955 - ERROR - Error processing batch 1770: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:26,492 - WARNING - NaN/inf in loss_classifier (batch 1771) - using fallback: 0.0302 (count: 409)
2025-10-05 18:00:26,493 - WARNING - NaN/inf in loss_box_reg (batch 1771) - using fallback: 0.0318 (count: 409)
2025-10-05 18:00:26,494 - WARNING - NaN/inf in loss_objectness (batch 1771) - using fallback: 0.0101 (count: 409)
2025-10-05 18:00:26,494 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1771) - using fallback: 0.0126 (count: 409)
2025-10-05 18:00:26,495 - ERROR - Error processing batch 1771: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:27,022 - WARNING - NaN/inf in loss_classifier (batch 1772) - using fallback: 0.0302 (count: 410)
2025-10-05 18:00:27,022 - WARNING - NaN/inf in loss_box_reg (batch 1772) - using fallback: 0.0318 (count: 410)
2025-10-05 18:00:27,023 - WARNING - NaN/inf in loss_objectness (batch 1772) - using fallback: 0.0101 (count: 410)
2025-10-05 18:00:27,024 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1772) - using fallback: 0.0126 (count: 410)
2025-10-05 18:00:27,024 - ERROR - Error processing batch 1772: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:27,655 - WARNING - NaN/inf in loss_classifier (batch 1773) - using fallback: 0.0302 (count: 411)
2025-10-05 18:00:27,656 - WARNING - NaN/inf in loss_box_reg (batch 1773) - using fallback: 0.0318 (count: 411)
2025-10-05 18:00:27,657 - WARNING - NaN/inf in loss_objectness (batch 1773) - using fallback: 0.0101 (count: 411)
2025-10-05 18:00:27,657 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1773) - using fallback: 0.0126 (count: 411)
2025-10-05 18:00:27,658 - ERROR - Error processing batch 1773: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:28,149 - WARNING - NaN/inf in loss_classifier (batch 1774) - using fallback: 0.0302 (count: 412)
2025-10-05 18:00:28,150 - WARNING - NaN/inf in loss_box_reg (batch 1774) - using fallback: 0.0318 (count: 412)
2025-10-05 18:00:28,150 - WARNING - NaN/inf in loss_objectness (batch 1774) - using fallback: 0.0101 (count: 412)
2025-10-05 18:00:28,151 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1774) - using fallback: 0.0126 (count: 412)
2025-10-05 18:00:28,151 - ERROR - Error processing batch 1774: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:28,783 - WARNING - NaN/inf in loss_classifier (batch 1775) - using fallback: 0.0302 (count: 413)
2025-10-05 18:00:28,784 - WARNING - NaN/inf in loss_box_reg (batch 1775) - using fallback: 0.0318 (count: 413)
2025-10-05 18:00:28,784 - WARNING - NaN/inf in loss_objectness (batch 1775) - using fallback: 0.0101 (count: 413)
2025-10-05 18:00:28,784 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1775) - using fallback: 0.0126 (count: 413)
2025-10-05 18:00:28,785 - ERROR - Error processing batch 1775: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:29,311 - WARNING - NaN/inf in loss_classifier (batch 1776) - using fallback: 0.0302 (count: 414)
2025-10-05 18:00:29,312 - WARNING - NaN/inf in loss_box_reg (batch 1776) - using fallback: 0.0318 (count: 414)
2025-10-05 18:00:29,313 - WARNING - NaN/inf in loss_objectness (batch 1776) - using fallback: 0.0101 (count: 414)
2025-10-05 18:00:29,314 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1776) - using fallback: 0.0126 (count: 414)
2025-10-05 18:00:29,314 - ERROR - Error processing batch 1776: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:29,882 - WARNING - NaN/inf in loss_classifier (batch 1777) - using fallback: 0.0302 (count: 415)
2025-10-05 18:00:29,883 - WARNING - NaN/inf in loss_box_reg (batch 1777) - using fallback: 0.0318 (count: 415)
2025-10-05 18:00:29,884 - WARNING - NaN/inf in loss_objectness (batch 1777) - using fallback: 0.0101 (count: 415)
2025-10-05 18:00:29,884 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1777) - using fallback: 0.0126 (count: 415)
2025-10-05 18:00:29,885 - ERROR - Error processing batch 1777: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:30,392 - WARNING - NaN/inf in loss_classifier (batch 1778) - using fallback: 0.0302 (count: 416)
2025-10-05 18:00:30,393 - WARNING - NaN/inf in loss_box_reg (batch 1778) - using fallback: 0.0318 (count: 416)
2025-10-05 18:00:30,394 - WARNING - NaN/inf in loss_objectness (batch 1778) - using fallback: 0.0101 (count: 416)
2025-10-05 18:00:30,394 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1778) - using fallback: 0.0126 (count: 416)
2025-10-05 18:00:30,395 - ERROR - Error processing batch 1778: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:31,058 - WARNING - NaN/inf in loss_classifier (batch 1779) - using fallback: 0.0302 (count: 417)
2025-10-05 18:00:31,059 - WARNING - NaN/inf in loss_box_reg (batch 1779) - using fallback: 0.0318 (count: 417)
2025-10-05 18:00:31,059 - WARNING - NaN/inf in loss_objectness (batch 1779) - using fallback: 0.0101 (count: 417)
2025-10-05 18:00:31,060 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1779) - using fallback: 0.0126 (count: 417)
2025-10-05 18:00:31,061 - ERROR - Error processing batch 1779: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:31,607 - WARNING - NaN/inf in loss_classifier (batch 1780) - using fallback: 0.0302 (count: 418)
2025-10-05 18:00:31,608 - WARNING - NaN/inf in loss_box_reg (batch 1780) - using fallback: 0.0318 (count: 418)
2025-10-05 18:00:31,609 - WARNING - NaN/inf in loss_objectness (batch 1780) - using fallback: 0.0101 (count: 418)
2025-10-05 18:00:31,609 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1780) - using fallback: 0.0126 (count: 418)
2025-10-05 18:00:31,610 - ERROR - Error processing batch 1780: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:32,195 - WARNING - NaN/inf in loss_classifier (batch 1781) - using fallback: 0.0302 (count: 419)
2025-10-05 18:00:32,196 - WARNING - NaN/inf in loss_box_reg (batch 1781) - using fallback: 0.0318 (count: 419)
2025-10-05 18:00:32,197 - WARNING - NaN/inf in loss_objectness (batch 1781) - using fallback: 0.0101 (count: 419)
2025-10-05 18:00:32,197 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1781) - using fallback: 0.0126 (count: 419)
2025-10-05 18:00:32,198 - ERROR - Error processing batch 1781: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:32,788 - WARNING - NaN/inf in loss_classifier (batch 1782) - using fallback: 0.0302 (count: 420)
2025-10-05 18:00:32,788 - WARNING - NaN/inf in loss_box_reg (batch 1782) - using fallback: 0.0318 (count: 420)
2025-10-05 18:00:32,789 - WARNING - NaN/inf in loss_objectness (batch 1782) - using fallback: 0.0101 (count: 420)
2025-10-05 18:00:32,790 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1782) - using fallback: 0.0126 (count: 420)
2025-10-05 18:00:32,790 - ERROR - Error processing batch 1782: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:33,453 - WARNING - NaN/inf in loss_classifier (batch 1783) - using fallback: 0.0302 (count: 421)
2025-10-05 18:00:33,454 - WARNING - NaN/inf in loss_box_reg (batch 1783) - using fallback: 0.0318 (count: 421)
2025-10-05 18:00:33,455 - WARNING - NaN/inf in loss_objectness (batch 1783) - using fallback: 0.0101 (count: 421)
2025-10-05 18:00:33,455 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1783) - using fallback: 0.0126 (count: 421)
2025-10-05 18:00:33,456 - ERROR - Error processing batch 1783: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:34,069 - WARNING - NaN/inf in loss_classifier (batch 1784) - using fallback: 0.0302 (count: 422)
2025-10-05 18:00:34,070 - WARNING - NaN/inf in loss_box_reg (batch 1784) - using fallback: 0.0318 (count: 422)
2025-10-05 18:00:34,071 - WARNING - NaN/inf in loss_objectness (batch 1784) - using fallback: 0.0101 (count: 422)
2025-10-05 18:00:34,071 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1784) - using fallback: 0.0126 (count: 422)
2025-10-05 18:00:34,072 - ERROR - Error processing batch 1784: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:34,666 - WARNING - NaN/inf in loss_classifier (batch 1785) - using fallback: 0.0302 (count: 423)
2025-10-05 18:00:34,667 - WARNING - NaN/inf in loss_box_reg (batch 1785) - using fallback: 0.0318 (count: 423)
2025-10-05 18:00:34,667 - WARNING - NaN/inf in loss_objectness (batch 1785) - using fallback: 0.0101 (count: 423)
2025-10-05 18:00:34,668 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1785) - using fallback: 0.0126 (count: 423)
2025-10-05 18:00:34,669 - ERROR - Error processing batch 1785: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:35,430 - WARNING - NaN/inf in loss_classifier (batch 1786) - using fallback: 0.0302 (count: 424)
2025-10-05 18:00:35,432 - WARNING - NaN/inf in loss_box_reg (batch 1786) - using fallback: 0.0318 (count: 424)
2025-10-05 18:00:35,432 - WARNING - NaN/inf in loss_objectness (batch 1786) - using fallback: 0.0101 (count: 424)
2025-10-05 18:00:35,433 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1786) - using fallback: 0.0126 (count: 424)
2025-10-05 18:00:35,433 - ERROR - Error processing batch 1786: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:36,068 - WARNING - NaN/inf in loss_classifier (batch 1787) - using fallback: 0.0302 (count: 425)
2025-10-05 18:00:36,069 - WARNING - NaN/inf in loss_box_reg (batch 1787) - using fallback: 0.0318 (count: 425)
2025-10-05 18:00:36,069 - WARNING - NaN/inf in loss_objectness (batch 1787) - using fallback: 0.0101 (count: 425)
2025-10-05 18:00:36,070 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1787) - using fallback: 0.0126 (count: 425)
2025-10-05 18:00:36,071 - ERROR - Error processing batch 1787: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:36,629 - WARNING - NaN/inf in loss_classifier (batch 1788) - using fallback: 0.0302 (count: 426)
2025-10-05 18:00:36,630 - WARNING - NaN/inf in loss_box_reg (batch 1788) - using fallback: 0.0318 (count: 426)
2025-10-05 18:00:36,631 - WARNING - NaN/inf in loss_objectness (batch 1788) - using fallback: 0.0101 (count: 426)
2025-10-05 18:00:36,632 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1788) - using fallback: 0.0126 (count: 426)
2025-10-05 18:00:36,632 - ERROR - Error processing batch 1788: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:37,306 - WARNING - NaN/inf in loss_classifier (batch 1789) - using fallback: 0.0302 (count: 427)
2025-10-05 18:00:37,307 - WARNING - NaN/inf in loss_box_reg (batch 1789) - using fallback: 0.0318 (count: 427)
2025-10-05 18:00:37,307 - WARNING - NaN/inf in loss_objectness (batch 1789) - using fallback: 0.0101 (count: 427)
2025-10-05 18:00:37,308 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1789) - using fallback: 0.0126 (count: 427)
2025-10-05 18:00:37,308 - ERROR - Error processing batch 1789: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:37,803 - WARNING - NaN/inf in loss_classifier (batch 1790) - using fallback: 0.0302 (count: 428)
2025-10-05 18:00:37,804 - WARNING - NaN/inf in loss_box_reg (batch 1790) - using fallback: 0.0318 (count: 428)
2025-10-05 18:00:37,805 - WARNING - NaN/inf in loss_objectness (batch 1790) - using fallback: 0.0101 (count: 428)
2025-10-05 18:00:37,805 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1790) - using fallback: 0.0126 (count: 428)
2025-10-05 18:00:37,806 - ERROR - Error processing batch 1790: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:38,378 - WARNING - NaN/inf in loss_classifier (batch 1791) - using fallback: 0.0302 (count: 429)
2025-10-05 18:00:38,378 - WARNING - NaN/inf in loss_box_reg (batch 1791) - using fallback: 0.0318 (count: 429)
2025-10-05 18:00:38,379 - WARNING - NaN/inf in loss_objectness (batch 1791) - using fallback: 0.0101 (count: 429)
2025-10-05 18:00:38,380 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1791) - using fallback: 0.0126 (count: 429)
2025-10-05 18:00:38,381 - ERROR - Error processing batch 1791: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:38,974 - WARNING - NaN/inf in loss_classifier (batch 1792) - using fallback: 0.0302 (count: 430)
2025-10-05 18:00:38,975 - WARNING - NaN/inf in loss_box_reg (batch 1792) - using fallback: 0.0318 (count: 430)
2025-10-05 18:00:38,975 - WARNING - NaN/inf in loss_objectness (batch 1792) - using fallback: 0.0101 (count: 430)
2025-10-05 18:00:38,976 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1792) - using fallback: 0.0126 (count: 430)
2025-10-05 18:00:38,977 - ERROR - Error processing batch 1792: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:39,569 - WARNING - NaN/inf in loss_classifier (batch 1793) - using fallback: 0.0302 (count: 431)
2025-10-05 18:00:39,569 - WARNING - NaN/inf in loss_box_reg (batch 1793) - using fallback: 0.0318 (count: 431)
2025-10-05 18:00:39,570 - WARNING - NaN/inf in loss_objectness (batch 1793) - using fallback: 0.0101 (count: 431)
2025-10-05 18:00:39,570 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1793) - using fallback: 0.0126 (count: 431)
2025-10-05 18:00:39,571 - ERROR - Error processing batch 1793: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:40,163 - WARNING - NaN/inf in loss_classifier (batch 1794) - using fallback: 0.0302 (count: 432)
2025-10-05 18:00:40,164 - WARNING - NaN/inf in loss_box_reg (batch 1794) - using fallback: 0.0318 (count: 432)
2025-10-05 18:00:40,165 - WARNING - NaN/inf in loss_objectness (batch 1794) - using fallback: 0.0101 (count: 432)
2025-10-05 18:00:40,165 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1794) - using fallback: 0.0126 (count: 432)
2025-10-05 18:00:40,166 - ERROR - Error processing batch 1794: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:40,847 - WARNING - NaN/inf in loss_classifier (batch 1795) - using fallback: 0.0302 (count: 433)
2025-10-05 18:00:40,847 - WARNING - NaN/inf in loss_box_reg (batch 1795) - using fallback: 0.0318 (count: 433)
2025-10-05 18:00:40,848 - WARNING - NaN/inf in loss_objectness (batch 1795) - using fallback: 0.0101 (count: 433)
2025-10-05 18:00:40,849 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1795) - using fallback: 0.0126 (count: 433)
2025-10-05 18:00:40,849 - ERROR - Error processing batch 1795: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:41,422 - WARNING - NaN/inf in loss_classifier (batch 1796) - using fallback: 0.0302 (count: 434)
2025-10-05 18:00:41,423 - WARNING - NaN/inf in loss_box_reg (batch 1796) - using fallback: 0.0318 (count: 434)
2025-10-05 18:00:41,424 - WARNING - NaN/inf in loss_objectness (batch 1796) - using fallback: 0.0101 (count: 434)
2025-10-05 18:00:41,424 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1796) - using fallback: 0.0126 (count: 434)
2025-10-05 18:00:41,425 - ERROR - Error processing batch 1796: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:41,981 - WARNING - NaN/inf in loss_classifier (batch 1797) - using fallback: 0.0302 (count: 435)
2025-10-05 18:00:41,981 - WARNING - NaN/inf in loss_box_reg (batch 1797) - using fallback: 0.0318 (count: 435)
2025-10-05 18:00:41,982 - WARNING - NaN/inf in loss_objectness (batch 1797) - using fallback: 0.0101 (count: 435)
2025-10-05 18:00:41,982 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1797) - using fallback: 0.0126 (count: 435)
2025-10-05 18:00:41,983 - ERROR - Error processing batch 1797: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:42,592 - WARNING - NaN/inf in loss_classifier (batch 1798) - using fallback: 0.0302 (count: 436)
2025-10-05 18:00:42,593 - WARNING - NaN/inf in loss_box_reg (batch 1798) - using fallback: 0.0318 (count: 436)
2025-10-05 18:00:42,593 - WARNING - NaN/inf in loss_objectness (batch 1798) - using fallback: 0.0101 (count: 436)
2025-10-05 18:00:42,594 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1798) - using fallback: 0.0126 (count: 436)
2025-10-05 18:00:42,595 - ERROR - Error processing batch 1798: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:43,214 - WARNING - NaN/inf in loss_classifier (batch 1799) - using fallback: 0.0302 (count: 437)
2025-10-05 18:00:43,215 - WARNING - NaN/inf in loss_box_reg (batch 1799) - using fallback: 0.0318 (count: 437)
2025-10-05 18:00:43,216 - WARNING - NaN/inf in loss_objectness (batch 1799) - using fallback: 0.0101 (count: 437)
2025-10-05 18:00:43,216 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1799) - using fallback: 0.0126 (count: 437)
2025-10-05 18:00:43,217 - ERROR - Error processing batch 1799: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:43,782 - WARNING - NaN/inf in loss_classifier (batch 1800) - using fallback: 0.0302 (count: 438)
2025-10-05 18:00:43,783 - WARNING - NaN/inf in loss_box_reg (batch 1800) - using fallback: 0.0318 (count: 438)
2025-10-05 18:00:43,783 - WARNING - NaN/inf in loss_objectness (batch 1800) - using fallback: 0.0101 (count: 438)
2025-10-05 18:00:43,784 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1800) - using fallback: 0.0126 (count: 438)
2025-10-05 18:00:43,784 - ERROR - Error processing batch 1800: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:44,369 - WARNING - NaN/inf in loss_classifier (batch 1801) - using fallback: 0.0302 (count: 439)
2025-10-05 18:00:44,370 - WARNING - NaN/inf in loss_box_reg (batch 1801) - using fallback: 0.0318 (count: 439)
2025-10-05 18:00:44,370 - WARNING - NaN/inf in loss_objectness (batch 1801) - using fallback: 0.0101 (count: 439)
2025-10-05 18:00:44,371 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1801) - using fallback: 0.0126 (count: 439)
2025-10-05 18:00:44,372 - ERROR - Error processing batch 1801: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:45,005 - WARNING - NaN/inf in loss_classifier (batch 1802) - using fallback: 0.0302 (count: 440)
2025-10-05 18:00:45,006 - WARNING - NaN/inf in loss_box_reg (batch 1802) - using fallback: 0.0318 (count: 440)
2025-10-05 18:00:45,006 - WARNING - NaN/inf in loss_objectness (batch 1802) - using fallback: 0.0101 (count: 440)
2025-10-05 18:00:45,007 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1802) - using fallback: 0.0126 (count: 440)
2025-10-05 18:00:45,008 - ERROR - Error processing batch 1802: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:45,686 - WARNING - NaN/inf in loss_classifier (batch 1803) - using fallback: 0.0302 (count: 441)
2025-10-05 18:00:45,686 - WARNING - NaN/inf in loss_box_reg (batch 1803) - using fallback: 0.0318 (count: 441)
2025-10-05 18:00:45,687 - WARNING - NaN/inf in loss_objectness (batch 1803) - using fallback: 0.0101 (count: 441)
2025-10-05 18:00:45,688 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1803) - using fallback: 0.0126 (count: 441)
2025-10-05 18:00:45,688 - ERROR - Error processing batch 1803: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:46,231 - WARNING - NaN/inf in loss_classifier (batch 1804) - using fallback: 0.0302 (count: 442)
2025-10-05 18:00:46,231 - WARNING - NaN/inf in loss_box_reg (batch 1804) - using fallback: 0.0318 (count: 442)
2025-10-05 18:00:46,232 - WARNING - NaN/inf in loss_objectness (batch 1804) - using fallback: 0.0101 (count: 442)
2025-10-05 18:00:46,233 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1804) - using fallback: 0.0126 (count: 442)
2025-10-05 18:00:46,233 - ERROR - Error processing batch 1804: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:46,760 - WARNING - NaN/inf in loss_classifier (batch 1805) - using fallback: 0.0302 (count: 443)
2025-10-05 18:00:46,761 - WARNING - NaN/inf in loss_box_reg (batch 1805) - using fallback: 0.0318 (count: 443)
2025-10-05 18:00:46,761 - WARNING - NaN/inf in loss_objectness (batch 1805) - using fallback: 0.0101 (count: 443)
2025-10-05 18:00:46,762 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1805) - using fallback: 0.0126 (count: 443)
2025-10-05 18:00:46,763 - ERROR - Error processing batch 1805: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:47,298 - WARNING - NaN/inf in loss_classifier (batch 1806) - using fallback: 0.0302 (count: 444)
2025-10-05 18:00:47,298 - WARNING - NaN/inf in loss_box_reg (batch 1806) - using fallback: 0.0318 (count: 444)
2025-10-05 18:00:47,299 - WARNING - NaN/inf in loss_objectness (batch 1806) - using fallback: 0.0101 (count: 444)
2025-10-05 18:00:47,300 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1806) - using fallback: 0.0126 (count: 444)
2025-10-05 18:00:47,300 - ERROR - Error processing batch 1806: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:47,989 - WARNING - NaN/inf in loss_classifier (batch 1807) - using fallback: 0.0302 (count: 445)
2025-10-05 18:00:47,990 - WARNING - NaN/inf in loss_box_reg (batch 1807) - using fallback: 0.0318 (count: 445)
2025-10-05 18:00:47,990 - WARNING - NaN/inf in loss_objectness (batch 1807) - using fallback: 0.0101 (count: 445)
2025-10-05 18:00:47,991 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1807) - using fallback: 0.0126 (count: 445)
2025-10-05 18:00:47,991 - ERROR - Error processing batch 1807: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:48,449 - WARNING - NaN/inf in loss_classifier (batch 1808) - using fallback: 0.0302 (count: 446)
2025-10-05 18:00:48,449 - WARNING - NaN/inf in loss_box_reg (batch 1808) - using fallback: 0.0318 (count: 446)
2025-10-05 18:00:48,450 - WARNING - NaN/inf in loss_objectness (batch 1808) - using fallback: 0.0101 (count: 446)
2025-10-05 18:00:48,464 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1808) - using fallback: 0.0126 (count: 446)
2025-10-05 18:00:48,465 - ERROR - Error processing batch 1808: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:49,083 - WARNING - NaN/inf in loss_classifier (batch 1809) - using fallback: 0.0302 (count: 447)
2025-10-05 18:00:49,084 - WARNING - NaN/inf in loss_box_reg (batch 1809) - using fallback: 0.0318 (count: 447)
2025-10-05 18:00:49,085 - WARNING - NaN/inf in loss_objectness (batch 1809) - using fallback: 0.0101 (count: 447)
2025-10-05 18:00:49,085 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1809) - using fallback: 0.0126 (count: 447)
2025-10-05 18:00:49,086 - ERROR - Error processing batch 1809: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:49,603 - WARNING - NaN/inf in loss_classifier (batch 1810) - using fallback: 0.0302 (count: 448)
2025-10-05 18:00:49,604 - WARNING - NaN/inf in loss_box_reg (batch 1810) - using fallback: 0.0318 (count: 448)
2025-10-05 18:00:49,604 - WARNING - NaN/inf in loss_objectness (batch 1810) - using fallback: 0.0101 (count: 448)
2025-10-05 18:00:49,605 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1810) - using fallback: 0.0126 (count: 448)
2025-10-05 18:00:49,606 - ERROR - Error processing batch 1810: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:50,305 - WARNING - NaN/inf in loss_classifier (batch 1811) - using fallback: 0.0302 (count: 449)
2025-10-05 18:00:50,306 - WARNING - NaN/inf in loss_box_reg (batch 1811) - using fallback: 0.0318 (count: 449)
2025-10-05 18:00:50,307 - WARNING - NaN/inf in loss_objectness (batch 1811) - using fallback: 0.0101 (count: 449)
2025-10-05 18:00:50,307 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1811) - using fallback: 0.0126 (count: 449)
2025-10-05 18:00:50,308 - ERROR - Error processing batch 1811: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:50,875 - WARNING - NaN/inf in loss_classifier (batch 1812) - using fallback: 0.0302 (count: 450)
2025-10-05 18:00:50,875 - WARNING - NaN/inf in loss_box_reg (batch 1812) - using fallback: 0.0318 (count: 450)
2025-10-05 18:00:50,876 - WARNING - NaN/inf in loss_objectness (batch 1812) - using fallback: 0.0101 (count: 450)
2025-10-05 18:00:50,876 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1812) - using fallback: 0.0126 (count: 450)
2025-10-05 18:00:50,877 - ERROR - Error processing batch 1812: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:51,505 - WARNING - NaN/inf in loss_classifier (batch 1813) - using fallback: 0.0302 (count: 451)
2025-10-05 18:00:51,505 - WARNING - NaN/inf in loss_box_reg (batch 1813) - using fallback: 0.0318 (count: 451)
2025-10-05 18:00:51,506 - WARNING - NaN/inf in loss_objectness (batch 1813) - using fallback: 0.0101 (count: 451)
2025-10-05 18:00:51,506 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1813) - using fallback: 0.0126 (count: 451)
2025-10-05 18:00:51,507 - ERROR - Error processing batch 1813: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:52,093 - WARNING - NaN/inf in loss_classifier (batch 1814) - using fallback: 0.0302 (count: 452)
2025-10-05 18:00:52,093 - WARNING - NaN/inf in loss_box_reg (batch 1814) - using fallback: 0.0318 (count: 452)
2025-10-05 18:00:52,094 - WARNING - NaN/inf in loss_objectness (batch 1814) - using fallback: 0.0101 (count: 452)
2025-10-05 18:00:52,094 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1814) - using fallback: 0.0126 (count: 452)
2025-10-05 18:00:52,095 - ERROR - Error processing batch 1814: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:52,750 - WARNING - NaN/inf in loss_classifier (batch 1815) - using fallback: 0.0302 (count: 453)
2025-10-05 18:00:52,751 - WARNING - NaN/inf in loss_box_reg (batch 1815) - using fallback: 0.0318 (count: 453)
2025-10-05 18:00:52,751 - WARNING - NaN/inf in loss_objectness (batch 1815) - using fallback: 0.0101 (count: 453)
2025-10-05 18:00:52,752 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1815) - using fallback: 0.0126 (count: 453)
2025-10-05 18:00:52,753 - ERROR - Error processing batch 1815: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:53,359 - WARNING - NaN/inf in loss_classifier (batch 1816) - using fallback: 0.0302 (count: 454)
2025-10-05 18:00:53,360 - WARNING - NaN/inf in loss_box_reg (batch 1816) - using fallback: 0.0318 (count: 454)
2025-10-05 18:00:53,361 - WARNING - NaN/inf in loss_objectness (batch 1816) - using fallback: 0.0101 (count: 454)
2025-10-05 18:00:53,362 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1816) - using fallback: 0.0126 (count: 454)
2025-10-05 18:00:53,362 - ERROR - Error processing batch 1816: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:54,054 - WARNING - NaN/inf in loss_classifier (batch 1817) - using fallback: 0.0302 (count: 455)
2025-10-05 18:00:54,055 - WARNING - NaN/inf in loss_box_reg (batch 1817) - using fallback: 0.0318 (count: 455)
2025-10-05 18:00:54,056 - WARNING - NaN/inf in loss_objectness (batch 1817) - using fallback: 0.0101 (count: 455)
2025-10-05 18:00:54,056 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1817) - using fallback: 0.0126 (count: 455)
2025-10-05 18:00:54,057 - ERROR - Error processing batch 1817: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:54,674 - WARNING - NaN/inf in loss_classifier (batch 1818) - using fallback: 0.0302 (count: 456)
2025-10-05 18:00:54,675 - WARNING - NaN/inf in loss_box_reg (batch 1818) - using fallback: 0.0318 (count: 456)
2025-10-05 18:00:54,676 - WARNING - NaN/inf in loss_objectness (batch 1818) - using fallback: 0.0101 (count: 456)
2025-10-05 18:00:54,676 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1818) - using fallback: 0.0126 (count: 456)
2025-10-05 18:00:54,677 - ERROR - Error processing batch 1818: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:55,370 - WARNING - NaN/inf in loss_classifier (batch 1819) - using fallback: 0.0302 (count: 457)
2025-10-05 18:00:55,370 - WARNING - NaN/inf in loss_box_reg (batch 1819) - using fallback: 0.0318 (count: 457)
2025-10-05 18:00:55,371 - WARNING - NaN/inf in loss_objectness (batch 1819) - using fallback: 0.0101 (count: 457)
2025-10-05 18:00:55,371 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1819) - using fallback: 0.0126 (count: 457)
2025-10-05 18:00:55,372 - ERROR - Error processing batch 1819: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:55,894 - WARNING - NaN/inf in loss_classifier (batch 1820) - using fallback: 0.0302 (count: 458)
2025-10-05 18:00:55,895 - WARNING - NaN/inf in loss_box_reg (batch 1820) - using fallback: 0.0318 (count: 458)
2025-10-05 18:00:55,896 - WARNING - NaN/inf in loss_objectness (batch 1820) - using fallback: 0.0101 (count: 458)
2025-10-05 18:00:55,896 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1820) - using fallback: 0.0126 (count: 458)
2025-10-05 18:00:55,897 - ERROR - Error processing batch 1820: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:56,541 - WARNING - NaN/inf in loss_classifier (batch 1821) - using fallback: 0.0302 (count: 459)
2025-10-05 18:00:56,542 - WARNING - NaN/inf in loss_box_reg (batch 1821) - using fallback: 0.0318 (count: 459)
2025-10-05 18:00:56,542 - WARNING - NaN/inf in loss_objectness (batch 1821) - using fallback: 0.0101 (count: 459)
2025-10-05 18:00:56,543 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1821) - using fallback: 0.0126 (count: 459)
2025-10-05 18:00:56,544 - ERROR - Error processing batch 1821: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:57,126 - WARNING - NaN/inf in loss_classifier (batch 1822) - using fallback: 0.0302 (count: 460)
2025-10-05 18:00:57,127 - WARNING - NaN/inf in loss_box_reg (batch 1822) - using fallback: 0.0318 (count: 460)
2025-10-05 18:00:57,127 - WARNING - NaN/inf in loss_objectness (batch 1822) - using fallback: 0.0101 (count: 460)
2025-10-05 18:00:57,128 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1822) - using fallback: 0.0126 (count: 460)
2025-10-05 18:00:57,129 - ERROR - Error processing batch 1822: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:57,738 - WARNING - NaN/inf in loss_classifier (batch 1823) - using fallback: 0.0302 (count: 461)
2025-10-05 18:00:57,738 - WARNING - NaN/inf in loss_box_reg (batch 1823) - using fallback: 0.0318 (count: 461)
2025-10-05 18:00:57,739 - WARNING - NaN/inf in loss_objectness (batch 1823) - using fallback: 0.0101 (count: 461)
2025-10-05 18:00:57,739 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1823) - using fallback: 0.0126 (count: 461)
2025-10-05 18:00:57,740 - ERROR - Error processing batch 1823: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:58,329 - WARNING - NaN/inf in loss_classifier (batch 1824) - using fallback: 0.0302 (count: 462)
2025-10-05 18:00:58,330 - WARNING - NaN/inf in loss_box_reg (batch 1824) - using fallback: 0.0318 (count: 462)
2025-10-05 18:00:58,330 - WARNING - NaN/inf in loss_objectness (batch 1824) - using fallback: 0.0101 (count: 462)
2025-10-05 18:00:58,331 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1824) - using fallback: 0.0126 (count: 462)
2025-10-05 18:00:58,331 - ERROR - Error processing batch 1824: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:59,024 - WARNING - NaN/inf in loss_classifier (batch 1825) - using fallback: 0.0302 (count: 463)
2025-10-05 18:00:59,024 - WARNING - NaN/inf in loss_box_reg (batch 1825) - using fallback: 0.0318 (count: 463)
2025-10-05 18:00:59,025 - WARNING - NaN/inf in loss_objectness (batch 1825) - using fallback: 0.0101 (count: 463)
2025-10-05 18:00:59,025 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1825) - using fallback: 0.0126 (count: 463)
2025-10-05 18:00:59,026 - ERROR - Error processing batch 1825: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:00:59,614 - WARNING - NaN/inf in loss_classifier (batch 1826) - using fallback: 0.0302 (count: 464)
2025-10-05 18:00:59,615 - WARNING - NaN/inf in loss_box_reg (batch 1826) - using fallback: 0.0318 (count: 464)
2025-10-05 18:00:59,616 - WARNING - NaN/inf in loss_objectness (batch 1826) - using fallback: 0.0101 (count: 464)
2025-10-05 18:00:59,617 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1826) - using fallback: 0.0126 (count: 464)
2025-10-05 18:00:59,617 - ERROR - Error processing batch 1826: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:00,326 - WARNING - NaN/inf in loss_classifier (batch 1827) - using fallback: 0.0302 (count: 465)
2025-10-05 18:01:00,326 - WARNING - NaN/inf in loss_box_reg (batch 1827) - using fallback: 0.0318 (count: 465)
2025-10-05 18:01:00,327 - WARNING - NaN/inf in loss_objectness (batch 1827) - using fallback: 0.0101 (count: 465)
2025-10-05 18:01:00,328 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1827) - using fallback: 0.0126 (count: 465)
2025-10-05 18:01:00,328 - ERROR - Error processing batch 1827: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:00,924 - WARNING - NaN/inf in loss_classifier (batch 1828) - using fallback: 0.0302 (count: 466)
2025-10-05 18:01:00,925 - WARNING - NaN/inf in loss_box_reg (batch 1828) - using fallback: 0.0318 (count: 466)
2025-10-05 18:01:00,925 - WARNING - NaN/inf in loss_objectness (batch 1828) - using fallback: 0.0101 (count: 466)
2025-10-05 18:01:00,926 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1828) - using fallback: 0.0126 (count: 466)
2025-10-05 18:01:00,927 - ERROR - Error processing batch 1828: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:01,452 - WARNING - NaN/inf in loss_classifier (batch 1829) - using fallback: 0.0302 (count: 467)
2025-10-05 18:01:01,452 - WARNING - NaN/inf in loss_box_reg (batch 1829) - using fallback: 0.0318 (count: 467)
2025-10-05 18:01:01,453 - WARNING - NaN/inf in loss_objectness (batch 1829) - using fallback: 0.0101 (count: 467)
2025-10-05 18:01:01,453 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1829) - using fallback: 0.0126 (count: 467)
2025-10-05 18:01:01,454 - ERROR - Error processing batch 1829: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:02,109 - WARNING - NaN/inf in loss_classifier (batch 1830) - using fallback: 0.0302 (count: 468)
2025-10-05 18:01:02,109 - WARNING - NaN/inf in loss_box_reg (batch 1830) - using fallback: 0.0318 (count: 468)
2025-10-05 18:01:02,110 - WARNING - NaN/inf in loss_objectness (batch 1830) - using fallback: 0.0101 (count: 468)
2025-10-05 18:01:02,110 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1830) - using fallback: 0.0126 (count: 468)
2025-10-05 18:01:02,111 - ERROR - Error processing batch 1830: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:02,842 - WARNING - NaN/inf in loss_classifier (batch 1831) - using fallback: 0.0302 (count: 469)
2025-10-05 18:01:02,843 - WARNING - NaN/inf in loss_box_reg (batch 1831) - using fallback: 0.0318 (count: 469)
2025-10-05 18:01:02,844 - WARNING - NaN/inf in loss_objectness (batch 1831) - using fallback: 0.0101 (count: 469)
2025-10-05 18:01:02,844 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1831) - using fallback: 0.0126 (count: 469)
2025-10-05 18:01:02,845 - ERROR - Error processing batch 1831: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:03,424 - WARNING - NaN/inf in loss_classifier (batch 1832) - using fallback: 0.0302 (count: 470)
2025-10-05 18:01:03,424 - WARNING - NaN/inf in loss_box_reg (batch 1832) - using fallback: 0.0318 (count: 470)
2025-10-05 18:01:03,425 - WARNING - NaN/inf in loss_objectness (batch 1832) - using fallback: 0.0101 (count: 470)
2025-10-05 18:01:03,426 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1832) - using fallback: 0.0126 (count: 470)
2025-10-05 18:01:03,426 - ERROR - Error processing batch 1832: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:04,241 - WARNING - NaN/inf in loss_classifier (batch 1833) - using fallback: 0.0302 (count: 471)
2025-10-05 18:01:04,242 - WARNING - NaN/inf in loss_box_reg (batch 1833) - using fallback: 0.0318 (count: 471)
2025-10-05 18:01:04,243 - WARNING - NaN/inf in loss_objectness (batch 1833) - using fallback: 0.0101 (count: 471)
2025-10-05 18:01:04,243 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1833) - using fallback: 0.0126 (count: 471)
2025-10-05 18:01:04,244 - ERROR - Error processing batch 1833: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:05,035 - WARNING - NaN/inf in loss_classifier (batch 1834) - using fallback: 0.0302 (count: 472)
2025-10-05 18:01:05,036 - WARNING - NaN/inf in loss_box_reg (batch 1834) - using fallback: 0.0318 (count: 472)
2025-10-05 18:01:05,036 - WARNING - NaN/inf in loss_objectness (batch 1834) - using fallback: 0.0101 (count: 472)
2025-10-05 18:01:05,037 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1834) - using fallback: 0.0126 (count: 472)
2025-10-05 18:01:05,037 - ERROR - Error processing batch 1834: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:05,709 - WARNING - NaN/inf in loss_classifier (batch 1835) - using fallback: 0.0302 (count: 473)
2025-10-05 18:01:05,710 - WARNING - NaN/inf in loss_box_reg (batch 1835) - using fallback: 0.0318 (count: 473)
2025-10-05 18:01:05,711 - WARNING - NaN/inf in loss_objectness (batch 1835) - using fallback: 0.0101 (count: 473)
2025-10-05 18:01:05,711 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1835) - using fallback: 0.0126 (count: 473)
2025-10-05 18:01:05,712 - ERROR - Error processing batch 1835: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:06,359 - WARNING - NaN/inf in loss_classifier (batch 1836) - using fallback: 0.0302 (count: 474)
2025-10-05 18:01:06,360 - WARNING - NaN/inf in loss_box_reg (batch 1836) - using fallback: 0.0318 (count: 474)
2025-10-05 18:01:06,361 - WARNING - NaN/inf in loss_objectness (batch 1836) - using fallback: 0.0101 (count: 474)
2025-10-05 18:01:06,361 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1836) - using fallback: 0.0126 (count: 474)
2025-10-05 18:01:06,362 - ERROR - Error processing batch 1836: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:06,898 - WARNING - NaN/inf in loss_classifier (batch 1837) - using fallback: 0.0302 (count: 475)
2025-10-05 18:01:06,899 - WARNING - NaN/inf in loss_box_reg (batch 1837) - using fallback: 0.0318 (count: 475)
2025-10-05 18:01:06,899 - WARNING - NaN/inf in loss_objectness (batch 1837) - using fallback: 0.0101 (count: 475)
2025-10-05 18:01:06,900 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1837) - using fallback: 0.0126 (count: 475)
2025-10-05 18:01:06,900 - ERROR - Error processing batch 1837: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:07,497 - WARNING - NaN/inf in loss_classifier (batch 1838) - using fallback: 0.0302 (count: 476)
2025-10-05 18:01:07,498 - WARNING - NaN/inf in loss_box_reg (batch 1838) - using fallback: 0.0318 (count: 476)
2025-10-05 18:01:07,499 - WARNING - NaN/inf in loss_objectness (batch 1838) - using fallback: 0.0101 (count: 476)
2025-10-05 18:01:07,499 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1838) - using fallback: 0.0126 (count: 476)
2025-10-05 18:01:07,500 - ERROR - Error processing batch 1838: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:08,064 - WARNING - NaN/inf in loss_classifier (batch 1839) - using fallback: 0.0302 (count: 477)
2025-10-05 18:01:08,065 - WARNING - NaN/inf in loss_box_reg (batch 1839) - using fallback: 0.0318 (count: 477)
2025-10-05 18:01:08,065 - WARNING - NaN/inf in loss_objectness (batch 1839) - using fallback: 0.0101 (count: 477)
2025-10-05 18:01:08,066 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1839) - using fallback: 0.0126 (count: 477)
2025-10-05 18:01:08,067 - ERROR - Error processing batch 1839: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:08,627 - WARNING - NaN/inf in loss_classifier (batch 1840) - using fallback: 0.0302 (count: 478)
2025-10-05 18:01:08,627 - WARNING - NaN/inf in loss_box_reg (batch 1840) - using fallback: 0.0318 (count: 478)
2025-10-05 18:01:08,628 - WARNING - NaN/inf in loss_objectness (batch 1840) - using fallback: 0.0101 (count: 478)
2025-10-05 18:01:08,629 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1840) - using fallback: 0.0126 (count: 478)
2025-10-05 18:01:08,629 - ERROR - Error processing batch 1840: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:09,221 - WARNING - NaN/inf in loss_classifier (batch 1841) - using fallback: 0.0302 (count: 479)
2025-10-05 18:01:09,222 - WARNING - NaN/inf in loss_box_reg (batch 1841) - using fallback: 0.0318 (count: 479)
2025-10-05 18:01:09,222 - WARNING - NaN/inf in loss_objectness (batch 1841) - using fallback: 0.0101 (count: 479)
2025-10-05 18:01:09,223 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1841) - using fallback: 0.0126 (count: 479)
2025-10-05 18:01:09,224 - ERROR - Error processing batch 1841: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:09,800 - WARNING - NaN/inf in loss_classifier (batch 1842) - using fallback: 0.0302 (count: 480)
2025-10-05 18:01:09,801 - WARNING - NaN/inf in loss_box_reg (batch 1842) - using fallback: 0.0318 (count: 480)
2025-10-05 18:01:09,801 - WARNING - NaN/inf in loss_objectness (batch 1842) - using fallback: 0.0101 (count: 480)
2025-10-05 18:01:09,802 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1842) - using fallback: 0.0126 (count: 480)
2025-10-05 18:01:09,803 - ERROR - Error processing batch 1842: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:10,398 - WARNING - NaN/inf in loss_classifier (batch 1843) - using fallback: 0.0302 (count: 481)
2025-10-05 18:01:10,398 - WARNING - NaN/inf in loss_box_reg (batch 1843) - using fallback: 0.0318 (count: 481)
2025-10-05 18:01:10,399 - WARNING - NaN/inf in loss_objectness (batch 1843) - using fallback: 0.0101 (count: 481)
2025-10-05 18:01:10,400 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1843) - using fallback: 0.0126 (count: 481)
2025-10-05 18:01:10,400 - ERROR - Error processing batch 1843: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:11,039 - WARNING - NaN/inf in loss_classifier (batch 1844) - using fallback: 0.0302 (count: 482)
2025-10-05 18:01:11,039 - WARNING - NaN/inf in loss_box_reg (batch 1844) - using fallback: 0.0318 (count: 482)
2025-10-05 18:01:11,040 - WARNING - NaN/inf in loss_objectness (batch 1844) - using fallback: 0.0101 (count: 482)
2025-10-05 18:01:11,040 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1844) - using fallback: 0.0126 (count: 482)
2025-10-05 18:01:11,041 - ERROR - Error processing batch 1844: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:11,632 - WARNING - NaN/inf in loss_classifier (batch 1845) - using fallback: 0.0302 (count: 483)
2025-10-05 18:01:11,640 - WARNING - NaN/inf in loss_box_reg (batch 1845) - using fallback: 0.0318 (count: 483)
2025-10-05 18:01:11,641 - WARNING - NaN/inf in loss_objectness (batch 1845) - using fallback: 0.0101 (count: 483)
2025-10-05 18:01:11,643 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1845) - using fallback: 0.0126 (count: 483)
2025-10-05 18:01:11,644 - ERROR - Error processing batch 1845: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:12,261 - WARNING - NaN/inf in loss_classifier (batch 1846) - using fallback: 0.0302 (count: 484)
2025-10-05 18:01:12,261 - WARNING - NaN/inf in loss_box_reg (batch 1846) - using fallback: 0.0318 (count: 484)
2025-10-05 18:01:12,262 - WARNING - NaN/inf in loss_objectness (batch 1846) - using fallback: 0.0101 (count: 484)
2025-10-05 18:01:12,263 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1846) - using fallback: 0.0126 (count: 484)
2025-10-05 18:01:12,264 - ERROR - Error processing batch 1846: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:13,050 - WARNING - NaN/inf in loss_classifier (batch 1847) - using fallback: 0.0302 (count: 485)
2025-10-05 18:01:13,051 - WARNING - NaN/inf in loss_box_reg (batch 1847) - using fallback: 0.0318 (count: 485)
2025-10-05 18:01:13,052 - WARNING - NaN/inf in loss_objectness (batch 1847) - using fallback: 0.0101 (count: 485)
2025-10-05 18:01:13,052 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1847) - using fallback: 0.0126 (count: 485)
2025-10-05 18:01:13,053 - ERROR - Error processing batch 1847: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:13,627 - WARNING - NaN/inf in loss_classifier (batch 1848) - using fallback: 0.0302 (count: 486)
2025-10-05 18:01:13,627 - WARNING - NaN/inf in loss_box_reg (batch 1848) - using fallback: 0.0318 (count: 486)
2025-10-05 18:01:13,628 - WARNING - NaN/inf in loss_objectness (batch 1848) - using fallback: 0.0101 (count: 486)
2025-10-05 18:01:13,629 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1848) - using fallback: 0.0126 (count: 486)
2025-10-05 18:01:13,629 - ERROR - Error processing batch 1848: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:14,399 - WARNING - NaN/inf in loss_classifier (batch 1849) - using fallback: 0.0302 (count: 487)
2025-10-05 18:01:14,400 - WARNING - NaN/inf in loss_box_reg (batch 1849) - using fallback: 0.0318 (count: 487)
2025-10-05 18:01:14,400 - WARNING - NaN/inf in loss_objectness (batch 1849) - using fallback: 0.0101 (count: 487)
2025-10-05 18:01:14,401 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1849) - using fallback: 0.0126 (count: 487)
2025-10-05 18:01:14,402 - ERROR - Error processing batch 1849: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:15,198 - WARNING - NaN/inf in loss_classifier (batch 1850) - using fallback: 0.0302 (count: 488)
2025-10-05 18:01:15,199 - WARNING - NaN/inf in loss_box_reg (batch 1850) - using fallback: 0.0318 (count: 488)
2025-10-05 18:01:15,200 - WARNING - NaN/inf in loss_objectness (batch 1850) - using fallback: 0.0101 (count: 488)
2025-10-05 18:01:15,200 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1850) - using fallback: 0.0126 (count: 488)
2025-10-05 18:01:15,201 - ERROR - Error processing batch 1850: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:15,973 - WARNING - NaN/inf in loss_classifier (batch 1851) - using fallback: 0.0302 (count: 489)
2025-10-05 18:01:15,974 - WARNING - NaN/inf in loss_box_reg (batch 1851) - using fallback: 0.0318 (count: 489)
2025-10-05 18:01:15,975 - WARNING - NaN/inf in loss_objectness (batch 1851) - using fallback: 0.0101 (count: 489)
2025-10-05 18:01:15,975 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1851) - using fallback: 0.0126 (count: 489)
2025-10-05 18:01:15,976 - ERROR - Error processing batch 1851: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:16,753 - WARNING - NaN/inf in loss_classifier (batch 1852) - using fallback: 0.0302 (count: 490)
2025-10-05 18:01:16,754 - WARNING - NaN/inf in loss_box_reg (batch 1852) - using fallback: 0.0318 (count: 490)
2025-10-05 18:01:16,755 - WARNING - NaN/inf in loss_objectness (batch 1852) - using fallback: 0.0101 (count: 490)
2025-10-05 18:01:16,756 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1852) - using fallback: 0.0126 (count: 490)
2025-10-05 18:01:16,756 - ERROR - Error processing batch 1852: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:17,471 - WARNING - NaN/inf in loss_classifier (batch 1853) - using fallback: 0.0302 (count: 491)
2025-10-05 18:01:17,472 - WARNING - NaN/inf in loss_box_reg (batch 1853) - using fallback: 0.0318 (count: 491)
2025-10-05 18:01:17,472 - WARNING - NaN/inf in loss_objectness (batch 1853) - using fallback: 0.0101 (count: 491)
2025-10-05 18:01:17,473 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1853) - using fallback: 0.0126 (count: 491)
2025-10-05 18:01:17,474 - ERROR - Error processing batch 1853: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:18,204 - WARNING - NaN/inf in loss_classifier (batch 1854) - using fallback: 0.0302 (count: 492)
2025-10-05 18:01:18,205 - WARNING - NaN/inf in loss_box_reg (batch 1854) - using fallback: 0.0318 (count: 492)
2025-10-05 18:01:18,205 - WARNING - NaN/inf in loss_objectness (batch 1854) - using fallback: 0.0101 (count: 492)
2025-10-05 18:01:18,206 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1854) - using fallback: 0.0126 (count: 492)
2025-10-05 18:01:18,206 - ERROR - Error processing batch 1854: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:18,873 - WARNING - NaN/inf in loss_classifier (batch 1855) - using fallback: 0.0302 (count: 493)
2025-10-05 18:01:18,874 - WARNING - NaN/inf in loss_box_reg (batch 1855) - using fallback: 0.0318 (count: 493)
2025-10-05 18:01:18,875 - WARNING - NaN/inf in loss_objectness (batch 1855) - using fallback: 0.0101 (count: 493)
2025-10-05 18:01:18,875 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1855) - using fallback: 0.0126 (count: 493)
2025-10-05 18:01:18,876 - ERROR - Error processing batch 1855: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:19,562 - WARNING - NaN/inf in loss_classifier (batch 1856) - using fallback: 0.0302 (count: 494)
2025-10-05 18:01:19,563 - WARNING - NaN/inf in loss_box_reg (batch 1856) - using fallback: 0.0318 (count: 494)
2025-10-05 18:01:19,564 - WARNING - NaN/inf in loss_objectness (batch 1856) - using fallback: 0.0101 (count: 494)
2025-10-05 18:01:19,564 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1856) - using fallback: 0.0126 (count: 494)
2025-10-05 18:01:19,565 - ERROR - Error processing batch 1856: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:20,292 - WARNING - NaN/inf in loss_classifier (batch 1857) - using fallback: 0.0302 (count: 495)
2025-10-05 18:01:20,292 - WARNING - NaN/inf in loss_box_reg (batch 1857) - using fallback: 0.0318 (count: 495)
2025-10-05 18:01:20,293 - WARNING - NaN/inf in loss_objectness (batch 1857) - using fallback: 0.0101 (count: 495)
2025-10-05 18:01:20,294 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1857) - using fallback: 0.0126 (count: 495)
2025-10-05 18:01:20,295 - ERROR - Error processing batch 1857: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:20,854 - WARNING - NaN/inf in loss_classifier (batch 1858) - using fallback: 0.0302 (count: 496)
2025-10-05 18:01:20,854 - WARNING - NaN/inf in loss_box_reg (batch 1858) - using fallback: 0.0318 (count: 496)
2025-10-05 18:01:20,855 - WARNING - NaN/inf in loss_objectness (batch 1858) - using fallback: 0.0101 (count: 496)
2025-10-05 18:01:20,855 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1858) - using fallback: 0.0126 (count: 496)
2025-10-05 18:01:20,856 - ERROR - Error processing batch 1858: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:21,548 - WARNING - NaN/inf in loss_classifier (batch 1859) - using fallback: 0.0302 (count: 497)
2025-10-05 18:01:21,549 - WARNING - NaN/inf in loss_box_reg (batch 1859) - using fallback: 0.0318 (count: 497)
2025-10-05 18:01:21,549 - WARNING - NaN/inf in loss_objectness (batch 1859) - using fallback: 0.0101 (count: 497)
2025-10-05 18:01:21,549 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1859) - using fallback: 0.0126 (count: 497)
2025-10-05 18:01:21,550 - ERROR - Error processing batch 1859: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:22,325 - WARNING - NaN/inf in loss_classifier (batch 1860) - using fallback: 0.0302 (count: 498)
2025-10-05 18:01:22,326 - WARNING - NaN/inf in loss_box_reg (batch 1860) - using fallback: 0.0318 (count: 498)
2025-10-05 18:01:22,326 - WARNING - NaN/inf in loss_objectness (batch 1860) - using fallback: 0.0101 (count: 498)
2025-10-05 18:01:22,327 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1860) - using fallback: 0.0126 (count: 498)
2025-10-05 18:01:22,327 - ERROR - Error processing batch 1860: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:23,103 - WARNING - NaN/inf in loss_classifier (batch 1861) - using fallback: 0.0302 (count: 499)
2025-10-05 18:01:23,104 - WARNING - NaN/inf in loss_box_reg (batch 1861) - using fallback: 0.0318 (count: 499)
2025-10-05 18:01:23,104 - WARNING - NaN/inf in loss_objectness (batch 1861) - using fallback: 0.0101 (count: 499)
2025-10-05 18:01:23,105 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1861) - using fallback: 0.0126 (count: 499)
2025-10-05 18:01:23,105 - ERROR - Error processing batch 1861: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:23,718 - WARNING - NaN/inf in loss_classifier (batch 1862) - using fallback: 0.0302 (count: 500)
2025-10-05 18:01:23,719 - WARNING - NaN/inf in loss_box_reg (batch 1862) - using fallback: 0.0318 (count: 500)
2025-10-05 18:01:23,719 - WARNING - NaN/inf in loss_objectness (batch 1862) - using fallback: 0.0101 (count: 500)
2025-10-05 18:01:23,720 - WARNING - NaN/inf in loss_rpn_box_reg (batch 1862) - using fallback: 0.0126 (count: 500)
2025-10-05 18:01:23,720 - ERROR - Error processing batch 1862: element 0 of tensors does not require grad and does not have a grad_fn
2025-10-05 18:01:48,621 - INFO - Using device: cuda
2025-10-05 18:01:48,622 - INFO - Loading split dataset (train/val/test)...
2025-10-05 18:01:48,641 - INFO - Split dataset loaded successfully!
2025-10-05 18:01:48,641 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 18:01:48,642 - INFO - Initializing adaptive fusion model...
2025-10-05 18:01:49,548 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 18:01:49,549 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-05 18:01:49,549 - INFO -  Starting cattle detection training...
2025-10-05 18:01:49,553 - INFO - Using learning rate: 0.000095
2025-10-05 18:02:09,992 - WARNING - NaN/inf in loss_classifier (batch 20) - using fallback: 0.0535 (count: 1, streak: 1)
2025-10-05 18:02:09,993 - WARNING - NaN/inf in loss_box_reg (batch 20) - using fallback: 0.0769 (count: 1, streak: 2)
2025-10-05 18:02:09,993 - WARNING - NaN/inf in loss_objectness (batch 20) - using fallback: 0.0491 (count: 1, streak: 3)
2025-10-05 18:02:10,029 - ERROR - Error processing batch 20: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.
2025-10-05 18:06:50,364 - INFO - Using device: cuda
2025-10-05 18:06:50,364 - INFO - Loading split dataset (train/val/test)...
2025-10-05 18:06:50,391 - INFO - Split dataset loaded successfully!
2025-10-05 18:06:50,391 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 18:06:50,391 - INFO - Initializing adaptive fusion model...
2025-10-05 18:06:51,310 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 18:06:51,310 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-05 18:06:51,310 - INFO -  Starting cattle detection training...
2025-10-05 18:06:51,314 - INFO - Using learning rate: 0.000095
2025-10-05 18:06:53,835 - ERROR - Error processing batch 0: 'loss_classifier'
2025-10-05 18:06:54,415 - ERROR - Error processing batch 1: 'loss_classifier'
2025-10-05 18:06:58,831 - ERROR - Error processing batch 2: 'loss_classifier'
2025-10-05 18:07:03,569 - ERROR - Error processing batch 3: 'loss_classifier'
2025-10-05 18:07:08,487 - ERROR - Error processing batch 4: 'loss_classifier'
2025-10-05 18:07:13,381 - ERROR - Error processing batch 5: 'loss_classifier'
2025-10-05 18:07:32,358 - ERROR - Error processing batch 6: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.47 GiB is allocated by PyTorch, and 82.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:07:43,915 - ERROR - Error processing batch 7: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:07:45,641 - ERROR - Error processing batch 8: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:07:48,317 - ERROR - Error processing batch 9: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:07:50,991 - ERROR - Error processing batch 10: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:07:53,666 - ERROR - Error processing batch 11: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:07:56,341 - ERROR - Error processing batch 12: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:07:59,017 - ERROR - Error processing batch 13: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:01,693 - ERROR - Error processing batch 14: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:04,367 - ERROR - Error processing batch 15: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:07,042 - ERROR - Error processing batch 16: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:09,715 - ERROR - Error processing batch 17: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:12,392 - ERROR - Error processing batch 18: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:15,067 - ERROR - Error processing batch 19: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:17,750 - ERROR - Error processing batch 20: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:20,428 - ERROR - Error processing batch 21: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:23,107 - ERROR - Error processing batch 22: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:25,785 - ERROR - Error processing batch 23: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:28,461 - ERROR - Error processing batch 24: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:31,131 - ERROR - Error processing batch 25: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:33,805 - ERROR - Error processing batch 26: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:36,481 - ERROR - Error processing batch 27: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:39,153 - ERROR - Error processing batch 28: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:41,844 - ERROR - Error processing batch 29: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:44,511 - ERROR - Error processing batch 30: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:47,188 - ERROR - Error processing batch 31: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:49,864 - ERROR - Error processing batch 32: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:52,537 - ERROR - Error processing batch 33: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:55,212 - ERROR - Error processing batch 34: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:08:57,886 - ERROR - Error processing batch 35: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:09:00,562 - ERROR - Error processing batch 36: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:09:03,241 - ERROR - Error processing batch 37: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:09:05,916 - ERROR - Error processing batch 38: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:09:08,589 - ERROR - Error processing batch 39: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:09:11,269 - ERROR - Error processing batch 40: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:09:13,945 - ERROR - Error processing batch 41: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:09:16,619 - ERROR - Error processing batch 42: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-10-05 18:14:02,151 - INFO - Using device: cuda
2025-10-05 18:14:02,151 - INFO - Loading split dataset (train/val/test)...
2025-10-05 18:14:02,670 - INFO - Split dataset loaded successfully!
2025-10-05 18:14:02,671 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 18:14:02,671 - INFO - Initializing adaptive fusion model...
2025-10-05 18:14:03,822 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 18:14:03,822 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-05 18:14:03,823 - INFO -  Starting cattle detection training...
2025-10-05 18:14:03,828 - INFO - Using learning rate: 0.000095
2025-10-05 18:14:06,419 - ERROR - Error processing batch 0: 'loss_classifier'
2025-10-05 18:14:06,951 - ERROR - Error processing batch 1: 'loss_classifier'
2025-10-05 18:14:11,175 - ERROR - Error processing batch 2: 'loss_classifier'
2025-10-05 18:14:15,499 - ERROR - Error processing batch 3: 'loss_classifier'
2025-10-05 18:14:19,813 - ERROR - Error processing batch 4: 'loss_classifier'
2025-10-05 18:14:24,455 - ERROR - Error processing batch 5: 'loss_classifier'
2025-10-05 18:28:36,635 - INFO - Using device: cuda
2025-10-05 18:28:36,635 - INFO - Loading split dataset (train/val/test)...
2025-10-05 18:28:36,654 - INFO - Split dataset loaded successfully!
2025-10-05 18:28:36,654 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 18:28:36,654 - INFO - Initializing adaptive fusion model...
2025-10-05 18:28:37,645 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 18:28:37,646 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-05 18:28:37,646 - INFO -  Starting cattle detection training...
2025-10-05 18:28:37,650 - INFO - Using learning rate: 0.000095
2025-10-05 18:29:07,593 - WARNING - NaN/inf in loss_classifier (batch 32) - using fallback: 0.0555
2025-10-05 18:29:07,593 - WARNING - NaN/inf in loss_box_reg (batch 32) - using fallback: 0.0728
2025-10-05 18:29:07,594 - WARNING - NaN/inf in loss_objectness (batch 32) - using fallback: 0.0355
2025-10-05 18:30:11,672 - WARNING - NaN/inf in loss_classifier (batch 112) - using fallback: 0.0574
2025-10-05 18:30:11,674 - WARNING - NaN/inf in loss_objectness (batch 112) - using fallback: 0.0236
2025-10-05 18:33:23,671 - INFO - Using device: cuda
2025-10-05 18:33:23,672 - INFO - Loading split dataset (train/val/test)...
2025-10-05 18:33:23,692 - INFO - Split dataset loaded successfully!
2025-10-05 18:33:23,692 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 18:33:23,692 - INFO - Initializing adaptive fusion model...
2025-10-05 18:33:24,583 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 18:33:24,583 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-05 18:33:24,583 - INFO -  Starting cattle detection training...
2025-10-05 18:33:24,587 - INFO - Using learning rate: 0.000095
2025-10-05 18:33:50,995 - WARNING - NaN/inf in loss_classifier (batch 28) - using fallback: 0.0181
2025-10-05 18:33:50,996 - WARNING - NaN/inf in loss_objectness (batch 28) - using fallback: 0.0227
2025-10-05 18:33:56,941 - WARNING - NaN/inf in loss_classifier (batch 36) - using fallback: 0.0160
2025-10-05 18:33:56,942 - WARNING - NaN/inf in loss_objectness (batch 36) - using fallback: 0.0217
2025-10-05 18:34:06,741 - WARNING - NaN/inf in loss_classifier (batch 49) - using fallback: 0.0174
2025-10-05 18:34:06,742 - WARNING - NaN/inf in loss_objectness (batch 49) - using fallback: 0.0182
2025-10-05 18:35:00,359 - WARNING - NaN/inf in loss_classifier (batch 118) - using fallback: 0.0182
2025-10-05 18:35:00,360 - WARNING - NaN/inf in loss_objectness (batch 118) - using fallback: 0.0116
2025-10-05 18:35:03,510 - WARNING - NaN/inf in loss_classifier (batch 122) - using fallback: 0.0180
2025-10-05 18:35:03,511 - WARNING - NaN/inf in loss_objectness (batch 122) - using fallback: 0.0112
2025-10-05 18:35:09,089 - WARNING - NaN/inf in loss_classifier (batch 129) - using fallback: 0.0160
2025-10-05 18:35:09,089 - WARNING - NaN/inf in loss_box_reg (batch 129) - using fallback: 0.0339
2025-10-05 18:35:09,090 - WARNING - NaN/inf in loss_objectness (batch 129) - using fallback: 0.0114
2025-10-05 18:35:32,121 - WARNING - NaN/inf in loss_classifier (batch 158) - using fallback: 0.0171
2025-10-05 18:35:32,123 - WARNING - NaN/inf in loss_objectness (batch 158) - using fallback: 0.0101
2025-10-05 18:35:37,008 - WARNING - NaN/inf in loss_classifier (batch 164) - using fallback: 0.0162
2025-10-05 18:35:37,009 - WARNING - NaN/inf in loss_box_reg (batch 164) - using fallback: 0.0321
2025-10-05 18:35:37,010 - WARNING - NaN/inf in loss_objectness (batch 164) - using fallback: 0.0095
2025-10-05 18:35:45,184 - WARNING - NaN/inf in loss_classifier (batch 174) - using fallback: 0.0139
2025-10-05 18:35:45,185 - WARNING - NaN/inf in loss_objectness (batch 174) - using fallback: 0.0087
2025-10-05 18:35:57,399 - WARNING - NaN/inf in loss_classifier (batch 189) - using fallback: 0.0156
2025-10-05 18:35:57,400 - WARNING - NaN/inf in loss_box_reg (batch 189) - using fallback: 0.0308
2025-10-05 18:35:57,400 - WARNING - NaN/inf in loss_objectness (batch 189) - using fallback: 0.0095
2025-10-05 18:35:58,150 - WARNING - NaN/inf in loss_classifier (batch 190) - using fallback: 0.0156
2025-10-05 18:35:58,151 - WARNING - NaN/inf in loss_objectness (batch 190) - using fallback: 0.0095
2025-10-05 18:50:18,365 - INFO - Using device: cuda
2025-10-05 18:50:18,366 - INFO - Loading split dataset (train/val/test)...
2025-10-05 18:50:18,384 - INFO - Split dataset loaded successfully!
2025-10-05 18:50:18,384 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 18:50:18,384 - INFO - Initializing adaptive fusion model...
2025-10-05 18:50:19,276 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 18:50:19,276 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-05 18:50:19,277 - INFO -  Starting cattle detection training...
2025-10-05 18:50:19,281 - INFO - Using learning rate: 0.000095
2025-10-05 18:50:19,598 - ERROR - Training failed with error: Boolean value of Tensor with more than one value is ambiguous
Traceback (most recent call last):
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 565, in <module>
    train_one_epoch(model, train_loader, optimizer, scaler, device, epoch, args, logger)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 254, in train_one_epoch
    if not images or not targets:
           ^^^^^^
RuntimeError: Boolean value of Tensor with more than one value is ambiguous
2025-10-05 18:51:37,282 - INFO - Using device: cuda
2025-10-05 18:51:37,282 - INFO - Loading split dataset (train/val/test)...
2025-10-05 18:51:37,302 - INFO - Split dataset loaded successfully!
2025-10-05 18:51:37,302 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 18:51:37,303 - INFO - Initializing adaptive fusion model...
2025-10-05 18:51:38,198 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 18:51:38,198 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-05 18:51:38,198 - INFO -  Starting cattle detection training...
2025-10-05 18:51:38,202 - INFO - Using learning rate: 0.000095
2025-10-05 21:03:33,593 - INFO - Epoch 17 | Training Loss: 0.1798
2025-10-05 21:03:33,594 - INFO - Current learning rate: 0.000095
2025-10-05 21:07:45,267 - INFO - ==========================================================================================
2025-10-05 21:07:45,267 - INFO - VAL Set Metrics:
2025-10-05 21:07:45,267 - INFO - mAP50 :  0.4219 
2025-10-05 21:07:45,267 - INFO - mAP50-95 : 0.1828
2025-10-05 21:07:45,268 - INFO - Precision : 0.3062 
2025-10-05 21:07:45,268 - INFO - Recall :    0.6280 
2025-10-05 21:07:45,268 - INFO - ==========================================================================================
2025-10-05 21:07:45,298 - INFO -  No improvement: Current Val mAP50 (0.4219) < Best (0.4265)
2025-10-05 21:07:45,298 - INFO - Stagnant epochs: 1/10
2025-10-05 21:07:45,300 - INFO - Using learning rate: 0.000095
2025-10-05 21:35:36,973 - INFO - Using device: cuda
2025-10-05 21:35:36,973 - INFO - Loading split dataset (train/val/test)...
2025-10-05 21:35:36,994 - INFO - Split dataset loaded successfully!
2025-10-05 21:35:36,994 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-05 21:35:36,994 - INFO - Initializing adaptive fusion model...
2025-10-05 21:35:38,031 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-05 21:35:38,031 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-05 21:35:38,031 - INFO -  Starting cattle detection training...
2025-10-05 21:35:38,035 - INFO - Using learning rate: 0.000095
2025-10-05 23:49:25,832 - INFO - Epoch 17 | Training Loss: 0.1875
2025-10-05 23:53:24,722 - INFO - ==========================================================================================
2025-10-05 23:53:24,722 - INFO - VAL Set Metrics:
2025-10-05 23:53:24,722 - INFO - mAP50 :  0.3820 
2025-10-05 23:53:24,722 - INFO - mAP50-95 : 0.1482
2025-10-05 23:53:24,722 - INFO - Precision : 0.4645 
2025-10-05 23:53:24,723 - INFO - Recall :    0.5989 
2025-10-05 23:53:24,723 - INFO - ==========================================================================================
2025-10-05 23:53:24,751 - INFO - Current learning rate: 0.000095
2025-10-05 23:53:24,753 - INFO -  No improvement: Current Val mAP50 (0.3820) < Best (0.4265)
2025-10-05 23:53:24,753 - INFO - Stagnant epochs: 1/10
2025-10-05 23:53:24,756 - INFO - Using learning rate: 0.000095
2025-10-06 00:28:47,580 - INFO - Using device: cuda
2025-10-06 00:28:47,580 - INFO - Loading split dataset (train/val/test)...
2025-10-06 00:28:48,147 - INFO - Split dataset loaded successfully!
2025-10-06 00:28:48,148 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-06 00:28:48,148 - INFO - Initializing adaptive fusion model...
2025-10-06 00:28:49,912 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-06 00:28:49,912 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-06 00:28:49,912 - INFO -  Starting cattle detection training...
2025-10-06 00:28:49,920 - INFO - Using learning rate: 0.000095
2025-10-06 00:43:07,713 - INFO - Using device: cuda
2025-10-06 00:43:07,714 - INFO - Loading split dataset (train/val/test)...
2025-10-06 00:43:07,752 - INFO - Split dataset loaded successfully!
2025-10-06 00:43:07,753 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-06 00:43:07,753 - INFO - Initializing adaptive fusion model...
2025-10-06 00:43:09,262 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-06 00:43:09,262 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-06 00:43:09,262 - INFO -  Starting cattle detection training...
2025-10-06 00:43:09,268 - INFO - Using learning rate: 0.000095
2025-10-06 02:38:01,868 - INFO - Using device: cuda
2025-10-06 02:38:01,868 - INFO - Loading split dataset (train/val/test)...
2025-10-06 02:38:01,869 - ERROR - Training failed with error: DetectionDataset.__init__() got an unexpected keyword argument 'image_dir'. Did you mean 'images_dir'?
Traceback (most recent call last):
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 545, in <module>
    train_loader, val_loader, test_loader = load_split_dataloaders(args, train_transform, val_test_transform, logger)
                                            ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 156, in load_split_dataloaders
    datasets[split] = DetectionDataset(
                      ~~~~~~~~~~~~~~~~^
        image_dir=paths["img"],
        ^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        target_size=(480, 480)  # Reduced from 640x640
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: DetectionDataset.__init__() got an unexpected keyword argument 'image_dir'. Did you mean 'images_dir'?
2025-10-06 02:44:24,481 - INFO - Using device: cuda
2025-10-06 02:44:24,481 - INFO - Loading split dataset (train/val/test)...
2025-10-06 02:44:24,482 - ERROR - Training failed with error: DetectionDataset.__init__() got an unexpected keyword argument 'image_dir'. Did you mean 'images_dir'?
Traceback (most recent call last):
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 545, in <module>
    train_loader, val_loader, test_loader = load_split_dataloaders(args, train_transform, val_test_transform, logger)
                                            ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 156, in load_split_dataloaders
    datasets[split] = DetectionDataset(
                      ~~~~~~~~~~~~~~~~^
        image_dir=paths["img"],
        ^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        target_size=(480, 480)  # Reduced from 640x640
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: DetectionDataset.__init__() got an unexpected keyword argument 'image_dir'. Did you mean 'images_dir'?
2025-10-06 02:44:53,581 - INFO - Using device: cuda
2025-10-06 02:44:53,582 - INFO - Loading split dataset (train/val/test)...
2025-10-06 02:44:53,582 - ERROR - Training failed with error: DetectionDataset.__init__() got an unexpected keyword argument 'label_dir'. Did you mean 'labels_dir'?
Traceback (most recent call last):
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 545, in <module>
    train_loader, val_loader, test_loader = load_split_dataloaders(args, train_transform, val_test_transform, logger)
                                            ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 156, in load_split_dataloaders
    datasets[split] = DetectionDataset(
                      ~~~~~~~~~~~~~~~~^
        images_dir=paths["img"],
        ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        target_size=(480, 480)  # Reduced from 640x640
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: DetectionDataset.__init__() got an unexpected keyword argument 'label_dir'. Did you mean 'labels_dir'?
2025-10-06 02:45:25,740 - INFO - Using device: cuda
2025-10-06 02:45:25,741 - INFO - Loading split dataset (train/val/test)...
2025-10-06 02:45:25,741 - ERROR - Training failed with error: DetectionDataset.__init__() got an unexpected keyword argument 'transform'. Did you mean 'transforms'?
Traceback (most recent call last):
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 545, in <module>
    train_loader, val_loader, test_loader = load_split_dataloaders(args, train_transform, val_test_transform, logger)
                                            ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 156, in load_split_dataloaders
    datasets[split] = DetectionDataset(
                      ~~~~~~~~~~~~~~~~^
        images_dir=paths["img"],
        ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        target_size=(480, 480)  # Reduced from 640x640
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: DetectionDataset.__init__() got an unexpected keyword argument 'transform'. Did you mean 'transforms'?
2025-10-06 02:46:05,118 - INFO - Using device: cuda
2025-10-06 02:46:05,119 - INFO - Loading split dataset (train/val/test)...
2025-10-06 02:46:05,119 - ERROR - Training failed with error: DetectionDataset.__init__() got an unexpected keyword argument 'target_size'. Did you mean 'image_size'?
Traceback (most recent call last):
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 545, in <module>
    train_loader, val_loader, test_loader = load_split_dataloaders(args, train_transform, val_test_transform, logger)
                                            ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 156, in load_split_dataloaders
    datasets[split] = DetectionDataset(
                      ~~~~~~~~~~~~~~~~^
        images_dir=paths["img"],
        ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        target_size=(480, 480)  # Reduced from 640x640
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: DetectionDataset.__init__() got an unexpected keyword argument 'target_size'. Did you mean 'image_size'?
2025-10-06 02:46:47,760 - INFO - Using device: cuda
2025-10-06 02:46:47,761 - INFO - Loading split dataset (train/val/test)...
2025-10-06 02:46:47,802 - INFO - Split dataset loaded successfully!
2025-10-06 02:46:47,803 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-06 02:46:47,803 - INFO - Initializing adaptive fusion model...
2025-10-06 02:46:49,203 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-06 02:46:49,203 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-06 02:46:49,204 - INFO -  Starting cattle detection training...
2025-10-06 02:46:49,209 - INFO - Using learning rate: 0.000095
2025-10-06 02:47:01,192 - ERROR - Training failed with error: Caught TypeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\_utils\worker.py", line 349, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\_utils\fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "C:\Users\ASUS\Desktop\project 1\src\loaders\detection_dataset.py", line 262, in __getitem__
    target['boxes'] = self._scale_boxes(
                      ~~~~~~~~~~~~~~~~~^
        target['boxes'], orig_width, orig_height)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ASUS\Desktop\project 1\src\loaders\detection_dataset.py", line 195, in _scale_boxes
    scale_x = self.image_size / orig_width
              ~~~~~~~~~~~~~~~~^~~~~~~~~~~~
TypeError: unsupported operand type(s) for /: 'tuple' and 'int'
Traceback (most recent call last):
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 586, in <module>
    train_one_epoch(model, train_loader, optimizer, scaler, device, epoch, args, logger)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 258, in train_one_epoch
    for batch_idx, (images, targets) in enumerate(progress_bar):
                                        ~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\tqdm\std.py", line 1181, in __iter__
    for obj in iterable:
               ^^^^^^^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\dataloader.py", line 708, in __next__
    data = self._next_data()
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\dataloader.py", line 1480, in _next_data
    return self._process_data(data)
           ~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\dataloader.py", line 1505, in _process_data
    data.reraise()
    ~~~~~~~~~~~~^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\_utils.py", line 733, in reraise
    raise exception
TypeError: Caught TypeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\_utils\worker.py", line 349, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\_utils\fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "C:\Users\ASUS\Desktop\project 1\src\loaders\detection_dataset.py", line 262, in __getitem__
    target['boxes'] = self._scale_boxes(
                      ~~~~~~~~~~~~~~~~~^
        target['boxes'], orig_width, orig_height)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ASUS\Desktop\project 1\src\loaders\detection_dataset.py", line 195, in _scale_boxes
    scale_x = self.image_size / orig_width
              ~~~~~~~~~~~~~~~~^~~~~~~~~~~~
TypeError: unsupported operand type(s) for /: 'tuple' and 'int'

2025-10-06 02:49:48,950 - INFO - Using device: cuda
2025-10-06 02:49:48,951 - INFO - Loading split dataset (train/val/test)...
2025-10-06 02:49:48,990 - INFO - Split dataset loaded successfully!
2025-10-06 02:49:48,991 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-06 02:49:48,991 - INFO - Initializing adaptive fusion model...
2025-10-06 02:49:50,194 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-06 02:49:50,194 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-06 02:49:50,195 - INFO -  Starting cattle detection training...
2025-10-06 02:49:50,200 - INFO - Using learning rate: 0.000095
2025-10-06 04:35:52,959 - INFO - Epoch 17 | Training Loss: 0.1654
2025-10-06 04:36:50,657 - ERROR - Training failed with error: Caught RuntimeError in pin memory thread for device 0.
Original Traceback (most recent call last):
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\_utils\pin_memory.py", line 41, in do_one_step
    data = pin_memory(data, device)
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\_utils\pin_memory.py", line 88, in pin_memory
    pin_memory(sample, device) for sample in data
    ~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\_utils\pin_memory.py", line 64, in pin_memory
    return data.pin_memory(device)
           ~~~~~~~~~~~~~~~^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 589, in <module>
    current_val_mAP50, _, _, _ = evaluate_model(
                                 ~~~~~~~~~~~~~~^
        model, val_loader, device, "val", logger,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        threshold=args.inference_threshold
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 442, in evaluate_model
    dataloader = list(dataloader)[:len(dataloader)//2]
                 ~~~~^^^^^^^^^^^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\dataloader.py", line 708, in __next__
    data = self._next_data()
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\dataloader.py", line 1480, in _next_data
    return self._process_data(data)
           ~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\dataloader.py", line 1505, in _process_data
    data.reraise()
    ~~~~~~~~~~~~^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\_utils.py", line 733, in reraise
    raise exception
RuntimeError: Caught RuntimeError in pin memory thread for device 0.
Original Traceback (most recent call last):
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\_utils\pin_memory.py", line 41, in do_one_step
    data = pin_memory(data, device)
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\_utils\pin_memory.py", line 88, in pin_memory
    pin_memory(sample, device) for sample in data
    ~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\_utils\pin_memory.py", line 64, in pin_memory
    return data.pin_memory(device)
           ~~~~~~~~~~~~~~~^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-10-06 11:50:34,716 - INFO - Using device: cuda
2025-10-06 11:50:34,717 - INFO - Loading split dataset (train/val/test)...
2025-10-06 11:50:34,756 - INFO - Split dataset loaded successfully!
2025-10-06 11:50:34,756 - INFO - Train samples: 7993 | Val samples: 2017 | Test samples: 1367
2025-10-06 11:50:34,756 - INFO - Initializing adaptive fusion model...
2025-10-06 11:50:35,861 - INFO -  Resumed training from: C:\Users\ASUS\Desktop\project 1\model_checkpoints\cattle_best_model.pth
2025-10-06 11:50:35,861 - INFO - Start epoch: 16 | Best Val mAP50 so far: 0.4265
2025-10-06 11:50:35,861 - INFO -  Starting cattle detection training...
2025-10-06 11:50:35,866 - INFO - Using learning rate: 0.000095
2025-10-06 13:28:08,842 - INFO - Epoch 17 | Training Loss: 0.1660
2025-10-06 13:29:13,231 - ERROR - Training failed with error: Caught RuntimeError in pin memory thread for device 0.
Original Traceback (most recent call last):
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\_utils\pin_memory.py", line 41, in do_one_step
    data = pin_memory(data, device)
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\_utils\pin_memory.py", line 88, in pin_memory
    pin_memory(sample, device) for sample in data
    ~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\_utils\pin_memory.py", line 64, in pin_memory
    return data.pin_memory(device)
           ~~~~~~~~~~~~~~~^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 608, in <module>
    current_val_mAP50, _, _, _ = evaluate_model(
                                 ~~~~~~~~~~~~~~^
        model, val_loader, device, "val", logger,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        threshold=args.inference_threshold
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\ASUS\Desktop\project 1\src\training\train_fusion.py", line 456, in evaluate_model
    dataloader = list(dataloader)[:len(dataloader)//2]
                 ~~~~^^^^^^^^^^^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\dataloader.py", line 708, in __next__
    data = self._next_data()
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\dataloader.py", line 1480, in _next_data
    return self._process_data(data)
           ~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\dataloader.py", line 1505, in _process_data
    data.reraise()
    ~~~~~~~~~~~~^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\_utils.py", line 733, in reraise
    raise exception
RuntimeError: Caught RuntimeError in pin memory thread for device 0.
Original Traceback (most recent call last):
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\_utils\pin_memory.py", line 41, in do_one_step
    data = pin_memory(data, device)
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\_utils\pin_memory.py", line 88, in pin_memory
    pin_memory(sample, device) for sample in data
    ~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "C:\Users\ASUS\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\_utils\pin_memory.py", line 64, in pin_memory
    return data.pin_memory(device)
           ~~~~~~~~~~~~~~~^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


